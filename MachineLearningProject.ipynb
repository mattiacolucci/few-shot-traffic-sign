{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwJPMAS_A27U"
      },
      "source": [
        "# Measuring the effectiveness Few-shot learning for traffic sign recognition\n",
        "\n",
        "# ABSTRACT\n",
        "Nowadays, self-driving veichles is one of the main application of Artificial Intelligence (AI) which has been most widely used in daily-life scenarios. These veichles are based on many AI models among which there are traffic sign recognition systems. Different proposals have been provided for these systems, most of which rely on the usage of big datasets such as GTSRB (dataset of German traffic signs). Collecting a big amount of data is one of the main problems of Machine Learning models, which need lots of evidences in order to being able to generalize well. The effort in collecting more data than available can be one of the main aspects to consider during the development of these systems. Furthermore, using a big dataset expose to possible Adversarial attacks, from poisoning to evasion ones, specially in case of out-source training and testing. For these reasons, in this work we investigate the application of state-of-art Few-shot learning models on the traffic sign recognition domain. The aim of this work is to define the effectiveness of these approaches, in contrast to non-few-shot ones, to open the possibilities of build more robust and effortless solutions in this field.\n",
        "\n",
        "# NOTE\n",
        "più peso alla motivazione dell'attacco rispetto alla difficoltà nella raccolta di dati. Quindi focalizzarsi sul problema che attacchi di poisoning necessitano di aggiungere esempi poisonati che sono facilmente scopribili in casi di dataset piccoli (come nel few-shot) mediante un controllo umano dei sample. Attenzione: verificare, in caso questo controllo non si possa fare, se l'attacco è avvantaggiato con un dataset più piccolo rispetto ad uno grande. Se cosi fosse, sarebbe un problema.\n",
        "\n",
        "in the related work there are the works we are trying to improve\n",
        "\n",
        "specificare come ho creato il dataset ridotto\n",
        "\n",
        "testare i modelli anche sul dataset ridotto\n",
        "\n",
        "cercare come vengono valutati i modelli di few shot. Se si usa bootstrap o altre tecniche\n",
        "\n",
        "usare più modelli few shot, non solo CLIP e LDC\n",
        "\n",
        "-  N-way-k-shot (it means N classes and K instances per classes)\n",
        "\n",
        "-  Approfondire discorso support set (set non utilizzato nè durante training nè durante test ma solo durante fase di predizione)\n",
        "\n",
        "\n",
        "# RICERCHE ESISTENTI\n",
        "- <b>FUSED-Net: Enhancing Few-Shot Traffic Sign Detection with Unfrozen Parameters, Pseudo-Support Sets, Embedding Normalization, and Domain Adaptation</b>: https://arxiv.org/html/2409.14852v1 SOLO SU DATASET DEL BANGLADESH\n",
        "\n",
        "- <b>Cross-domain Few-shot In-context Learning for Enhancing Traffic Sign Recognition</b>: questo fa un compare tra modelli few shot sul dataset GTSRB\n",
        "\n",
        "- <b>Few-shot traffic sign recognition with clustering inductive bias and random neural network</b>: questo propone un nuovo modello per few-shot su traffic sign recognition\n",
        "\n",
        "- <b>Meta-YOLO: Meta-Learning for Few-Shot Traffic Sign Detection via Decoupling Dependencies</b>: questo fa traffic sign detection e non recognition (usa YOLO) quindi a noi non ci interessa\n",
        "\n",
        "- <b>Research on a Traffic Sign Recognition Method under Small Sample Conditions</b>: nuovo modello proposto\n",
        "\n",
        "- <b>Self-supervised few-shot learning for real-time traffic sign classification</b>: altro modello introdotto\n",
        "\n",
        "# EVALUATION METRICS\n",
        "\n",
        "Possible evaluation metrics used in the papers above are:\n",
        "Ma precision e recall non sono per binary classification? Lo dovresti fare per ogni classe considerando tutte le altre classi come istanze negative?\n",
        "- Average precision (AP): area under the precision-recall curve\n",
        "- Precision\n",
        "- Recall\n",
        "- A sto punto anche F1 Score? Male non fa\n",
        "- Accuracy rate (consigliato al posto di error rate. più utilizzato in letteratura)\n",
        "-\n",
        "\n",
        "# EVALUATION TECHNIQUES FOR FEW SHOTS ALGORITHMS\n",
        "- <b>Bootstrap</b>\n",
        "- <b>Fine-Grained Image Classification</b>: si valutano e testano gruppi di classi alla volta in modo tale da identificare i gruppi più problematici (nel nostro caso il gruppo dei segnali stradali relativi ai limiti di velocità potrebbero essere piu difficili da classificare rispetto a quelli di pericolo). \"Fine-Grained Image Classification is a task in computer vision where the goal is to classify images into subcategories within a larger category. For example, classifying different species of birds or different types of flowers. This task is considered to be fine-grained because it requires the model to distinguish between subtle differences in visual appearance and patterns, making it more challenging than regular image classification tasks.\"(https://paperswithcode.com/task/fine-grained-image-classification)\n",
        "-<b>Generalization error</b>: How much does accuracy drop when we reduce K (e.g., from K=5 to K=1)?*\n",
        "\n",
        "\n",
        "# EVALUATION TECHNIQUES TO COMPARE THE FEW SHOT VS MANY-SHOT LEARNING\n",
        "- <b>T-test</b> Separiamo il dataset di test in più dataset dove ciascun dataset contiene i sample di un determinato gruppo di segnali stradali (quindi un gruppo di classi) (vedere Fine-Grained Image Classification in  EVALUATION TECHNIQUES FOR FEW SHOTS ALGORITHMS). Siccome i dataset sono indipendenti gli uni dagli altri possiamo tranquillamente applicare il t-test classico per vedere se l'accuracy rate dell'algoritmo few shot e l'accuracy rate dell'algoritmo non-few shot sono significativamente diversi.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVluDFxmA63f"
      },
      "source": [
        "# Nuova sezione"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1X_N9dmATNzr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lew2aE4D5Nyk"
      },
      "source": [
        "<h2>Code used to create the random dataset:</h2>\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "def copy_random_images(p1, p2, num_images_per_folder=5):\n",
        "    \"\"\"\n",
        "    Copies random images from subfolders in p1 to p2, recreating the subfolder structure.\n",
        "\n",
        "    Args:\n",
        "        p1 (str): Source path containing subfolders with images.\n",
        "        p2 (str): Destination path where the subfolder structure and images will be recreated.\n",
        "        num_images_per_folder (int): Number of random images to copy from each subfolder.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(p1):\n",
        "        raise ValueError(f\"Source path '{p1}' does not exist.\")\n",
        "    \n",
        "    if not os.path.exists(p2):\n",
        "        os.makedirs(p2)\n",
        "\n",
        "    # Iterate through subfolders in p1\n",
        "    for subfolder in os.listdir(p1):\n",
        "        subfolder_path = os.path.join(p1, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            # Create the same subfolder in p2\n",
        "            dest_subfolder_path = os.path.join(p2, subfolder)\n",
        "            os.makedirs(dest_subfolder_path, exist_ok=True)\n",
        "\n",
        "            # Get all image files in the current subfolder\n",
        "            image_files = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n",
        "            \n",
        "            # Select random images\n",
        "            random_images = random.sample(image_files, min(num_images_per_folder, len(image_files)))\n",
        "\n",
        "            # Copy selected images to the destination subfolder\n",
        "            for image in random_images:\n",
        "                src_image_path = os.path.join(subfolder_path, image)\n",
        "                dest_image_path = os.path.join(dest_subfolder_path, image)\n",
        "\n",
        "                # Open, resize, and save the image\n",
        "                with Image.open(src_image_path) as img:\n",
        "                    img = img.convert(\"RGB\")  # Ensure the image is in RGB format\n",
        "                    img = img.resize((32, 32))  # Resize to 32x32\n",
        "                    img.save(dest_image_path)\n",
        "\n",
        "            print(f\"Copied {len(random_images)} images from '{subfolder_path}' to '{dest_subfolder_path}'.\")\n",
        "\n",
        "p1 = \"ortiginal_images_folder\"\n",
        "p2 = \"destination_images_folder\"\n",
        "num_images_per_folder = 30\n",
        "\n",
        "arr=[\"/train\",\"/val\",\"/test\"]\n",
        "\n",
        "for a in arr:\n",
        "  copy_random_images(p1, p2, num_images_per_folder+a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQLHmo5PTSVe"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzVHtTVx3K1m"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4Gb5yKmbBgYh"
      },
      "outputs": [],
      "source": [
        "import importlib.util\n",
        "import sys\n",
        "\n",
        "# allows to import py files from this folder\n",
        "sys.path.append(\"./few-shot-traffic-sign/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "5s1agHQX7gNa",
        "outputId": "cbf48c73-777a-4eec-f5b5-4a4f74a892f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-21 19:45:12 Preparing ViT-B/16 model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 335M/335M [01:40<00:00, 3.49MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-21 19:47:00 Getting cached textual weights W ...\n",
            "2025-05-21 19:47:05 Preparing traffic-signs dataset.\n",
            "2025-05-21 19:47:05 Starting training with the custom dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 0: 100%|██████████| 11/11 [00:09<00:00,  1.21it/s, cur_loss=27.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-21 19:47:46 train acc=0.41569767441860467, [l1_loss, ce_loss] => [21.134943181818183, 0.4385653409090909, 2.3245738636363638, 3.125887784090909, 2.4886363636363638]\n",
            "2025-05-21 19:47:46 Epoch: 0, loss: 29.5142, lr: 0.00009990\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9912\\1574377172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Start the training process\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mTools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Starting training with the custom dataset...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0macc_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mTools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"traffic-sign\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"acc\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0macc_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"detail\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_detail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_txt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\Desktop\\uni\\anno 1 magistrale\\semestre 2\\Machine Learning\\few-shot-traffic-sign\\ldc_train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m             Tools.print(f\"Epoch: {epoch}, loss: {loss:.4f}, \"\n\u001b[0;32m    491\u001b[0m                         f\"lr: {self.optimizer.state_dict()['param_groups'][0]['lr']:.8f}\")\n",
            "\u001b[1;32mc:\\Users\\utente\\Desktop\\uni\\anno 1 magistrale\\semestre 2\\Machine Learning\\few-shot-traffic-sign\\ldc_train.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(self, epoch)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAvgACC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         \u001b[0mloss_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mf\"epoch {epoch}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtqdm_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m                 \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\caml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\caml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\caml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\caml\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\caml\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\caml\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\caml\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\caml\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from ldc_train import *\n",
        "\n",
        "dataset_name=\"traffic-signs\"\n",
        "shots=16\n",
        "save_dir = dataset_name+\"_100_way_\"+str(shots)+\"_shot\"\n",
        "log_txt_path = Tools.new_dir(os.path.join(LOG_ROOT, save_dir, \"results.txt\"))\n",
        "\n",
        "# Create the configuration for the custom dataset\n",
        "config = Config10Dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    seed=2024,\n",
        "    shots=shots,\n",
        "    backbone=\"ViT-B/16\",\n",
        "    lr=0.001,\n",
        "    batch_size=64,\n",
        "    train_epoch=50,\n",
        "    loss_lambda=[1.0, 1.0, 1.0, 1.0, 1.0, 1.0],   #last is regularization lambda\n",
        "    fuse_type=2,\n",
        "    save_dir=save_dir,\n",
        "    #regularization='elastic_net'\n",
        ")\n",
        "\n",
        "# Initialize the Runner with the custom dataset configuration\n",
        "runner = Runner(config=config)\n",
        "\n",
        "# Start the training process\n",
        "Tools.print(\"Starting training with the custom dataset...\")\n",
        "acc_list = runner.train()\n",
        "Tools.print({\"name\": \"traffic-sign\", \"acc\": acc_list, \"detail\": config.get_detail()}, log_txt_path)\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "Tools.print(\"Evaluating the model...\")\n",
        "test_acc_list = runner.test()\n",
        "Tools.print({\"name\": \"traffic-sign\", \"test_acc\": test_acc_list}, log_txt_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X4-YscaR3ZQP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "caml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
