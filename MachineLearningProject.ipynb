{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwJPMAS_A27U"
      },
      "source": [
        "# Evaluating the Effectiveness of Few-Shot Learning in Traffic Sign Recognition Tasks\n",
        "\n",
        "<h2>ABSTRACT</h2>\n",
        "<p style=\"text-align: justify; font-family: Arial; font-size: 15px; line-height: 1.6; font-weight: normal;margin-right: 20px;\">Nowadays, self-driving veichles is one of the main application of Artificial Intelligence (AI) which has been most widely used in daily-life scenarios. These veichles are based on many AI models among which there are traffic sign recognition systems. Different proposals have been provided for these systems, most of which rely on the usage of big datasets such as GTSRB (dataset of German traffic signs). Collecting a big amount of data is one of the main problems of Machine Learning models, which need lots of evidences in order to being able to generalize well. The effort in collecting more data than available can be one of the main aspects to consider during the development of these systems. Furthermore, using a big dataset expose to possible Adversarial attacks, from poisoning to evasion ones, specially in case of out-source training and testing. For these reasons, in this work we investigate the application of state-of-art Few-shot learning models on the traffic sign recognition domain. The aim of this work is to define the effectiveness of these approaches, in contrast to non-few-shot ones, to open the possibilities of build more robust and effortless solutions in this field.</p>\n",
        "\n",
        "# NOTE\n",
        "più peso alla motivazione dell'attacco rispetto alla difficoltà nella raccolta di dati. Quindi focalizzarsi sul problema che attacchi di poisoning necessitano di aggiungere esempi poisonati che sono facilmente scopribili in casi di dataset piccoli (come nel few-shot) mediante un controllo umano dei sample. Attenzione: verificare, in caso questo controllo non si possa fare, se l'attacco è avvantaggiato con un dataset più piccolo rispetto ad uno grande. Se cosi fosse, sarebbe un problema.\n",
        "\n",
        "in the related work there are the works we are trying to improve\n",
        "\n",
        "specificare come ho creato il dataset ridotto\n",
        "\n",
        "testare i modelli anche sul dataset ridotto\n",
        "\n",
        "cercare come vengono valutati i modelli di few shot. Se si usa bootstrap o altre tecniche\n",
        "\n",
        "usare più modelli few shot, non solo CLIP e LDC\n",
        "\n",
        "-  N-way-k-shot (it means N classes and K instances per classes)\n",
        "\n",
        "-  Approfondire discorso support set (set non utilizzato nè durante training nè durante test ma solo durante fase di predizione)\n",
        "\n",
        "\n",
        "# RICERCHE ESISTENTI\n",
        "- <b>FUSED-Net: Enhancing Few-Shot Traffic Sign Detection with Unfrozen Parameters, Pseudo-Support Sets, Embedding Normalization, and Domain Adaptation</b>: https://arxiv.org/html/2409.14852v1 SOLO SU DATASET DEL BANGLADESH\n",
        "\n",
        "- <b>Cross-domain Few-shot In-context Learning for Enhancing Traffic Sign Recognition</b>: questo fa un compare tra modelli few shot sul dataset GTSRB\n",
        "\n",
        "- <b>Few-shot traffic sign recognition with clustering inductive bias and random neural network</b>: questo propone un nuovo modello per few-shot su traffic sign recognition\n",
        "\n",
        "- <b>Meta-YOLO: Meta-Learning for Few-Shot Traffic Sign Detection via Decoupling Dependencies</b>: questo fa traffic sign detection e non recognition (usa YOLO) quindi a noi non ci interessa\n",
        "\n",
        "- <b>Research on a Traffic Sign Recognition Method under Small Sample Conditions</b>: nuovo modello proposto\n",
        "\n",
        "-  <b>Self-supervised few-shot learning for real-time traffic sign classification</b>: altro modello introdotto\n",
        "\n",
        "<h2>No few-shot models used for the comparison</h2>\n",
        "<div style=\"text-align: justify; font-family: Arial; font-size: 15px; line-height: 1.6; font-weight: normal;margin-right: 20px;\">\n",
        "<ul>\n",
        "<li>An effective automatic traffic sign classification and recognition deep convolutional networks (2022) (Quello di Mattia)\n",
        "<a href=\"https://doi.org/10.1007/s11042-022-12531-w\">Link Paper</a>\n",
        "</li>\n",
        "<li>Multi-column deep neural network for traffic sign classification (2012) (Modello MCDNN)\n",
        "<a href=\"https://doi.org/10.1016/j.neunet.2012.02.023\">Link Paper</a>\n",
        "<br><a href=\"https://github.com/sixftninja/german-traffic-sign-detection/tree/master\">Link GitHub</a>\n",
        "</li>\n",
        "<li>A Low-cost and Ultra-lightweight Binary Neural Network for Traffic Signal Recognition (2025) (Modello BNN) (No GitHub)\n",
        "<a href=\"http://dx.doi.org/10.48550/arXiv.2501.07808\">Link Paper</a>\n",
        "</li>\n",
        "<li>Visual Trasformer (No Paper, solo codice)\n",
        "<a href=\"https://huggingface.co/kelvinandreas/vit-traffic-sign-GTSRB\">Link HuggingFace</a>\n",
        "</li>\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "<h2>Few-shot models used for the comparison</h2>\n",
        "<div style=\"text-align: justify; font-family: Arial; font-size: 15px; line-height: 1.6; font-weight: normal;margin-right: 20px;\">\n",
        "<ul>\n",
        "<li>(Quello nostro di Computer Vision) Clip encoder (<a href=\"https://doi.org/10.48550/arXiv.2103.00020\">Link Paper</a>) + LCD to calculate the noise (<a href=\"https://doi.org/10.48550/arXiv.2504.12104\">Link Paper</a>)\n",
        "</li>\n",
        "</ul>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# EVALUATION METRICS\n",
        "\n",
        "Possible evaluation metrics used in the papers above are:\n",
        "Ma precision e recall non sono per binary classification? Lo dovresti fare per ogni classe considerando tutte le altre classi come istanze negative?\n",
        "- Average precision (AP): area under the precision-recall curve\n",
        "- Precision\n",
        "- Recall\n",
        "- A sto punto anche F1 Score? Male non fa\n",
        "- Accuracy rate (consigliato al posto di error rate. più utilizzato in letteratura)\n",
        "-\n",
        "\n",
        "# EVALUATION TECHNIQUES FOR FEW SHOTS ALGORITHMS\n",
        "- <b>Bootstrap</b>\n",
        "- <b>Fine-Grained Image Classification</b>: si valutano e testano gruppi di classi alla volta in modo tale da identificare i gruppi più problematici (nel nostro caso il gruppo dei segnali stradali relativi ai limiti di velocità potrebbero essere piu difficili da classificare rispetto a quelli di pericolo). \"Fine-Grained Image Classification is a task in computer vision where the goal is to classify images into subcategories within a larger category. For example, classifying different species of birds or different types of flowers. This task is considered to be fine-grained because it requires the model to distinguish between subtle differences in visual appearance and patterns, making it more challenging than regular image classification tasks.\"(https://paperswithcode.com/task/fine-grained-image-classification)\n",
        "-<b>Generalization error</b>: How much does accuracy drop when we reduce K (e.g., from K=5 to K=1)?*\n",
        "- <b>Paper on few-shot evaluation techniques</b> https://arxiv.org/pdf/2307.02732\n",
        "\n",
        "# EVALUATION TECHNIQUES TO COMPARE THE FEW SHOT VS MANY-SHOT LEARNING\n",
        "- <b>Paired T-test</b>: Usiamo J dataset differenti per il traffic sign recgnition task (uno è quello tedesco, dobbiamo trovarne altri) e testiamo per ciascuno di essi il modello few-shot ed uno no-few shot. Per ottenere l'error rate per ciascun dataset possiamore usare l'holdout o cross-validation (meglio ques'ultimo perchè citato nel paper come migliore metodo di valutazione per modelli few-shot).\n",
        "1) Usiamo l'holdout assicurandoci di avere stesso identico test set per entrambi i modelli ma training set diverso (per il modello few-shot ovviamente abbiamo bisogno di meno sample rispetto a quello no few-shot).\n",
        "2) In alternativa all'holdout, possiamo usare una k-fold cross validation in questo modo: il numero e la suddivisione dei fold sono gli stessi per entrambi i modelli, tuttavia, ad ogni iterazione della cross validation, usiamo lo stesso test set per entrambi e, per il modello few-shot, anzichè usare tutte i rimanenti fold per il training set ne prendiamo solo una parte. Dato che il numero di sample per classe nel modello few-shot segue la potenza del 2(Y=2,4,8,16 tipicamente), allora dobbiamo fare in modo che ogni fold abbia Y*N(dove N è il numero delle label e Y il numero dei sample per label richiesto dal modello few-shot) con l'accortezza di averne almeno x=Y/2 che siano strutturati in modo tale da avere SOLTANTO Y istanze per ciascuna delle N label. Problema: cosi abbiamo pochi sample nel test set dato che i fold sono piccoli per venire incontro alle esigenze del modello few-shot (J*N sample in ciascun fold)...Soluzione: anzichè prendere un fold alla volta per il test set ne prendiamo tipo 3 (ovviamente ciò vale per entrambi i modelli). Quindi per il no few-shot prendiamo X fold per il test set e utilizziamo i restanti per il training set, mentre per il few-shot prendiamo sempre X fold per il test set e utilizziamo soltanto quelli che ci servono il training. \n",
        "\n",
        "\n",
        "- <b>Intervalli di confidenza</b> A parte dal t-test, per ogni confronto tra due algoritmi ci calcoliamo per entrambe il corrispondente intervallo di confidenza.\n",
        "- <b>Focus su few-shot</b> A parte dal t-test, testiamo anche il modello few-shot sui diversi gruppi di classi (fine-grained few shot) (no train, solo test) per identificare su quali gruppi il modello few-shot si comporta peggio.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVluDFxmA63f"
      },
      "source": [
        "# Nuova sezione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lew2aE4D5Nyk"
      },
      "source": [
        "<h2>Code used to create the random dataset:</h2>\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "def copy_random_images(p1, p2, num_images_per_folder=5):\n",
        "    \"\"\"\n",
        "    Copies random images from subfolders in p1 to p2, recreating the subfolder structure.\n",
        "\n",
        "    Args:\n",
        "        p1 (str): Source path containing subfolders with images.\n",
        "        p2 (str): Destination path where the subfolder structure and images will be recreated.\n",
        "        num_images_per_folder (int): Number of random images to copy from each subfolder.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(p1):\n",
        "        raise ValueError(f\"Source path '{p1}' does not exist.\")\n",
        "    \n",
        "    if not os.path.exists(p2):\n",
        "        os.makedirs(p2)\n",
        "\n",
        "    # Iterate through subfolders in p1\n",
        "    for subfolder in os.listdir(p1):\n",
        "        subfolder_path = os.path.join(p1, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            # Create the same subfolder in p2\n",
        "            dest_subfolder_path = os.path.join(p2, subfolder)\n",
        "            os.makedirs(dest_subfolder_path, exist_ok=True)\n",
        "\n",
        "            # Get all image files in the current subfolder\n",
        "            image_files = [f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))]\n",
        "            \n",
        "            # Select random images\n",
        "            random_images = random.sample(image_files, min(num_images_per_folder, len(image_files)))\n",
        "\n",
        "            # Copy selected images to the destination subfolder\n",
        "            for image in random_images:\n",
        "                src_image_path = os.path.join(subfolder_path, image)\n",
        "                dest_image_path = os.path.join(dest_subfolder_path, image)\n",
        "\n",
        "                # Open, resize, and save the image\n",
        "                with Image.open(src_image_path) as img:\n",
        "                    img = img.convert(\"RGB\")  # Ensure the image is in RGB format\n",
        "                    img = img.resize((32, 32))  # Resize to 32x32\n",
        "                    img.save(dest_image_path)\n",
        "\n",
        "            print(f\"Copied {len(random_images)} images from '{subfolder_path}' to '{dest_subfolder_path}'.\")\n",
        "\n",
        "p1 = \"ortiginal_images_folder\"\n",
        "p2 = \"destination_images_folder\"\n",
        "num_images_per_folder = 30\n",
        "\n",
        "arr=[\"/train\",\"/val\",\"/test\"]\n",
        "\n",
        "for a in arr:\n",
        "  copy_random_images(p1, p2, num_images_per_folder+a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQLHmo5PTSVe"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2> LOAD THE DATASETS </h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset, DatasetDict, Dataset as LoadDataset, Image,concatenate_datasets\n",
        "import pandas as pd\n",
        "import os\n",
        "import kagglehub\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from PIL import Image as ImagePil\n",
        "import gc\n",
        "from collections.abc import Iterator \n",
        "from typing import Optional\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(self, dataset_path, dataset_name, column_name_image, column_name_label):\n",
        "        \"\"\"Initialize a Dataset object\n",
        "        \n",
        "        Args:\n",
        "            dataset_path (str): path of the dataset\n",
        "            dataset_name (str): name of the dataset\n",
        "            column_name_image(str) the name of the column in which there are the images\n",
        "            column_name_label(str): the name of the column in which there are the labels\n",
        "        \"\"\"\n",
        "\n",
        "        # Inizializza gli attributi privati\n",
        "        self._dataset_path = None\n",
        "        self._dataset_name = None\n",
        "        self._column_name_image = None\n",
        "        self._column_name_label = None\n",
        "        self._pandas_dataset = None\n",
        "        \n",
        "        # Usa i setter per validazione\n",
        "        self.dataset_path = dataset_path\n",
        "        self.dataset_name = dataset_name\n",
        "        self.column_name_image = column_name_image\n",
        "        self.column_name_label = column_name_label\n",
        "        self.pandas_dataset = None\n",
        "\n",
        "\n",
        "   \n",
        "    # ---- Dataset Path ----\n",
        "    @property\n",
        "    def dataset_path(self) -> Optional[str]:\n",
        "        return self._dataset_path\n",
        "    \n",
        "    @dataset_path.setter\n",
        "    def dataset_path(self, value: str) -> None:\n",
        "        if not isinstance(value, str):\n",
        "            raise TypeError(\"dataset_path deve essere una stringa\")\n",
        "        self._dataset_path = value\n",
        "\n",
        "\n",
        "    # ---- Pandas dataset ----\n",
        "    @property\n",
        "    def pandas_dataset(self):\n",
        "        return self._pandas_dataset \n",
        "    \n",
        "    @pandas_dataset.setter\n",
        "    def pandas_dataset(self, value) -> None:\n",
        "        self._pandas_dataset = value  \n",
        "\n",
        "    # ---- Dataset Name ----\n",
        "    @property\n",
        "    def dataset_name(self) -> Optional[str]:\n",
        "        return self._dataset_name\n",
        "    \n",
        "    @dataset_name.setter\n",
        "    def dataset_name(self, value: str) -> None:\n",
        "        if not isinstance(value, str):\n",
        "            raise TypeError(\"dataset_name deve essere una stringa\")\n",
        "        if not value.strip():\n",
        "            raise ValueError(\"dataset_name non può essere vuoto\")\n",
        "        self._dataset_name = value\n",
        "\n",
        "    # ---- Image Column ----\n",
        "    @property\n",
        "    def column_name_image(self) -> Optional[str]:\n",
        "        return self._column_name_image\n",
        "    \n",
        "    @column_name_image.setter\n",
        "    def column_name_image(self, value: str) -> None:\n",
        "        if not isinstance(value, str):\n",
        "            raise TypeError(\"column_name_image deve essere una stringa\")\n",
        "        self._column_name_image = value\n",
        "\n",
        "    # ---- Label Column ----\n",
        "    @property\n",
        "    def column_name_label(self) -> Optional[str]:\n",
        "        return self._column_name_label\n",
        "    \n",
        "    @column_name_label.setter\n",
        "    def column_name_label(self, value: str) -> None:\n",
        "        if not isinstance(value, str):\n",
        "            raise TypeError(\"column_name_label deve essere una stringa\")\n",
        "        self._column_name_label = value\n",
        "    \n",
        "\n",
        "class LocalDataset(Dataset):\n",
        "    pass\n",
        "\n",
        "class HuggingFaceDataset(Dataset):\n",
        "    pass\n",
        "\n",
        "class KaggleDataset(Dataset):\n",
        "    def __init__(self, dataset_path, dataset_name, column_name_image, column_name_label, local_subpath):\n",
        "        \"\"\"Initialize a KaggleDataset object\n",
        "        \n",
        "        Args:\n",
        "            dataset_path (str): path of the dataset\n",
        "            dataset_name (str): name of the dataset\n",
        "            column_name_image(str) the name of the column in which there are the images\n",
        "            column_name_label(str): the name of the column in which there are the labels\n",
        "            local_subpath (str): subpath to use to find the actual directory containing the images\n",
        "        \"\"\"\n",
        "        super().__init__(dataset_path, dataset_name, column_name_image, column_name_label)\n",
        "        self._local_subpath = None  # Inizializza prima\n",
        "        self.local_subpath = local_subpath  # Poi usa il setter\n",
        "\n",
        "    @property\n",
        "    def local_subpath(self) -> Optional[str]:\n",
        "        return self._local_subpath\n",
        "    \n",
        "    @local_subpath.setter\n",
        "    def local_subpath(self, value: str) -> None:\n",
        "        if not isinstance(value, str):\n",
        "            raise TypeError(\"local_subpath deve essere una stringa\")\n",
        "        self._local_subpath = value\n",
        "\n",
        "\n",
        "class DatasetCollection:\n",
        "\n",
        "    kaggle_dataset_path = \"./dataset/Kaggle\"\n",
        "    hugging_face_dataset_local_path = \"./dataset/HuggingFace\"\n",
        "    templates = {\n",
        "            \"belgian_dataset\":[\n",
        "    # Class 0: Speed limit 30\n",
        "    \"A white circular sign with a red border, with the number '30' in the center.\",\n",
        "    # Class 1: Speed limit 50\n",
        "    \"A white circular sign with a red border, with the number '50' in the center.\",\n",
        "    # Class 2: Speed limit 70\n",
        "    \"A white circular sign with a red border, with the number '70' in the center.\",\n",
        "    # Class 3: Speed limit 80\n",
        "    \"A white circular sign with a red border, with the number '80' in the center.\",\n",
        "    # Class 4: No overtaking\n",
        "    \"A white circular sign with a red border, showing a red car and a black car side-by-side.\",\n",
        "    # Class 5: No overtaking for trucks\n",
        "    \"A white circular sign with a red border, showing a red truck and a black car side-by-side.\",\n",
        "    # Class 6: Priority road\n",
        "    \"A yellow, diamond-shaped sign with a white border.\",\n",
        "    # Class 7: End of priority road\n",
        "    \"A yellow, diamond-shaped sign with a white border, crossed out by a single black diagonal stripe.\",\n",
        "    # Class 8: Give way\n",
        "    \"An inverted triangular sign with a red border and a white background.\",\n",
        "    # Class 9: Stop\n",
        "    \"A red, octagonal sign with the word 'STOP' in white letters.\",\n",
        "    # Class 10: No entry for all vehicles\n",
        "    \"A plain white circular sign with a red border.\",\n",
        "    # Class 11: End of speed limit 30 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '30'.\",\n",
        "    # Class 12: End of speed limit 50 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '50'.\",\n",
        "    # Class 13: End of speed limit 70 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '70'.\",\n",
        "    # Class 14: End of speed limit 80 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '80'.\",\n",
        "    # Class 15: End of no overtaking\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing faded silhouettes of two cars.\",\n",
        "    # Class 16: End of no overtaking for trucks\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing faded silhouettes of a truck and a car.\",\n",
        "    # Class 17: Speed limit 90\n",
        "    \"A white circular sign with a red border, with the number '90' in the center.\",\n",
        "    # Class 18: Road works\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a person with a shovel.\",\n",
        "    # Class 19: Speed limit 60\n",
        "    \"A white circular sign with a red border, with the number '60' in the center.\",\n",
        "    # Class 20: Dangerous curve to the right\n",
        "    \"A triangular sign with a red border, showing a black arrow that curves to the right.\",\n",
        "    # Class 21: Dangerous curve to the left\n",
        "    \"A triangular sign with a red border, showing a black arrow that curves to the left.\",\n",
        "    # Class 22: General caution / Danger\n",
        "    \"A triangular sign with a red border, containing a black exclamation mark.\",\n",
        "    # Class 23: No entry\n",
        "    \"A red circular sign with a solid white horizontal bar across its center.\",\n",
        "    # Class 24: End of speed limit 60 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '60'.\",\n",
        "    # Class 25: End of speed limit 90 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '90'.\",\n",
        "    # Class 26: Speed limit 120\n",
        "    \"A white circular sign with a red border, with the number '120' in the center.\",\n",
        "    # Class 27: End of speed limit 120 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '120'.\",\n",
        "    # Class 28: Speed limit 40\n",
        "    \"A white circular sign with a red border, with the number '40' in the center.\",\n",
        "    # Class 29: End of speed limit 40 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '40'.\",\n",
        "    # Class 30: No left turn\n",
        "    \"A white circular sign with a red border, showing a black arrow turning left, crossed out by a red diagonal line.\",\n",
        "    # Class 31: No right turn\n",
        "    \"A white circular sign with a red border, showing a black arrow turning right, crossed out by a red diagonal line.\",\n",
        "    # Class 32: Bumpy road\n",
        "    \"A triangular sign with a red border, showing a single raised bump in a horizontal line.\",\n",
        "    # Class 33: Roundabout\n",
        "    \"A triangular sign with a red border, showing three black arrows forming a circle.\",\n",
        "    # Class 34: Slippery road\n",
        "    \"A triangular sign with a red border, showing a car silhouette with curving skid marks.\",\n",
        "    # Class 35: Road narrows\n",
        "    \"A triangular sign with a red border, showing two vertical lines curving inwards.\",\n",
        "    # Class 36: Pedestrian crossing\n",
        "    \"A triangular sign with a red border, featuring a silhouette of a person on a crosswalk.\",\n",
        "    # Class 37: Children crossing\n",
        "    \"A triangular sign with a red border, showing black silhouettes of two people, one larger and one smaller.\",\n",
        "    # Class 38: End of all prohibitions\n",
        "    \"A plain white circular sign with a single black diagonal stripe across it.\",\n",
        "    # Class 39: Ahead only\n",
        "    \"A blue circular sign with a white arrow pointing straight upwards.\",\n",
        "    # Class 40: Turn right ahead\n",
        "    \"A blue circular sign with a white arrow pointing to the right.\",\n",
        "    # Class 41: Turn left ahead\n",
        "    \"A blue circular sign with a white arrow pointing to the left.\",\n",
        "    # Class 42: No parking\n",
        "    \"A blue circular sign with a red border and a single red diagonal line.\",\n",
        "    # Class 43: Two-way traffic\n",
        "    \"A triangular sign with a red border, showing two black arrows pointing in opposite vertical directions.\",\n",
        "    # Class 44: Traffic signals ahead\n",
        "    \"A triangular sign with a red border, containing a symbol of a traffic light.\",\n",
        "    # Class 45: Go straight or right\n",
        "    \"A blue circular sign displaying two white arrows, one pointing up and one pointing to the right.\",\n",
        "    # Class 46: Bicycles crossing\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a bicycle.\",\n",
        "    # Class 47: Keep right\n",
        "    \"A blue circular sign with a white arrow pointing diagonally down and to the right.\",\n",
        "    # Class 48: Speed limit 20\n",
        "    \"A white circular sign with a red border, with the number '20' in the center.\",\n",
        "    # Class 49: Speed limit 100\n",
        "    \"A white circular sign with a red border, with the number '100' in the center.\",\n",
        "    # Class 50: End of speed limit 20 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '20'.\",\n",
        "    # Class 51: End of speed limit 100 zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '100'.\",\n",
        "    # Class 52: No U-turn\n",
        "    \"A white circular sign with a red border, showing a black U-shaped arrow, crossed out by a red diagonal line.\",\n",
        "    # Class 53: No stopping or parking\n",
        "    \"A blue circular sign with a red border and a red 'X' cross.\",\n",
        "    # Class 54: No entry for cyclists\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a bicycle.\",\n",
        "    # Class 55: No entry for pedestrians\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a person walking.\",\n",
        "    # Class 56: Mandatory roundabout\n",
        "    \"A blue circular sign with three white arrows forming a counter-clockwise circle.\",\n",
        "    # Class 57: End of built-up area\n",
        "    \"A white rectangular sign with a black silhouette of a city skyline, crossed out by a red diagonal line.\",\n",
        "    # Class 58: Beginning of built-up area\n",
        "    \"A white rectangular sign with a black silhouette of a city skyline.\",\n",
        "    # Class 59: Go straight or left\n",
        "    \"A blue circular sign showing two white arrows, one pointing straight ahead and the other to the left.\",\n",
        "    # Class 60: Keep left\n",
        "    \"A blue circular sign with a white arrow pointing diagonally down and to the left.\",\n",
        "    # Class 61: No entry for trucks\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a truck.\"\n",
        "            ],\n",
        "            \"russian_dataset\":[\n",
        "    # Class 0: 1.1_railroad_crossing_with_barrier\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a fence or gate.\",\n",
        "    # Class 1: 1.2_railroad_crossing_without_barrier\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a steam train.\",\n",
        "    # Class 2: 1.5_intersection_with_a_tram_line\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a tram.\",\n",
        "    # Class 3: 1.6_crossing_of_equivalent_roads\n",
        "    \"A triangular sign with a red border, showing a black cross symbol.\",\n",
        "    # Class 4: 1.8_traffic_lights\n",
        "    \"A triangular sign with a red border, containing a symbol of a traffic light.\",\n",
        "    # Class 5: 1.16_uneven_road\n",
        "    \"A triangular sign with a red border, showing two bumps in a horizontal line.\",\n",
        "    # Class 6: 1.17_road_bump\n",
        "    \"A triangular sign with a red border, showing a single raised bump in a horizontal line.\",\n",
        "    # Class 7: 1.19_slippery_road\n",
        "    \"A triangular sign with a red border, showing a car silhouette with curving skid marks.\",\n",
        "    # Class 8: 1.20_road_narrows\n",
        "    \"A triangular sign with a red border, showing two vertical lines curving inwards.\",\n",
        "    # Class 9: 1.22_pedestrian_crossing\n",
        "    \"A triangular sign with a red border, featuring a silhouette of a person on a crosswalk.\",\n",
        "    # Class 10: 1.23_children\n",
        "    \"A triangular sign with a red border, showing silhouettes of two running children.\",\n",
        "    # Class 11: 1.25_road_works\n",
        "    \"A yellow triangular sign with a red border, containing a black silhouette of a person with a shovel.\",\n",
        "    # Class 12: 1.30_wild_animals\n",
        "    \"A triangular sign with a red border, showing the silhouette of a leaping deer.\",\n",
        "    # Class 13: 1.34.1_direction_of_turn\n",
        "    \"A rectangular sign with a red background, showing thick white chevron arrows.\",\n",
        "    # Class 14: 1.34.2_direction_of_turn\n",
        "    \"A rectangular sign with a red background, showing thick white chevron arrows.\",\n",
        "    # Class 15: 1.34.3_direction_of_turn\n",
        "    \"A rectangular sign with a red background, showing thick white chevron arrows.\",\n",
        "    # Class 16: 2.1_main_road\n",
        "    \"A yellow, diamond-shaped sign with a white border.\",\n",
        "    # Class 17: 2.2_end_of_main_road\n",
        "    \"A yellow, diamond-shaped sign with a white border, crossed out by four thin black diagonal lines.\",\n",
        "    # Class 18: 2.4_yield\n",
        "    \"An inverted triangular sign with a red border and a white background.\",\n",
        "    # Class 19: 2.5_stop\n",
        "    \"A red, octagonal sign with the word 'СТОП' in white Cyrillic letters.\",\n",
        "    # Class 20: 2.7_advantage_for_oncoming_traffic\n",
        "    \"A white circular sign with a red border, showing a black arrow and a red arrow pointing in opposite directions.\",\n",
        "    # Class 21: 3.1_no_entry\n",
        "    \"A red circular sign with a solid white horizontal bar across its center.\",\n",
        "    # Class 22: 3.2_no_vehicles\n",
        "    \"A plain white circular sign with a red border.\",\n",
        "    # Class 23: 3.4_no_trucks\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a truck.\",\n",
        "    # Class 24: 3.11_weight_limit\n",
        "    \"A white circular sign with a red border, showing a number followed by 'т' (the Cyrillic letter for 't').\",\n",
        "    # Class 25: 3.12_axle_load_limit\n",
        "    \"A white circular sign with a red border, showing a number above a small icon of a vehicle axle.\",\n",
        "    # Class 26: 3.13_height_limit\n",
        "    \"A white circular sign with a red border, showing a number between two vertically pointing arrows.\",\n",
        "    # Class 27: 3.14_width_limit\n",
        "    \"A white circular sign with a red border, showing a number between two horizontally pointing arrows.\",\n",
        "    # Class 28: 3.16_length_limit\n",
        "    \"A white circular sign with a red border, showing a number next to a silhouette of a long vehicle.\",\n",
        "    # Class 29: 3.18.1_no_right_turn\n",
        "    \"A white circular sign with a red border, showing a black arrow turning right, crossed out by a red diagonal line.\",\n",
        "    # Class 30: 3.18.2_no_left_turn\n",
        "    \"A white circular sign with a red border, showing a black arrow turning left, crossed out by a red diagonal line.\",\n",
        "    # Class 31: 3.19_no_u_turn\n",
        "    \"A white circular sign with a red border, showing a black U-shaped arrow, crossed out by a red diagonal line.\",\n",
        "    # Class 32: 3.20_no_overtaking\n",
        "    \"A white circular sign with a red border, showing a red car and a black car side-by-side.\",\n",
        "    # Class 33: 3.21_end_of_no_overtaking_zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing faded silhouettes of two cars.\",\n",
        "    # Class 34: 3.24_speed_limit\n",
        "    \"A white circular sign with a red border, with a number in the center.\",\n",
        "    # Class 35: 3.25_end_of_speed_limit_zone\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number.\",\n",
        "    # Class 36: 3.27_no_stopping\n",
        "    \"A blue circular sign with a red border and a red 'X' cross.\",\n",
        "    # Class 37: 3.28_no_parking\n",
        "    \"A blue circular sign with a red border and a single red diagonal line.\",\n",
        "    # Class 38: 3.31_end_of_all_restrictions\n",
        "    \"A white circular sign with multiple thin black diagonal stripes.\",\n",
        "    # Class 39: 4.1.1_go_straight\n",
        "    \"A blue circular sign with a white arrow pointing straight upwards.\",\n",
        "    # Class 40: 4.1.2_go_right\n",
        "    \"A blue circular sign with a white arrow pointing to the right.\",\n",
        "    # Class 41: 4.1.3_go_left\n",
        "    \"A blue circular sign with a white arrow pointing to the left.\",\n",
        "    # Class 42: 4.1.4_go_straight_or_right\n",
        "    \"A blue circular sign displaying two white arrows, one pointing up and one pointing to the right.\",\n",
        "    # Class 43: 4.1.5_go_straight_or_left\n",
        "    \"A blue circular sign showing two white arrows, one pointing straight ahead and the other to the left.\",\n",
        "    # Class 44: 4.2.1_keep_right\n",
        "    \"A blue circular sign with a white arrow curving around an obstacle on the left.\",\n",
        "    # Class 45: 4.2.2_keep_left\n",
        "    \"A blue circular sign with a white arrow curving around an obstacle on the right.\",\n",
        "    # Class 46: 4.3_roundabout\n",
        "    \"A blue circular sign with three white arrows forming a counter-clockwise circle.\",\n",
        "    # Class 47: 5.5_one_way_road\n",
        "    \"A blue square sign with a thick, long white arrow pointing upwards.\",\n",
        "    # Class 48: 5.6_end_of_one_way_road\n",
        "    \"A blue square sign with a thick, long white arrow pointing upwards, crossed out by a red diagonal line.\",\n",
        "    # Class 49: 5.15.1_lane_directions\n",
        "    \"A blue rectangular sign with white arrows indicating permissible directions of travel from different lanes.\",\n",
        "    # Class 50: 5.15.2_lane_directions\n",
        "    \"A blue rectangular sign with white arrows indicating permissible directions of travel from different lanes.\",\n",
        "    # Class 51: 5.15.7_lane_directions\n",
        "    \"A blue square sign with white arrows showing lane directions.\",\n",
        "    # Class 52: 5.19.1_pedestrian_crossing\n",
        "    \"A blue square sign containing a white triangle with a silhouette of a person on a crosswalk.\",\n",
        "    # Class 53: 5.19.2_pedestrian_crossing\n",
        "    \"A blue square sign containing a white triangle with a silhouette of a person on a crosswalk.\",\n",
        "    # Class 54: 5.21_residential_area\n",
        "    \"A blue rectangular sign showing white silhouettes of a house, a car, and a person with a child.\",\n",
        "    # Class 55: 6.8.1_dead_end\n",
        "    \"A blue square sign with a white 'T' shape that has a thick red horizontal bar.\",\n",
        "    # Class 56: 8.22.1_obstacle\n",
        "    \"A rectangular white sign with diagonal black and white stripes pointing downwards.\",\n",
        "    # Class 57: 8.23_photo_and_video_recording\n",
        "    \"A rectangular white sign with a black silhouette of a camera.\"\n",
        "            ],\n",
        "            \"german_dataset\":[\n",
        "    # Class 0: Speed limit (20km/h)\n",
        "    \"A white circular sign with a red border, with the number '20' in the center.\",\n",
        "    # Class 1: Speed limit (30km/h)\n",
        "    \"A white circular sign with a red border, with the number '30' in the center.\",\n",
        "    # Class 2: Speed limit (50km/h)\n",
        "    \"A white circular sign with a red border, with the number '50' in the center.\",\n",
        "    # Class 3: Speed limit (60km/h)\n",
        "    \"A white circular sign with a red border, with the number '60' in the center.\",\n",
        "    # Class 4: Speed limit (70km/h)\n",
        "    \"A white circular sign with a red border, with the number '70' in the center.\",\n",
        "    # Class 5: Speed limit (80km/h)\n",
        "    \"A white circular sign with a red border, with the number '80' in the center.\",\n",
        "    # Class 6: End of speed limit (80km/h)\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing a faded number '80'.\",\n",
        "    # Class 7: Speed limit (100km/h)\n",
        "    \"A white circular sign with a red border, with the number '100' in the center.\",\n",
        "    # Class 8: Speed limit (120km/h)\n",
        "    \"A white circular sign with a red border, with the number '120' in the center.\",\n",
        "    # Class 9: No passing\n",
        "    \"A white circular sign with a red border, showing a red car and a black car side-by-side.\",\n",
        "    # Class 10: No passing for vehicles over 3.5 tons\n",
        "    \"A white circular sign with a red border, showing a red truck and a black car side-by-side.\",\n",
        "    # Class 11: Right-of-way at the next intersection\n",
        "    \"A triangular sign with a red border, showing a thick black vertical arrow intersected by a thinner horizontal line.\",\n",
        "    # Class 12: Priority road\n",
        "    \"A yellow, diamond-shaped sign with a white border.\",\n",
        "    # Class 13: Yield\n",
        "    \"An inverted triangular sign with a red border and a white background.\",\n",
        "    # Class 14: Stop\n",
        "    \"A red, octagonal sign with the word 'STOP' in white letters.\",\n",
        "    # Class 15: No vehicles\n",
        "    \"A plain white circular sign with a red border.\",\n",
        "    # Class 16: Vehicles over 3.5 tons prohibited\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a truck.\",\n",
        "    # Class 17: No entry\n",
        "    \"A red circular sign with a solid white horizontal bar across its center.\",\n",
        "    # Class 18: General caution\n",
        "    \"A triangular sign with a red border, containing a black exclamation mark.\",\n",
        "    # Class 19: Dangerous curve to the left\n",
        "    \"A triangular sign with a red border, showing a black arrow that curves to the left.\",\n",
        "    # Class 20: Dangerous curve to the right\n",
        "    \"A triangular sign with a red border, showing a black arrow that curves to the right.\",\n",
        "    # Class 21: Double curve\n",
        "    \"A triangular sign with a red border, displaying a black S-shaped line.\",\n",
        "    # Class 22: Bumpy road\n",
        "    \"A triangular sign with a red border, showing a single raised bump in a horizontal line.\",\n",
        "    # Class 23: Slippery road\n",
        "    \"A triangular sign with a red border, showing a car silhouette with curving skid marks.\",\n",
        "    # Class 24: Road narrows on the right\n",
        "    \"A triangular sign with a red border, showing a straight vertical line on the left and a curving line on the right.\",\n",
        "    # Class 25: Road work\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a person with a shovel.\",\n",
        "    # Class 26: Traffic signals\n",
        "    \"A triangular sign with a red border, containing a symbol of a traffic light.\",\n",
        "    # Class 27: Pedestrians\n",
        "    \"A triangular sign with a red border, featuring the silhouette of a person walking across a series of horizontal lines.\",\n",
        "    # Class 28: Children crossing\n",
        "    \"A triangular sign with a red border, showing black silhouettes of two people, one larger and one smaller.\",\n",
        "    # Class 29: Bicycles crossing\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a bicycle.\",\n",
        "    # Class 30: Beware of ice/snow\n",
        "    \"A triangular sign with a red border, containing a black snowflake symbol.\",\n",
        "    # Class 31: Wild animals crossing\n",
        "    \"A triangular sign with a red border, showing the silhouette of a leaping deer.\",\n",
        "    # Class 32: End of all speed and passing limits\n",
        "    \"A white circular sign with a single black diagonal stripe across it.\",\n",
        "    # Class 33: Turn right ahead\n",
        "    \"A blue circular sign with a white arrow pointing to the right.\",\n",
        "    # Class 34: Turn left ahead\n",
        "    \"A blue circular sign with a white arrow pointing to the left.\",\n",
        "    # Class 35: Ahead only\n",
        "    \"A blue circular sign with a white arrow pointing straight upwards.\",\n",
        "    # Class 36: Go straight or right\n",
        "    \"A blue circular sign displaying two white arrows, one pointing up and one pointing to the right.\",\n",
        "    # Class 37: Go straight or left\n",
        "    \"A blue circular sign showing two white arrows, one pointing straight ahead and the other to the left.\",\n",
        "    # Class 38: Keep right\n",
        "    \"A blue circular sign with a white arrow pointing diagonally down and to the right.\",\n",
        "    # Class 39: Keep left\n",
        "    \"A blue circular sign with a white arrow pointing diagonally down and to the left.\",\n",
        "    # Class 40: Roundabout mandatory\n",
        "    \"A blue circular sign with three white arrows forming a counter-clockwise circle.\",\n",
        "    # Class 41: End of no passing\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing faded silhouettes of two cars.\",\n",
        "    # Class 42: End of no passing by vehicles over 3.5 tons\n",
        "    \"A white circular sign with multiple black diagonal stripes, showing faded silhouettes of a truck and a car.\"\n",
        "            ],\n",
        "            \"chinese_dataset\":[\n",
        "    # Class 0: prohibitory_speed_limit_20\n",
        "    \"A white circular sign with a red border, with the number '20' in the center.\",\n",
        "    # Class 1: prohibitory_speed_limit_30\n",
        "    \"A white circular sign with a red border, with the number '30' in the center.\",\n",
        "    # Class 2: prohibitory_speed_limit_40\n",
        "    \"A white circular sign with a red border, with the number '40' in the center.\",\n",
        "    # Class 3: prohibitory_speed_limit_50\n",
        "    \"A white circular sign with a red border, with the number '50' in the center.\",\n",
        "    # Class 4: prohibitory_speed_limit_60\n",
        "    \"A white circular sign with a red border, with the number '60' in the center.\",\n",
        "    # Class 5: prohibitory_speed_limit_70\n",
        "    \"A white circular sign with a red border, with the number '70' in the center.\",\n",
        "    # Class 6: prohibitory_speed_limit_80\n",
        "    \"A white circular sign with a red border, with the number '80' in the center.\",\n",
        "    # Class 7: prohibitory_no_entry_for_motor_vehicles\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a car.\",\n",
        "    # Class 8: prohibitory_no_entry_for_hgvs\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a truck.\",\n",
        "    # Class 9: prohibitory_no_entry\n",
        "    \"A red circular sign with a solid white horizontal bar across its center.\",\n",
        "    # Class 10: prohibitory_no_honking\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a horn.\",\n",
        "    # Class 11: prohibitory_no_left_turn\n",
        "    \"A white circular sign with a red border, showing a black arrow turning left, crossed out by a red diagonal line.\",\n",
        "    # Class 12: prohibitory_no_right_turn\n",
        "    \"A white circular sign with a red border, showing a black arrow turning right, crossed out by a red diagonal line.\",\n",
        "    # Class 13: prohibitory_no_u_turn\n",
        "    \"A white circular sign with a red border, showing a black U-shaped arrow, crossed out by a red diagonal line.\",\n",
        "    # Class 14: prohibitory_no_overtaking\n",
        "    \"A white circular sign with a red border, showing a red car and a black car side-by-side.\",\n",
        "    # Class 15: prohibitory_no_parking\n",
        "    \"A blue circular sign with a red border and a single red diagonal line.\",\n",
        "    # Class 16: warning_crossroads\n",
        "    \"A triangular sign with a red border, showing a black cross symbol.\",\n",
        "    # Class 17: warning_narrow_road_both_sides\n",
        "    \"A triangular sign with a red border, showing two vertical lines curving inwards.\",\n",
        "    # Class 18: warning_narrow_road_right\n",
        "    \"A triangular sign with a red border, showing a straight vertical line on the left and a curving line on the right.\",\n",
        "    # Class 19: warning_rail_crossing_with_barriers\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a fence or gate.\",\n",
        "    # Class 20: warning_rail_crossing_without_barriers\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a steam train.\",\n",
        "    # Class 21: warning_attention\n",
        "    \"A triangular sign with a red border, containing a black exclamation mark.\",\n",
        "    # Class 22: warning_pedestrian\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a person walking.\",\n",
        "    # Class 23: warning_school\n",
        "    \"A triangular sign with a red border, showing black silhouettes of two people, one larger and one smaller.\",\n",
        "    # Class 24: warning_bicycles\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a bicycle.\",\n",
        "    # Class s25: warning_road_works\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a person with a shovel.\",\n",
        "    # Class 26: warning_traffic_lights\n",
        "    \"A triangular sign with a red border, containing a symbol of a traffic light with red, yellow, and green circles.\",\n",
        "    # Class 27: warning_sharp_curve_to_the_left\n",
        "    \"A triangular sign with a red border, showing a black arrow that sharply curves to the left.\",\n",
        "    # Class 28: warning_sharp_curve_to_the_right\n",
        "    \"A triangular sign with a red border, showing a black arrow that sharply curves to the right.\",\n",
        "    # Class 29: warning_winding_road\n",
        "    \"A triangular sign with a red border, displaying a black S-shaped line.\",\n",
        "    # Class 30: warning_steep_ascent\n",
        "    \"A triangular sign with a red border, showing a car silhouette on an upward slope.\",\n",
        "    # Class 31: warning_steep_descent\n",
        "    \"A triangular sign with a red border, showing a car silhouette on a downward slope.\",\n",
        "    # Class 32: warning_uneven_road\n",
        "    \"A triangular sign with a red border, showing two bumps in a horizontal line.\",\n",
        "    # Class 33: warning_hump_bridge\n",
        "    \"A triangular sign with a red border, showing a single raised bump in a horizontal line.\",\n",
        "    # Class 34: warning_village\n",
        "    \"A triangular sign with a red border, showing a silhouette of several buildings.\",\n",
        "    # Class 35: warning_falling_rocks\n",
        "    \"A triangular sign with a red border, showing rocks falling from a cliff on one side.\",\n",
        "    # Class 36: warning_side_wind\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a windsock.\",\n",
        "    # Class 37: warning_unprotected_quayside\n",
        "    \"A triangular sign with a red border, showing a car silhouette falling off a ledge into water.\",\n",
        "    # Class 38: warning_tunnel\n",
        "    \"A triangular sign with a red border, showing a black silhouette of a tunnel entrance.\",\n",
        "    # Class 39: warning_domestic_animals\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a cow.\",\n",
        "    # Class 40: warning_slow\n",
        "    \"A triangular sign with a red border, containing Chinese characters.\",\n",
        "    # Class 41: mandatory_turn_left\n",
        "    \"A blue circular sign with a white arrow pointing to the left.\",\n",
        "    # Class 42: mandatory_turn_right\n",
        "    \"A blue circular sign with a white arrow pointing to the right.\",\n",
        "    # Class 43: mandatory_go_straight\n",
        "    \"A blue circular sign with a white arrow pointing straight upwards.\",\n",
        "    # Class 44: mandatory_go_straight_or_turn_left\n",
        "    \"A blue circular sign showing two white arrows, one pointing straight ahead and the other to the left.\",\n",
        "    # Class 45: mandatory_go_straight_or_turn_right\n",
        "    \"A blue circular sign showing two white arrows, one pointing straight ahead and the other to the right.\",\n",
        "    # Class 46: mandatory_keep_left\n",
        "    \"A blue circular sign with a white arrow pointing diagonally down and to the left.\",\n",
        "    # Class 47: mandatory_keep_right\n",
        "    \"A blue circular sign with a white arrow pointing diagonally down and to the right.\",\n",
        "    # Class 48: mandatory_roundabout\n",
        "    \"A blue circular sign with three white arrows forming a counter-clockwise circle.\",\n",
        "    # Class 49: mandatory_end_of_no_overtaking\n",
        "    \"A white circular sign with a black diagonal stripe, showing faded silhouettes of two cars.\",\n",
        "    # Class 50: mandatory_horn\n",
        "    \"A blue circular sign with a white silhouette of a horn.\",\n",
        "    # Class 51: mandatory_bicycle_lane\n",
        "    \"A blue circular sign with a white silhouette of a bicycle.\",\n",
        "    # Class 52: mandatory_speed_limit_40\n",
        "    \"A blue circular sign with the number '40' in white.\",\n",
        "    # Class 53: mandatory_speed_limit_50\n",
        "    \"A blue circular sign with the number '50' in white.\",\n",
        "    # Class 54: mandatory_speed_limit_60\n",
        "    \"A blue circular sign with the number '60' in white.\",\n",
        "    # Class 55: other_stop\n",
        "    \"A red, octagonal sign with white characters.\",\n",
        "    # Class 56: other_parking\n",
        "    \"A square blue sign with a large white letter 'P' and other symbols or characters.\",\n",
        "    # Class 57: other_give_way\n",
        "    \"An inverted triangular sign with a red border, a white background, and black characters.\"\n",
        "            ],\n",
        "            \"indian_dataset\":[\n",
        "    # ClassId 0\n",
        "    \"An inverted triangular sign with a red border and a white background.\",\n",
        "    # ClassId 1\n",
        "    \"A red circular sign with a solid white horizontal bar across its center.\",\n",
        "    # ClassId 2\n",
        "    \"A rectangular blue sign with a large white arrow pointing in one direction.\",\n",
        "    # ClassId 3\n",
        "    \"A rectangular blue sign with a large white arrow pointing in one direction.\",\n",
        "    # ClassId 4\n",
        "    \"A plain white circular sign with a red border.\",\n",
        "    # ClassId 5\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a bicycle.\",\n",
        "    # ClassId 6\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a truck.\",\n",
        "    # ClassId 7\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a person walking.\",\n",
        "    # ClassId 8\n",
        "    \"A white circular sign with a red border, containing a black silhouette of an animal-drawn cart.\",\n",
        "    # ClassId 9\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a person pushing a cart.\",\n",
        "    # ClassId 10\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a car.\",\n",
        "    # ClassId 11\n",
        "    \"A white circular sign with a red border, showing a number between two vertically pointing arrows.\",\n",
        "    # ClassId 12\n",
        "    \"A white circular sign with a red border, showing a number followed by 't' for tonnes.\",\n",
        "    # ClassId 13\n",
        "    \"A white circular sign with a red border, showing a number above a small icon of a vehicle axle.\",\n",
        "    # ClassId 14\n",
        "    \"A white circular sign with a red border, showing a number next to a silhouette of a long vehicle.\",\n",
        "    # ClassId 15\n",
        "    \"A white circular sign with a red border, showing a black arrow turning left, crossed out by a red diagonal line.\",\n",
        "    # ClassId 16\n",
        "    \"A white circular sign with a red border, showing a black arrow turning right, crossed out by a red diagonal line.\",\n",
        "    # ClassId 17\n",
        "    \"A white circular sign with a red border, showing a red car and a black car side-by-side.\",\n",
        "    # ClassId 18\n",
        "    \"A white circular sign with a red border, with the number '90' in the center.\",\n",
        "    # ClassId 19\n",
        "    \"A white circular sign with a red border, with the number '110' in the center.\",\n",
        "    # ClassId 20\n",
        "    \"A white circular sign with a red border, containing a black silhouette of a horn.\",\n",
        "    # ClassId 21\n",
        "    \"A blue circular sign with a red border and a single red diagonal line.\",\n",
        "    # ClassId 22\n",
        "    \"A blue circular sign with a red border and a red 'X' cross.\",\n",
        "    # ClassId 23\n",
        "    \"A blue circular sign with a white arrow pointing to the left.\",\n",
        "    # ClassId 24\n",
        "    \"A blue circular sign with a white arrow pointing to the right.\",\n",
        "    # ClassId 25\n",
        "    \"A triangular sign with a red border, showing a car silhouette on a downward slope with a percentage.\",\n",
        "    # ClassId 26\n",
        "    \"A triangular sign with a red border, showing a car silhouette on an upward slope with a percentage.\",\n",
        "    # ClassId 27\n",
        "    \"A triangular sign with a red border, showing two vertical lines curving inwards.\",\n",
        "    # ClassId 28\n",
        "    \"A triangular sign with a red border, showing two vertical lines that narrow in the middle.\",\n",
        "    # ClassId 29\n",
        "    \"A triangular sign with a red border, showing a car silhouette falling off a ledge into water.\",\n",
        "    # ClassId 30\n",
        "    \"A triangular sign with a red border, showing a single raised bump in a horizontal line.\",\n",
        "    # ClassId 31\n",
        "    \"A triangular sign with a red border, showing a single dip in a horizontal line.\",\n",
        "    # ClassId 32\n",
        "    \"A triangular sign with a red border, showing a car silhouette with small specks flying from a tire.\",\n",
        "    # ClassId 33\n",
        "    \"A triangular sign with a red border, showing rocks falling from a cliff on one side.\",\n",
        "    # ClassId 34\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a cow.\",\n",
        "    # ClassId 35\n",
        "    \"A triangular sign with a red border, showing a black cross symbol.\",\n",
        "    # ClassId 36\n",
        "    \"A triangular sign with a red border, showing a main vertical line with a smaller line joining from one side.\",\n",
        "    # ClassId 37\n",
        "    \"A triangular sign with a red border, showing a main vertical line with a smaller line joining from one side.\",\n",
        "    # ClassId 38\n",
        "    \"A triangular sign with a red border, showing a main vertical line with a smaller diagonal line joining from one side.\",\n",
        "    # ClassId 39\n",
        "    \"A triangular sign with a red border, showing a main vertical line with a smaller diagonal line joining from one side.\",\n",
        "    # ClassId 40\n",
        "    \"A triangular sign with a red border, showing a vertical line ending at a horizontal line, forming a 'T' shape.\",\n",
        "    # ClassId 41\n",
        "    \"A triangular sign with a red border, showing a black 'Y' shape.\",\n",
        "    # ClassId 42\n",
        "    \"A triangular sign with a red border, showing a vertical line with two offset horizontal lines joining from opposite sides.\",\n",
        "    # ClassId 43\n",
        "    \"A triangular sign with a red border, showing a vertical line with two offset horizontal lines joining from opposite sides.\",\n",
        "    # ClassId 44\n",
        "    \"A triangular sign with a red border, showing three arrows forming a circle.\",\n",
        "    # ClassId 45\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a fence or gate.\",\n",
        "    # ClassId 46\n",
        "    \"A triangular sign with a red border, containing a black silhouette of a steam train.\",\n",
        "    # ClassId 47\n",
        "    \"A rectangular sign with three diagonal red stripes.\",\n",
        "    # ClassId 48\n",
        "    \"A rectangular sign with two diagonal red stripes.\",\n",
        "    # ClassId 49\n",
        "    \"A rectangular sign with one diagonal red stripe.\",\n",
        "    # ClassId 50\n",
        "    \"A rectangular sign with diagonal red stripes.\",\n",
        "    # ClassId 51\n",
        "    \"A square blue sign with a large white letter 'P'.\",\n",
        "    # ClassId 52\n",
        "    \"A square blue sign with a white silhouette of a bus.\",\n",
        "    # ClassId 53\n",
        "    \"A square blue sign with a white first aid symbol (often a cross).\",\n",
        "    # ClassId 54\n",
        "    \"A square blue sign with a white silhouette of a telephone receiver.\",\n",
        "    # ClassId 55\n",
        "    \"A square blue sign with a white silhouette of a fuel pump.\",\n",
        "    # ClassId 56\n",
        "    \"A square blue sign with a white silhouette of a person sleeping in a bed.\",\n",
        "    # ClassId 57\n",
        "    \"A square blue sign with a white silhouette of a knife and fork.\",\n",
        "    # ClassId 58\n",
        "    \"A square blue sign with a white silhouette of a cup and saucer.\"\n",
        "            ],\n",
        "            \"bangladesh_dataset\":[\n",
        "    # First batch\n",
        "    \"A speed limit sign indicating a maximum speed of 20.\",\n",
        "    \"A 30 speed limit sign with a red circular border.\",\n",
        "    \"A blue, circular road sign with the number 50, indicating a minimum speed limit.\",\n",
        "    \"A road sign showing a speed limit of 60.\",\n",
        "    \"A road sign indicating a 70 speed limit.\",\n",
        "    # Second batch\n",
        "    \"A road sign indicating a maximum speed limit of 80.\",\n",
        "    \"A sign indicating the end of a 20 speed limit zone.\",\n",
        "    \"A prohibitory road sign with a red circular border and a green symbol inside.\",\n",
        "    \"A road sign indicating the end of a no-overtaking restriction.\",\n",
        "    \"A \\\"No overtaking\\\" road sign.\",\n",
        "    \"A road sign prohibiting overtaking by heavy goods vehicles.\",\n",
        "    \"A triangular warning sign for a priority crossroads ahead.\",\n",
        "    \"A yellow, diamond-shaped priority road sign.\",\n",
        "    \"An inverted triangular \\\"Give Way\\\" or \\\"Yield\\\" sign.\",\n",
        "    \"A red, octagonal stop sign.\",\n",
        "    \"A \\\"No vehicles\\\" sign, which is a white circle with a red border.\",\n",
        "    \"A road sign prohibiting entry for trucks.\",\n",
        "    \"A circular red \\\"No Entry\\\" sign with a white horizontal bar.\",\n",
        "    \"A triangular warning sign with an exclamation mark, indicating a general hazard.\",\n",
        "    # Third batch (visual descriptions)\n",
        "    \"A triangular sign with a red border, showing a black arrow that curves to the left.\",\n",
        "    \"A triangular road sign with a red border, featuring a black arrow that curves to the right.\",\n",
        "    \"A triangular sign with a red border, displaying a black S-shaped line.\",\n",
        "    \"A triangular sign with a red border, showing the black silhouettes of two cars side-by-side.\",\n",
        "    \"A triangular road sign with a red border, depicting a black car silhouette on a bumpy line.\",\n",
        "    \"A triangular sign with a red border, featuring the silhouette of a person walking across a series of horizontal lines.\",\n",
        "    \"A triangular road sign with a red border, showing the black silhouettes of two people, one larger and one smaller.\",\n",
        "    \"A triangular sign with a red border, containing a symbol of a traffic light with red, yellow, and green circles.\",\n",
        "    \"A triangular road sign with a red border, displaying the black silhouette of a person walking.\",\n",
        "    \"A triangular sign with a red border, showing the black silhouette of a bicycle.\",\n",
        "    \"A triangular road sign with a red border, featuring the black silhouette of a farm tractor.\",\n",
        "    \"A triangular sign with a red border, containing a black snowflake symbol.\",\n",
        "    \"A triangular road sign with a red border, showing the silhouette of a leaping deer.\",\n",
        "    \"A white circular sign with a single black diagonal stripe across it.\",\n",
        "    \"A blue circular sign with a white arrow that curves to the right.\",\n",
        "    \"A blue circular sign containing a white arrow that points to the left.\",\n",
        "    \"A blue circular sign with a white arrow pointing straight upwards.\",\n",
        "    \"A blue circular sign displaying two white arrows, one pointing up and one pointing to the right.\",\n",
        "    \"A blue circular sign showing two white arrows, one pointing straight ahead and the other to the left.\",\n",
        "    \"A blue circular sign with a white arrow pointing diagonally downwards and to the right.\",\n",
        "    \"A blue circular sign featuring a white arrow that points diagonally down and to the left.\",\n",
        "    \"A blue circular sign with three white arrows forming a counter-clockwise circle.\",\n",
        "    \"A white circular sign with a red border and a blue background, divided by a single red diagonal line.\",\n",
        "    \"A dark, circular object, possibly a sign, with a thin vertical line through its center.\"\n",
        "            ],\n",
        "            \"persian_dataset\":[\n",
        "    # 0-9\n",
        "    \"Blue circular sign with two white arrows pointing left and right\",                         # 0_Compulsory Keep BothSide\n",
        "    \"Blue round sign with a thick white arrow bending left\",                                    # 1_Compulsory Keep Left\n",
        "    \"Blue circular sign with a thick white arrow bending right\",                                # 2_Compulsory Keep Right\n",
        "    \"Red-edged triangle with a black bicycle symbol inside\",                                    # 3_Cycle crossing\n",
        "    \"Red triangular warning sign with an exclamation mark in the center\",                       # 4_Danger\n",
        "    \"Inverted red-and-white triangle pointing downward\",                                        # 5_Give Way\n",
        "    \"Red-bordered triangle depicting a black hump or bump graphic\",                             # 6_Hump\n",
        "    \"Triangular warning sign with a black left-curving arrow\",                                  # 7_Left Bend\n",
        "    \"Blue rectangle with a white arrow pointing to the left edge\",                              # 8_Left Margin\n",
        "    \"Red circle with a black left-turn arrow struck through by a red line\",                     # 9_Left Turn Prohibited\n",
        "\n",
        "    # 10-19\n",
        "    \"Red-bordered white circle with '30' in bold black digits\",                                 # 10_Maximum Speed 30\n",
        "    \"White circular sign edged in red, displaying '40' in large black font\",                    # 11_Maximum Speed 40\n",
        "    \"Round white sign with a red border and the number '50' centered\",                          # 12_Maximum Speed 50\n",
        "    \"Red-outlined white disc featuring '60' in thick black numerals\",                           # 13_Maximum Speed 60\n",
        "    \"Circular white background, red border, and '70' prominently printed\",                      # 14_Maximum Speed 70\n",
        "    \"White speed limit sign with a red rim and '80' in bold\",                                   # 15_Maximum Speed 80\n",
        "    \"Red-rimmed white circle showcasing '90' in large black type\",                              # 16_Maximum Speed 90\n",
        "    \"Red-banned symbol over a black motorcycle silhouette on white\",                            # 17_MotorCycle Prohibited\n",
        "    \"Red circle with a solid white horizontal bar in the center\",                               # 18_No Entry\n",
        "    \"Blue circle crossed by a red diagonal line over a black horn symbol\",                      # 19_No Horn\n",
        "\n",
        "    # 20-29\n",
        "    \"Red circle with a blue background and a red 'X' over a parked car\",                        # 20_NO Stopping\n",
        "    \"Red-bordered white circle showing two parked cars crossed by a red line\",                  # 21_NO Waiting\n",
        "    \"Rectangular blue sign with a large white arrow pointing right or left\",                    # 22_One way Traffic\n",
        "    \"Blue square sign with a white 'P' in the center\",                                          # 23_Park\n",
        "    \"Red circle with a blue interior and a red slash over a parked car\",                        # 24_Park Forbidden\n",
        "    \"Blue square with a white silhouette of a walking figure\",                                  # 25_Pedestrain\n",
        "    \"Triangular red-bordered sign with a black walking person symbol\",                          # 26_Pedestrian crossing\n",
        "    \"Red triangular warning sign with a bold black right-curving arrow\",                        # 27_Right Bend\n",
        "    \"Blue rectangular sign with a white arrow pointing to the right edge\",                      # 28_Right Margin\n",
        "    \"Red circle with a black right-turn arrow crossed by a red line\",                           # 29_Right Turn Prohibited\n",
        "\n",
        "    # 30-39\n",
        "    \"Orange diamond-shaped sign with a black worker digging symbol\",                            # 30_Road Work\n",
        "    \"Triangular red-bordered sign with three circular arrows\",                                  # 31_Roundabouts\n",
        "    \"Yellow diamond-shaped sign with two black child figures walking\",                           # 32_School\n",
        "    \"Pentagonal yellow sign with a black silhouette of children crossing\",                      # 33_School Crossing\n",
        "    \"Red triangle with a black 'T' symbol and a right-side branch\",                             # 34_Side Road Right\n",
        "    \"Red triangular sign with 'SLOW' in bold black letters\",                                    # 35_Slow\n",
        "    \"White rectangle with a black camera icon and speed limit text\",                            # 36_Speed Camera\n",
        "    \"Red octagon with 'STOP' in bold white uppercase letters\",                                  # 37_STOP\n",
        "    \"Red circle with a black truck symbol crossed by a red line\",                               # 38_Truck Prohibited\n",
        "    \"Rectangular blue sign with opposing white horizontal arrows\",                              # 39_Two Way Traffic\n",
        "\n",
        "    # 40-42\n",
        "    \"Blue square sign with a white U-shaped arrow\",                                             # 40_U-Turn\n",
        "    \"White circular sign with a blue U-turn arrow symbol\",                                      # 41_U-Turn Allowed\n",
        "    \"Red circle with a black U-turn arrow crossed by a red slash\"                               # 42_U-turn Prohibited\n",
        "            ],\n",
        "        }\n",
        "\n",
        "\n",
        "    def __init__(self, kaggle_datasets, hugging_face_datasets, local_datasets):\n",
        "        \"\"\"Initialize a DatasetCollection object\n",
        "        \n",
        "        Args:\n",
        "            kaggle_datasets (List<KaggleDataset>): list of kaggle datasets.\n",
        "            hugging_face_datasets (List<HuggingFaceDataset>): list of hugging face datasets.\n",
        "            local_datasets (List<LocalDataset>): list of local datasets.\n",
        "        \"\"\"\n",
        "\n",
        "        self.kaggle_datasets = kaggle_datasets\n",
        "        self.hugging_face_datasets = hugging_face_datasets\n",
        "        self.local_datasets = local_datasets\n",
        "\n",
        "\n",
        "    def stream_all(self) -> Iterator:\n",
        "        \"\"\"Unified generator\"\"\"\n",
        "        yield from self.stream_kaggle()\n",
        "        yield from self.stream_hugging_face()\n",
        "        yield from self.stream_local()\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "    def stream_kaggle(self) -> Iterator:\n",
        "        \"\"\"\n",
        "        Generator that serves one kaggle dataset at a time\n",
        "        and cleans memory after each rendering\n",
        "        \"\"\"\n",
        "        for dataset in self.kaggle_datasets:  \n",
        "            try:\n",
        "                dataset_loaded = self._load_kaggle_dataset(dataset)\n",
        "                yield dataset_loaded  \n",
        "            finally:\n",
        "                del dataset_loaded      # Explicitly remove the reference\n",
        "                self._cleanup()  # Force the garbage collection\n",
        "\n",
        "\n",
        "    def stream_hugging_face(self) -> Iterator:\n",
        "        \"\"\"\n",
        "        Generator that serves one Hugging Face dataset at a time\n",
        "        and cleans memory after each rendering\n",
        "        \"\"\"\n",
        "        for dataset in self.hugging_face_datasets:  \n",
        "            try:\n",
        "                dataset_loaded = self._load_hugging_face_dataset(dataset)\n",
        "                yield dataset_loaded  \n",
        "            finally:\n",
        "                del dataset_loaded      # Explicitly remove the reference\n",
        "                self._cleanup()  # Force the garbage collection\n",
        "\n",
        "\n",
        "    def stream_local(self) -> Iterator:\n",
        "        \"\"\"\n",
        "        Generator that serves one local dataset at a time\n",
        "        and cleans memory after each rendering\n",
        "        \"\"\"\n",
        "        for dataset in self.local_datasets:  \n",
        "            try:\n",
        "                dataset_loaded = self._load_local_dataset(dataset)\n",
        "                yield dataset_loaded  \n",
        "            finally:\n",
        "                del dataset_loaded      # Explicitly remove the reference\n",
        "                self._cleanup()  # Force the garbage collection\n",
        "\n",
        "\n",
        "    def _cleanup(self) -> None:\n",
        "        \"\"\"\n",
        "        Pulisce la memoria in modo aggressivo\n",
        "        \"\"\"\n",
        "        gc.collect()  # Forza la garbage collection\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def _load_split_images(self, split_folder):\n",
        "        image_paths = []\n",
        "        labels = []\n",
        "        \n",
        "        for label in os.listdir(split_folder):\n",
        "            label_folder = os.path.join(split_folder, label)\n",
        "            if os.path.isdir(label_folder):\n",
        "                for file in os.listdir(label_folder):\n",
        "                    if file.lower().endswith(('.ppm','.png','.jpg')):\n",
        "                        image_paths.append(os.path.join(label_folder, file))\n",
        "                        labels.append(label)\n",
        "        \n",
        "        return {\"image\": image_paths, \"label\": labels}\n",
        "\n",
        "\n",
        "\n",
        "    def _load_kaggle_dataset(self, kaggle_dataset):\n",
        "        \"\"\"\n",
        "        Return a loaded kaggle dataset given the path\n",
        "        \"\"\"\n",
        "        print(\"Processing the Kaggle dataset: \" + kaggle_dataset.dataset_name)\n",
        "        dataset_desired_path = os.path.join(self.kaggle_dataset_path, kaggle_dataset.dataset_name)\n",
        "        if not os.path.exists(dataset_desired_path):\n",
        "            dataset_default_path = kagglehub.dataset_download(kaggle_dataset.dataset_path)\n",
        "            shutil.move(dataset_default_path, dataset_desired_path)\n",
        "        complete_path = os.path.join(dataset_desired_path, kaggle_dataset.local_subpath)\n",
        "        dataset_loaded = self._load_split_images(complete_path)\n",
        "        dataset_loaded = DatasetDict({\n",
        "            \"train\": LoadDataset.from_dict(dataset_loaded).cast_column(\"image\", Image())\n",
        "        })\n",
        "        dataset = self._filter_dataset(kaggle_dataset,dataset_loaded)\n",
        "        kaggle_dataset.pandas_dataset = dataset\n",
        "        del dataset\n",
        "        del dataset_loaded\n",
        "        return kaggle_dataset\n",
        "\n",
        "\n",
        "    def _load_hugging_face_dataset(self, hugging_face_dataset):\n",
        "        \"\"\"\n",
        "        Return a loaded Hugging Face dataset given the path\n",
        "        \"\"\"\n",
        "        print(\"Processing the Hugging Face dataset: \" + hugging_face_dataset.dataset_name)\n",
        "        dataset_desired_path = os.path.join(self.hugging_face_dataset_local_path, hugging_face_dataset.dataset_name)\n",
        "        dataset_loaded = load_dataset(hugging_face_dataset.dataset_path, cache_dir=dataset_desired_path)\n",
        "        dataset = self._filter_dataset(hugging_face_dataset, dataset_loaded)\n",
        "        hugging_face_dataset.pandas_dataset = dataset\n",
        "        del dataset\n",
        "        del dataset_loaded\n",
        "        return hugging_face_dataset\n",
        "    \n",
        "\n",
        "    def _load_local_dataset(self, local_dataset):\n",
        "        \"\"\"\n",
        "        Return a loaded local dataset given the path\n",
        "        \"\"\"\n",
        "        print(\"Processing the local dataset: \" + local_dataset.dataset_name)\n",
        "        # Load Belgian Traffic Sign Dataset\n",
        "        dataset_loaded_train = self._load_split_images(os.path.join(local_dataset.dataset_path,\"train\"))\n",
        "        dataset_loaded_test = self._load_split_images(os.path.join(local_dataset.dataset_path,\"test\"))\n",
        "        dataset_loaded = DatasetDict({\n",
        "            \"train\": LoadDataset.from_dict(dataset_loaded_train).cast_column(\"image\", Image()),\n",
        "            \"test\": LoadDataset.from_dict(dataset_loaded_test).cast_column(\"image\", Image())\n",
        "        })\n",
        "        dataset = self._filter_dataset(local_dataset, dataset_loaded)\n",
        "        local_dataset.pandas_dataset = dataset\n",
        "        del dataset\n",
        "        del dataset_loaded\n",
        "        return local_dataset\n",
        "    \n",
        "    def _filter_dataset(self, dataset, dataset_loaded):\n",
        "        \"\"\"\n",
        "        Filter the given dataset removing the labels that have few instances and transform the dataset into a pandas dataframe.\n",
        "        \"\"\"\n",
        "        if \"test\" in dataset_loaded.keys():\n",
        "            dataset_loaded=concatenate_datasets([dataset_loaded[\"train\"], dataset_loaded[\"test\"]])\n",
        "        else:\n",
        "            dataset_loaded = dataset_loaded['train']\n",
        "\n",
        "        df=dataset_loaded.to_pandas()\n",
        "\n",
        "        # Rename the image and label column with the column \"image\" and \"label\"\n",
        "        df.rename(columns={dataset.column_name_image:\"image\", dataset.column_name_label:\"label\"},inplace=True)\n",
        "        \n",
        "        # Get label frequencies (number of samples for each label)\n",
        "        label_frequencies = [(i,df[df[\"label\"]==i].shape[0]) for i in df[\"label\"].unique()]\n",
        "\n",
        "        # Remove labels with less than 20 samples\n",
        "        df_filtered = df[df[\"label\"].isin([i[0] for i in label_frequencies if i[1] >= 20])]\n",
        "        \n",
        "        # Convert str lables in int\n",
        "        all_labels = df_filtered[\"label\"].unique()\n",
        "        mapping_labels = {label: i for i, label in enumerate(all_labels)}\n",
        "        df_filtered[\"label\"]  = [mapping_labels[i] for i in df_filtered[\"label\"]]\n",
        "        \n",
        "        for ind, img in enumerate(tqdm(df_filtered[\"image\"], desc=\"Processing images\")):\n",
        "            if img['bytes'] is None:\n",
        "                img['bytes'] = open(img[\"path\"],\"rb\").read()\n",
        "\n",
        "        print(\"Number of filtered labels: \", df_filtered[\"label\"].nunique())\n",
        "        print(\"Number of removed labels: \",df[dataset.column_name_label].nunique()-df_filtered[\"label\"].nunique())\n",
        "        print(\"Number of samples in the dataset: \",df_filtered.shape[0])\n",
        "\n",
        "        return df_filtered\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import PIL.Image as ImagePIL\n",
        "import io\n",
        "import torch\n",
        "from torch.utils.data import Dataset as DatasetTorch\n",
        "\n",
        "class PandasDataset(DatasetTorch):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        \"\"\"\n",
        "        Own class to represent the datasets used in the experimentation\n",
        "        \"\"\"\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.num_classes = dataframe[\"label\"].nunique()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if isinstance(idx, torch.Tensor):\n",
        "            idx = idx.item() \n",
        "\n",
        "        image = ImagePIL.open(io.BytesIO(self.dataframe.iloc[idx]['image'][\"bytes\"])).convert(\"RGB\")\n",
        "        label = self.dataframe.iloc[idx]['label']\n",
        "\n",
        "        # Applica le trasformazioni\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzVHtTVx3K1m"
      },
      "source": [
        "<h2>Few-shot models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "5s1agHQX7gNa",
        "outputId": "cbf48c73-777a-4eec-f5b5-4a4f74a892f3"
      },
      "outputs": [],
      "source": [
        "from ldc_train import *\n",
        "import os\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "class FewShotDataset(PandasDataset):\n",
        "    def __init__(self, dataframe, transform=None, shots=16):\n",
        "        super().__init__(dataframe, transform)\n",
        "        \n",
        "        self.num_shots = shots\n",
        "\n",
        "        self.loader = None\n",
        "        self.classnames = dataframe[\"label\"].unique()\n",
        "\n",
        "    def set_loader(self, loader):\n",
        "        self.loader = loader\n",
        "\n",
        "class Config():\n",
        "    def __init__(self, config):\n",
        "        self.num_classes = config[\"num_classes\"]\n",
        "        self.seed = config[\"seed\"]\n",
        "        self.shots = config[\"shots\"]\n",
        "        self.backbone = config[\"backbone\"]\n",
        "        self.lr = config[\"lr\"]\n",
        "        self.batch_size = config[\"batch_size\"]\n",
        "        self.loss_lambda = config[\"loss_lambda\"]  # last is regularization lambda\n",
        "        self.fuse_type = config[\"fuse_type\"]\n",
        "        self.cache_dir = config[\"cache_dir\"]\n",
        "\n",
        "class FewShotTrasform(object):\n",
        "\n",
        "    @staticmethod\n",
        "    def _convert_image_to_rgb(image):\n",
        "        return image.convert(\"RGB\")\n",
        "\n",
        "    @staticmethod\n",
        "    def transform_train(size, scale=(0.8, 1.0)):\n",
        "        funcs = [\n",
        "            T.RandomResizedCrop(size=size, scale=scale, interpolation=InterpolationMode.BICUBIC),\n",
        "            T.RandomHorizontalFlip(p=0.5), FewShotTrasform._convert_image_to_rgb, ToTensor(),\n",
        "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "        ]\n",
        "        return Compose(funcs)\n",
        "\n",
        "    @staticmethod\n",
        "    def transform_test(size):\n",
        "        funcs = [\n",
        "            Resize(size, interpolation=InterpolationMode.BICUBIC),\n",
        "            CenterCrop(size), FewShotTrasform._convert_image_to_rgb, ToTensor(),\n",
        "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "        ]\n",
        "        return Compose(funcs)\n",
        "\n",
        "    pass\n",
        "\n",
        "class FewShotModel():\n",
        "    transform = FewShotTrasform.transform_train(224)\n",
        "\n",
        "    def __init__(self, shots, batch_size, classnames, template, dataset_name):\n",
        "        self.config = Config({\n",
        "            \"num_classes\":len(classnames),\n",
        "            \"seed\":2024,\n",
        "            \"shots\":shots,\n",
        "            \"backbone\":\"ViT-B/16\",\n",
        "            \"lr\":0.001,\n",
        "            \"batch_size\":batch_size,\n",
        "            \"loss_lambda\":[1.0, 1.0, 1.0, 1.0, 1.0],\n",
        "            \"fuse_type\":2,\n",
        "            \"cache_dir\":\"./__few_shot_cache__\"\n",
        "        })\n",
        "\n",
        "        self.clip_model, self.preprocess = clip.load(self.config.backbone, download_root=self.config.cache_dir,\n",
        "                                                     num_classes=len(classnames), config=self.config)\n",
        "        self.clip_model.eval()\n",
        "\n",
        "        Tools.print(\"Getting cached textual weights W ...\")\n",
        "        self.text_feats = self.clip_classifier(\n",
        "            os.path.join(self.config.cache_dir, f\"{dataset_name}_{self.config.backbone}_textfeats.pt\"),\n",
        "            classnames, template, self.clip_model)\n",
        "        \n",
        "    def train_epoch(self, epoch):\n",
        "        self.clip_model.adapter.train()\n",
        "        self.clip_model.visual.adapter.train()\n",
        "\n",
        "        train_acc, train_loss = AvgACC(), 0.0\n",
        "        loss_list = [0, 0, 0, 0, 0]\n",
        "        with tqdm(enumerate(self.train_loader), total=len(self.train_loader), desc=f\"epoch {epoch}\") as tqdm_train:\n",
        "            for _, (images, labels) in tqdm_train:\n",
        "                images, labels = images.cuda(), labels.cuda()\n",
        "                clip_logits, mlp_logits, ada_logits, total_logits, weight = self.clip_model.my_forward(images, self.text_feats)\n",
        "                \n",
        "                loss, losses = self.get_loss(labels, clip_logits, mlp_logits, ada_logits, total_logits,\n",
        "                                             lambda_value=self.config.loss_lambda)\n",
        "                train_loss += loss.item()\n",
        "                train_acc.step(mlp_logits, labels)\n",
        "\n",
        "                for i, l in enumerate(losses):\n",
        "                    loss_list[i] += l.item()\n",
        "                tqdm_train.set_postfix(cur_loss=loss.item())\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                if self.scheduler:\n",
        "                    self.scheduler.step()\n",
        "\n",
        "            train_acc_result = train_acc.cal()\n",
        "            train_loss = train_loss / len(self.train_loader)\n",
        "            pass\n",
        "\n",
        "        print(f\"train acc={train_acc_result}, \"\n",
        "                    f\"[l1_loss, ce_loss] => {[one / len(self.train_loader) for one in loss_list]}\")\n",
        "        return train_loss\n",
        "        \n",
        "    def train_model(self, dataset_loader, epochs=10, lr=0.001):\n",
        "        self.optimizer = torch.optim.AdamW(self.clip_model.parameters(), lr=lr / 10, weight_decay=1e-4, eps=1e-4)\n",
        "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, epochs * len(dataset_loader))\n",
        "\n",
        "        self.train_loader = dataset_loader\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            loss = self.train_epoch(epoch)\n",
        "            print(f\"Epoch: {epoch}, loss: {loss:.4f}, \"\n",
        "                        f\"lr: {self.optimizer.state_dict()['param_groups'][0]['lr']:.8f}\")\n",
        "            pass\n",
        "            \n",
        "    \n",
        "    def calculate_accuracy(self, dataset_loader):\n",
        "        self.clip_model.eval()\n",
        "        all_labels, all_logits, all_preds = [], [], []\n",
        "\n",
        "        best_beta = None\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with tqdm(enumerate(dataset_loader), total=len(dataset_loader), desc='Evaluate') as tqdm_eval:\n",
        "                for _, (images, labels) in tqdm_eval:\n",
        "                    clip_logits, mlp_logits, ada_logits, tot_logits, weight = self.clip_model.my_forward(images.cuda(),\n",
        "                                                                                                 self.text_feats)\n",
        "                    all_logits.append([clip_logits, mlp_logits, ada_logits, tot_logits])\n",
        "                    all_labels.append(labels)\n",
        "\n",
        "                    all_preds.append(torch.argmax(tot_logits, -1).cpu())\n",
        "                    pass\n",
        "                pass\n",
        "            pass\n",
        "\n",
        "        all_labels = torch.cat(all_labels, dim=0)\n",
        "        all_preds = torch.cat(all_preds, dim=0).numpy()\n",
        "\n",
        "        return f1_score(all_labels.cpu().numpy(),all_preds, average=\"macro\")\n",
        "    \n",
        "    @staticmethod\n",
        "    def cal_acc(logits, labels):\n",
        "        pred = torch.argmax(logits, -1)\n",
        "        acc_num = (pred == labels.cuda()).sum().item()\n",
        "        return 1.0 * acc_num / len(labels)\n",
        "    \n",
        "    @staticmethod\n",
        "    def fuse_logits(mlp_logits, clip_logits, beta=1.0):\n",
        "        return beta * mlp_logits + (1 - beta) * clip_logits\n",
        "    \n",
        "    def search_hp(self, mlp_logits, clip_logits, all_labels, start=0, end=1, step=50):\n",
        "        beta_list = [i * (end - start) / step + start for i in range(step + 1)]\n",
        "        accs, best_beta, best_acc = [], start, 0.\n",
        "        for beta in beta_list:\n",
        "            logits = self.fuse_logits(mlp_logits, clip_logits, beta=beta)\n",
        "            acc = self.cal_acc(logits, all_labels) * 100.\n",
        "            accs.append((beta, acc))\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                best_beta = beta\n",
        "        return best_beta, accs[-1][-1], best_acc\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_loss(labels, clip_logits, mlp_logits, ada_logits, total_logits, lambda_value=[1.0, 1.0, 1.0, 1.0, 1.0]):\n",
        "        ce_loss = F.cross_entropy(mlp_logits, labels) * lambda_value[0]\n",
        "        ce_loss2 = F.cross_entropy(ada_logits, labels) * lambda_value[1]\n",
        "        ce_loss3 = F.cross_entropy(total_logits, labels) * lambda_value[2]\n",
        "\n",
        "        l1_loss1 = F.l1_loss(mlp_logits, clip_logits) * lambda_value[3]\n",
        "        l1_loss2 = F.l1_loss(ada_logits, clip_logits) * lambda_value[4]\n",
        "\n",
        "        loss = l1_loss1 + l1_loss2 + ce_loss + ce_loss2 + ce_loss3\n",
        "        return loss, [l1_loss1, l1_loss2, ce_loss, ce_loss2, ce_loss3]\n",
        "    \n",
        "    @staticmethod\n",
        "    def clip_classifier(feat_path, classnames, template, clip_model):\n",
        "        if os.path.exists(feat_path):\n",
        "            Tools.print(f\"Loading texture features from {feat_path}\")\n",
        "            text_feats = torch.load(feat_path, map_location='cpu')\n",
        "            return text_feats.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            clip_weights = []\n",
        "            for classname in classnames:\n",
        "                classname = str(classname).replace('_', ' ')\n",
        "                if isinstance(template, list):\n",
        "                    texts = [t.format(classname) for t in template]\n",
        "                elif isinstance(template, dict):\n",
        "                    texts = template[classname]\n",
        "\n",
        "                texts = clip.tokenize(texts).cuda()\n",
        "                # prompt ensemble for ImageNet\n",
        "                class_embeddings = clip_model.encode_text(texts)\n",
        "                class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
        "                class_embedding = class_embeddings.mean(dim=0)\n",
        "                class_embedding /= class_embedding.norm()\n",
        "                clip_weights.append(class_embedding)\n",
        "                pass\n",
        "\n",
        "            clip_weights = torch.stack(clip_weights, dim=1).cuda()\n",
        "            torch.save(clip_weights, Tools.new_dir(feat_path))\n",
        "\n",
        "        return clip_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>NON-Few-shot models</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "X4-YscaR3ZQP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import cv2\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#############################################\n",
        "# Modified Neural Network Class\n",
        "##############################################\n",
        "\n",
        "class ModifiedNN(nn.Module):\n",
        "    '''\n",
        "    Parent class for all neural networks model that we will implement.\n",
        "    It is a basic nn.Module with a training method which implements the training for neural networks.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def calculate_accuracy(self, data_loader):\n",
        "        \"\"\"\n",
        "        Calculate accuracy of the model on a given dataset loader\n",
        "        \"\"\"\n",
        "        self.eval()  # Set the model to evaluation mode\n",
        "        y_pred = []\n",
        "        y_true = []\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient computation for evaluation\n",
        "            for batch in data_loader:\n",
        "                X_batch, y_batch = batch\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.forward(X_batch)\n",
        "\n",
        "                # Get predictions (class with the highest score)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                y_pred.extend(predicted.numpy())\n",
        "                y_true.extend(y_batch.numpy())\n",
        "\n",
        "        # Calculate AP\n",
        "        return f1_score(y_true,y_pred,average=\"macro\")\n",
        "    \n",
        "    def training_loop(self, train_loader, optimizer, loss_function, epochs=10):\n",
        "        \"\"\"\n",
        "        Train the model on the given loader using the given loss and optimizer\n",
        "        \"\"\"\n",
        "        # Training loop\n",
        "        for epoch in range(epochs):\n",
        "            self.train()  # Set the model to training mode\n",
        "            running_loss = 0.0\n",
        "\n",
        "            for batch in train_loader:\n",
        "                X_batch, y_batch = batch\n",
        "\n",
        "                if type(y_batch) is not torch.Tensor:\n",
        "                    y_batch = torch.Tensor(y_batch)\n",
        "\n",
        "                # Forward pass\n",
        "                predictions = self.forward(X_batch)\n",
        "                loss = loss_function(predictions, y_batch)\n",
        "\n",
        "                # Backward pass\n",
        "                optimizer.zero_grad()  # Clear previous gradients\n",
        "                loss.backward()        # Compute gradients\n",
        "                optimizer.step()       # Update parameters\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "            # Calculate average training loss\n",
        "            avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"  Training Loss: {avg_train_loss:.4f}\")\n",
        "        \n",
        "        return avg_train_loss\n",
        "\n",
        "##############################################\n",
        "# Utility functions\n",
        "###############################################\n",
        "\n",
        "def from_data_loader_to_numpy(data_loader):\n",
        "    '''\n",
        "    Method that concevts a torch data loader to two numpy arrays: X (samples) and y (labels).\n",
        "    '''\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "\n",
        "    for batch in data_loader:\n",
        "        X_batch, y_batch = batch\n",
        "\n",
        "        X_list.append(X_batch.numpy())\n",
        "        if isinstance(y_batch,tuple):\n",
        "            y_list.append(np.array(list(y_batch)))\n",
        "        else:\n",
        "            y_list.append(y_batch.numpy())\n",
        "    \n",
        "    X = np.concatenate(X_list, axis=0)\n",
        "    y = np.concatenate(y_list, axis=0)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "#############################################\n",
        "# CNN\n",
        "#############################################\n",
        "\n",
        "class CNNModel(ModifiedNN):\n",
        "    '''\n",
        "    CNN for traffic sign classification. The input is a 32x32x3 image.\n",
        "    '''\n",
        "\n",
        "    # Transformation used to adapt an input to the desired size wanted by the model\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dropout1 = nn.Dropout(0.2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # padding=1 per \"same\"\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(64 * 5 * 5, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        x = F.relu(self.conv1(x))  \n",
        "        x = F.relu(self.conv2(x))  \n",
        "        x = self.pool1(x)          \n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.conv3(x))  \n",
        "        x = F.relu(self.conv4(x))  \n",
        "        x = self.pool2(x)          \n",
        "        x = self.dropout2(x)\n",
        "        x = self.flatten(x)       \n",
        "        x = self.fc(x)             \n",
        "        return F.softmax(x, dim=1)\n",
        "    \n",
        "    def train_model(self, train_loader, epochs=10, lr=0.001):\n",
        "        # set optimizer and loss\n",
        "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        loss = nn.CrossEntropyLoss()\n",
        "        return super().training_loop(train_loader, optimizer, loss, epochs)\n",
        "        \n",
        "\n",
        "#############################################\n",
        "# MDCNN\n",
        "#############################################\n",
        "\n",
        "class MCDNN(ModifiedNN):\n",
        "    '''\n",
        "    MCDNN for traffic sign classification. The input is a 48x48x3 image.\n",
        "    '''\n",
        "    # Transformation used to adapt an input to the desired size wanted by the model\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((48, 48)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
        "    ])\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super(MCDNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 150, kernel_size=7)\n",
        "        self.bn1 = nn.BatchNorm2d(150)\n",
        "        self.conv2 = nn.Conv2d(150, 200, kernel_size=4)\n",
        "        self.bn2 = nn.BatchNorm2d(200)\n",
        "        self.conv3 = nn.Conv2d(200, 300, kernel_size=4)\n",
        "        self.bn3 = nn.BatchNorm2d(300)\n",
        "        self.fc1 = nn.Linear(300 * 3 * 3, 350)\n",
        "        self.bn4 = nn.BatchNorm1d(350)\n",
        "        self.fc2 = nn.Linear(350, num_classes)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv_drop = nn.Dropout2d(p=0.2)\n",
        "        self.fc_drop = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.conv_drop(self.pool(x))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.conv_drop(self.pool(x))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.conv_drop(self.pool(x))\n",
        "        x = x.view(-1, 300 * 3 * 3)\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = self.fc2(self.fc_drop(x))\n",
        "        return F.log_softmax(x, dim=1)\n",
        "    \n",
        "    def train_model(self, train_loader, epochs=10, lr=0.001):\n",
        "        # set optimizer and loss\n",
        "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        loss = F.nll_loss\n",
        "        return super().training_loop(train_loader, optimizer, loss, epochs)\n",
        "    \n",
        "\n",
        "#############################################\n",
        "# KNN\n",
        "#############################################\n",
        "\n",
        "class KNNClassifier:\n",
        "    # Transformation used to adapt an input to the desired size wanted by the model\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    def __init__(self, num_classes, k=3):\n",
        "        self.k = k\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.model = KNeighborsClassifier(n_neighbors=self.k)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.model.fit(self.X_train, self.y_train)\n",
        "\n",
        "        # Predict on new data\n",
        "        predictions = self.model.predict(X)\n",
        "\n",
        "        return predictions\n",
        "    \n",
        "    def process_hog(self, X):\n",
        "        # Compute the HOG features\n",
        "        hog = cv2.HOGDescriptor(_winSize=(32,32), _blockSize=(8,8), \n",
        "                        _blockStride=(4,4), _cellSize=(4,4), \n",
        "                        _nbins=9)\n",
        "\n",
        "        hog_x = []\n",
        "\n",
        "        for x in X:\n",
        "            gray_scale = cv2.cvtColor(x.reshape((32,32,3)), cv2.COLOR_RGB2GRAY)\n",
        "            gray_scale = (gray_scale*255).astype(np.uint8).reshape((32, 32))\n",
        "            x_hog = hog.compute(gray_scale)\n",
        "            hog_x.append(x_hog)\n",
        "        \n",
        "        return hog_x\n",
        "\n",
        "    def train_model(self, train_loader, epochs=10, lr=0.001):\n",
        "        X, y = from_data_loader_to_numpy(train_loader)\n",
        "\n",
        "        # Store training data for distance calculations\n",
        "        self.X_train = self.process_hog(X)\n",
        "        self.y_train = y\n",
        "    \n",
        "    def calculate_accuracy(self, data_loader):\n",
        "        X, y = from_data_loader_to_numpy(data_loader)\n",
        "        preds = self.forward(self.process_hog(X))\n",
        "\n",
        "        return f1_score(y,preds,average=\"macro\")\n",
        "\n",
        "\n",
        "#############################################\n",
        "# HOG SVM\n",
        "#############################################\n",
        "\n",
        "class HOG_SVM():\n",
        "    \"\"\"\n",
        "    SVM model applied on the HOG features extracted from the images\n",
        "    \"\"\"\n",
        "    # Transformation used to adapt an input to the desired size wanted by the model\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    def __init__(self,num_classes):\n",
        "        \"\"\"\n",
        "        Multiclass SVM whihc implements multiple classifier, one for each class, in a one-vs-rest scenario\n",
        "        \"\"\"\n",
        "        self.model = SVC(kernel='linear', decision_function_shape=\"ovr\", probability=True)\n",
        "    \n",
        "    def process_hog(self, X):\n",
        "        # Compute the HOG features\n",
        "        hog = cv2.HOGDescriptor(_winSize=(32,32), _blockSize=(8,8), \n",
        "                        _blockStride=(4,4), _cellSize=(4,4), \n",
        "                        _nbins=9)\n",
        "\n",
        "        hog_x = []\n",
        "\n",
        "        for x in X:\n",
        "            gray_scale = cv2.cvtColor(x.reshape((32,32,3)), cv2.COLOR_RGB2GRAY)\n",
        "            gray_scale = (gray_scale*255).astype(np.uint8).reshape((32, 32))\n",
        "            x_hog = hog.compute(gray_scale)\n",
        "            hog_x.append(x_hog)\n",
        "\n",
        "        return hog_x\n",
        "    \n",
        "    def process_dataset(self, dataset_loader):\n",
        "        X, y = from_data_loader_to_numpy(dataset_loader)\n",
        "        \n",
        "        return self.process_hog(X),y\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def train_model(self, train_loader, epochs=10, lr=0.001):\n",
        "        hog_X, y = self.process_dataset(train_loader)\n",
        "\n",
        "        self.model.fit(hog_X,y)\n",
        "\n",
        "    def calculate_accuracy(self, data_loader):\n",
        "        \"\"\"\n",
        "        Calculate accuracy of the model on a given dataset loader\n",
        "        \"\"\"\n",
        "        hog_X, y = self.process_dataset(data_loader)\n",
        "\n",
        "        pred = self.model.predict_proba(hog_X)\n",
        "        pred_labels = [np.argmax(p) for p in pred]\n",
        "\n",
        "        return f1_score(y,pred_labels, average=\"macro\")\n",
        "\n",
        "        \n",
        "\n",
        "#############################################\n",
        "# ViT\n",
        "#############################################\n",
        "\n",
        "#processor = ViTImageProcessor.from_pretrained(\"kelvinandreas/vit-traffic-sign-GTSRB\")\n",
        "#model = ViTForImageClassification.from_pretrained(\"kelvinandreas/vit-traffic-sign-GTSRB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparison using Paired t-test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from scipy.stats import t\n",
        "from sklearn.base import clone\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "class TrafficSignRecognitionComparator:\n",
        "\n",
        "    def __init__(self, few_shot_model, no_few_shot_model, dataset_iterator, no_few_shot_model_results=None, k_shot=16, n_folds=5):\n",
        "        \"\"\"\n",
        "        Initializes the comparator for traffic sign recognition.\n",
        "\n",
        "        Args:\n",
        "        few_shot_model: Few-shot model to compare\n",
        "        no_few_shot_model: nNo-few shot model to compare\n",
        "        dataset_iterator: the iterator on the collection of datasets.\n",
        "        no_few_shot_model_results: the AP (Average Precision) results obtained for the specified no-few shot model. (List of AP values)\n",
        "        k_shot: Number of samples per class in few-shot learning\n",
        "        n_folds: Number of folds for cross-validation\n",
        "        \"\"\"\n",
        "\n",
        "        self.few_shot_model = few_shot_model\n",
        "        self.no_few_shot_model = no_few_shot_model\n",
        "        self.dataset_iterator = dataset_iterator\n",
        "        self.no_few_shot_model_results = no_few_shot_model_results\n",
        "        self.k_shot = k_shot\n",
        "        self.n_folds = n_folds\n",
        "\n",
        "        \n",
        "    \n",
        "        \n",
        "\n",
        "    def _verify_number_of_samples(self, dataset):\n",
        "        \"\"\"Verify if the dataset has a number of samples that is sufficient to execute the train of the few-shot model.\n",
        "\n",
        "        Returns\n",
        "            result: true if all the datasets have a number of samples that is sufficient to execute the train of the few-shot model, false otherwise.\n",
        "        \n",
        "        \"\"\"\n",
        "        X = dataset.pandas_dataset['image']\n",
        "        y = dataset.pandas_dataset['label']\n",
        "\n",
        "        classes = np.unique(y)\n",
        "        # We find the class that has the lowest number of samples in the dataset\n",
        "        min_number_of_samples = float('inf')\n",
        "        for cls in classes:\n",
        "            # Take the indices corresponding to the samples of the current class\n",
        "            cls_indices = np.where(y == cls)[0]\n",
        "            number_of_samples_cls = len(cls_indices)\n",
        "            if number_of_samples_cls < min_number_of_samples:\n",
        "                min_number_of_samples = number_of_samples_cls\n",
        "        # After finding the number of samples in the class with the fewest instances\n",
        "        number_of_samples_each_fold = min_number_of_samples/self.n_folds\n",
        "        number_of_samples_training_setCV = number_of_samples_each_fold * (self.n_folds-1)\n",
        "        if number_of_samples_training_setCV  >= self.k_shot:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def _prepare_few_shot_data(self, X_train, y_train):\n",
        "        \"\"\"Filter the given training set in order to obtain a subset of it that can be used to train the Few-shot model.\n",
        "\n",
        "        Args:\n",
        "            X_train: the features of the given training set.\n",
        "            t_train: the labels of the given training set\n",
        "\n",
        "        Returns\n",
        "            X_train_few_shot: the featues of the new smaller training set.\n",
        "            y_train_few_shot: the labels of the new smaller training set.\n",
        "        \n",
        "        \"\"\"\n",
        "\n",
        "       \n",
        "        X_train_few_shot = []\n",
        "        y_train_few_shot = []\n",
        "        classes = np.unique(y_train)\n",
        "        \n",
        "        for cls in classes:\n",
        "            # Take the indices corresponding to the samples of the current class\n",
        "            cls_indices = np.where(y_train == cls)[0]\n",
        "\n",
        "            if len(cls_indices) < self.k_shot:\n",
        "                raise ValueError(\"The class\" + cls + \"does not have sufficient samples to execute the train of the few-shot model. Minimun number of samples required: \" + self.k_shot + \", actual number of samples: \" + len(cls_indices) + \"!\")\n",
        "\n",
        "\n",
        "            # Choose self.k_shot indices from all the indices found \n",
        "            selected_random_indices = np.random.choice(cls_indices, size=self.k_shot, replace=False)\n",
        "\n",
        "            X_train_few_shot.extend(X_train.iloc[selected_random_indices])\n",
        "            y_train_few_shot.extend(y_train.iloc[selected_random_indices])\n",
        "            \n",
        "            \n",
        "        return X_train_few_shot, y_train_few_shot\n",
        "    \n",
        "    \n",
        "    def _evaluate_dataset(self, dataset):\n",
        "        \"\"\"Performs evaluation on a single dataset. It uses the stratified K-fold cross validation<.\n",
        "\n",
        "        Args:\n",
        "            dataset: dataset to evaluate.\n",
        "\n",
        "        Returns:\n",
        "            no_few_shot_model_mean_ap_results: the mean AP result obtained from the cross-validation process applied to the No few-shot model.\n",
        "            few_shot_model_mean_ap_results: the mean AP result obtained from the cross-validation process applied to the few-shot model.\n",
        "        \"\"\"\n",
        "        \n",
        "        if(self._verify_number_of_samples(dataset))==False:\n",
        "            raise ValueError(\"The dataset \" + dataset-dataset.name + \" does not have have a number of samples that is sufficient to execute the train of the few-shot model\")\n",
        "\n",
        "        X = dataset.pandas_dataset['image']\n",
        "        y = dataset.pandas_dataset['label']\n",
        "\n",
        "\n",
        "        # Lists to store the AP results from the individual iterations of the cross-validation process.\n",
        "        no_few_shot_ap_resultsCV = [] # The AP results obtained from the No few-shot model\n",
        "        few_shot_scores_ap_resultsCV = [] # The AP results obtained from the few-shot model\n",
        "\n",
        "\n",
        "        # Create a StratifiedKFold object for cross-validation.\n",
        "        # This ensures each fold has a balanced distribution of classes.\n",
        "        # Data is shuffled before splitting to improve representativeness,\n",
        "        # and a fixed random seed is used for reproducibility.\n",
        "        skf = StratifiedKFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "        n_iter=0\n",
        "\n",
        "        # For each iteration of the Cross validation\n",
        "        for train_index, test_index in skf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            print(\"\\nIteration: \",n_iter)\n",
        "\n",
        "            # test dataset loader\n",
        "            dataset_pandas_test = pd.DataFrame()\n",
        "            dataset_pandas_test[\"image\"]=X_test\n",
        "            dataset_pandas_test[\"label\"]=y_test\n",
        "            \n",
        "            if self.no_few_shot_model_results is None:\n",
        "                # train dataset loader\n",
        "                dataset_pandas_train = pd.DataFrame()\n",
        "                dataset_pandas_train[\"image\"]=X_train\n",
        "                dataset_pandas_train[\"label\"]=y_train\n",
        "                train_dataset_torch = PandasDataset(dataset_pandas_train, transform=self.no_few_shot_model.transform)\n",
        "                train_dataset_loader = torch.utils.data.DataLoader(train_dataset_torch, batch_size=64, shuffle=True)\n",
        "\n",
        "                test_dataset_torch = PandasDataset(dataset_pandas_test, transform=self.no_few_shot_model.transform)\n",
        "                test_dataset_loader = torch.utils.data.DataLoader(test_dataset_torch, batch_size=64, shuffle=True)\n",
        "\n",
        "                # No few-shot model\n",
        "                no_few_shot_model = self.no_few_shot_model(num_classes=train_dataset_torch.num_classes)\n",
        "                # Train the model on the training set\n",
        "                print(\"\\n#######################################\")\n",
        "                print(\"Training non-few shot model...\")\n",
        "                print(\"Train dataset size: \",train_dataset_loader.__len__())\n",
        "                print(\"Train dataset size: \",test_dataset_loader.__len__())\n",
        "                no_few_shot_model.train_model(train_dataset_loader)\n",
        "                print(\"Training complete!\")\n",
        "                # Make the predictionas on the test set\n",
        "                no_few_shot_acc= no_few_shot_model.calculate_accuracy(test_dataset_loader)\n",
        "                print(\"\\nTest F1-macro: \",no_few_shot_acc)\n",
        "                print(\"##########################################\")\n",
        "                no_few_shot_ap_resultsCV.append(1 - no_few_shot_acc) # Average Precision result calculated for a single iteration of the cross-validation process\n",
        "            \n",
        "\n",
        "            # Few-shot model\n",
        "\n",
        "            # Obtain the filtered training set starting from the cross-validation training set\n",
        "            few_shot_X_train, few_shot_y_train = self._prepare_few_shot_data(X_train, y_train)\n",
        "\n",
        "            # train dataset loader\n",
        "            dataset_pandas_train = pd.DataFrame()\n",
        "            dataset_pandas_train[\"image\"]=few_shot_X_train\n",
        "            dataset_pandas_train[\"label\"]=few_shot_y_train\n",
        "            train_dataset_torch = FewShotDataset(dataset_pandas_train, transform=self.few_shot_model.transform, shots=self.k_shot)\n",
        "            train_dataset_loader = torch.utils.data.DataLoader(train_dataset_torch, batch_size=64, shuffle=True)\n",
        "\n",
        "            # test dataset loader\n",
        "            test_dataset_torch = FewShotDataset(dataset_pandas_test, transform=self.few_shot_model.transform, shots=self.k_shot)\n",
        "            test_dataset_loader = torch.utils.data.DataLoader(test_dataset_torch, batch_size=64, shuffle=True)\n",
        "\n",
        "            few_shot_model = self.few_shot_model(shots=self.k_shot, batch_size=64, classnames=train_dataset_torch.classnames, template=DatasetCollection.templates[dataset.dataset_name], dataset_name=dataset.dataset_name)\n",
        "\n",
        "            # Train the model on the (filtered) training set\n",
        "            print(\"\\n#######################################\")\n",
        "            print(\"Training few-shot model...\")\n",
        "            print(\"Train dataset size: \",train_dataset_loader.__len__())\n",
        "            print(\"Train dataset size: \",test_dataset_loader.__len__())\n",
        "            few_shot_model.train_model(train_dataset_loader)\n",
        "            print(\"Training complete!\")\n",
        "            # Make the predictionas on the test set\n",
        "            few_shot_acc= few_shot_model.calculate_accuracy(test_dataset_loader)\n",
        "            print(\"\\nTest F1-macro: \",few_shot_acc)\n",
        "            print(\"#######################################\")\n",
        "            few_shot_scores_ap_resultsCV.append(1 - few_shot_acc)   # Average Precision result for a single iteration of the cross-validation process\n",
        "\n",
        "            n_iter+=1\n",
        "\n",
        "        few_shot_model_mean_ap_results = sum(few_shot_scores_ap_resultsCV)/self.n_folds\n",
        "        if self.no_few_shot_model_results is None:\n",
        "            no_few_shot_model_mean_ap_results =  sum(no_few_shot_ap_resultsCV)/self.n_folds\n",
        "        else:\n",
        "            no_few_shot_model_mean_ap_results = -1\n",
        "            \n",
        "        return no_few_shot_model_mean_ap_results, few_shot_model_mean_ap_results\n",
        "    \n",
        "\n",
        "    def run_comparison(self, confidence_level=0.05):\n",
        "        \"\"\"It runs the comparison on all datasets and returns the results.\n",
        "\n",
        "        Args:\n",
        "            confidence_level: confidence interval to use when perform the paired t-test.\n",
        "\n",
        "        Returns:\n",
        "            t-stat: the t-statistic value.\n",
        "            t_critical\n",
        "            no_few_shot_ap_results: List to store the AP results obtained from each dataset with the No few-shot model\n",
        "            few_shot_ap_results: List to store the AP results obtained from each dataset with the Few-shot model\n",
        "            result: boolen value where true means that there is a significant difference between the two models, false otherwise. \n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Lists to store the AP result obtained from each dataset\n",
        "        no_few_shot_ap_results = [] # List to store the AP results obtained from each dataset with the No few-shot model\n",
        "        few_shot_ap_results = [] # List to store the AP results obtained from each dataset with the Few-shot model\n",
        "        if self.no_few_shot_model_results is not None:\n",
        "            no_few_shot_ap_results = self.no_few_shot_model_results\n",
        "        \n",
        "        # For each dataset\n",
        "        print(\"\\nEVALUATING DATASETS USING CROSS-VALIDATION\\n\")\n",
        "        print(\"\\n#######################################\")\n",
        "        print(self.no_few_shot_model.__name__,\" VS \",self.few_shot_model.__name__)\n",
        "        print(\"#######################################\")\n",
        "        \n",
        "        for i, dataset in enumerate(self.dataset_iterator):\n",
        "            no_few_shot_ap_result, few_shot_ap_result = self._evaluate_dataset(dataset)\n",
        "            no_few_shot_ap_results.append(no_few_shot_ap_result)\n",
        "            few_shot_ap_results.append(few_shot_ap_result)\n",
        "        \n",
        "        # Exeute the paired t-test\n",
        "        number_of_datasets = len(self.dataset_iterator)\n",
        "        mean_differences = abs(no_few_shot_ap_results - few_shot_ap_results)\n",
        "        mean_differences = np.mean(mean_differences)\n",
        "        std_differences = np.std(mean_differences, ddof=1)  # Std campionaria (corretta per n-1)\n",
        "\n",
        "        t_stat = mean_differences / (std_differences / np.sqrt(number_of_datasets))\n",
        "        dof = number_of_datasets - 1  # Degrees of freedom\n",
        "        t_critical = t.ppf(1 - confidence_level/2, dof)  # Two-tailed: confidence_level/2\n",
        "\n",
        "        result = abs(t_stat) > t_critical\n",
        "        return t_stat, t_critical, no_few_shot_ap_results, few_shot_ap_results, result\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "EVALUATING DATASETS USING CROSS-VALIDATION\n",
            "\n",
            "\n",
            "#######################################\n",
            "CNNModel  VS  FewShotModel\n",
            "#######################################\n",
            "Processing the Kaggle dataset: indian_dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing images: 100%|██████████| 13971/13971 [00:03<00:00, 3555.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of filtered labels:  58\n",
            "Number of removed labels:  0\n",
            "Number of samples in the dataset:  13971\n",
            "\n",
            "Iteration:  0\n",
            "\n",
            "#######################################\n",
            "Training non-few shot model...\n",
            "Train dataset size:  175\n",
            "Train dataset size:  44\n",
            "Epoch 1/10\n",
            "  Training Loss: 4.0150\n",
            "Epoch 2/10\n",
            "  Training Loss: 4.0085\n",
            "Epoch 3/10\n",
            "  Training Loss: 4.0100\n",
            "Epoch 4/10\n",
            "  Training Loss: 4.0283\n",
            "Epoch 5/10\n",
            "  Training Loss: 4.0463\n",
            "Epoch 6/10\n",
            "  Training Loss: 4.0463\n",
            "Epoch 7/10\n",
            "  Training Loss: 4.0463\n",
            "Epoch 8/10\n",
            "  Training Loss: 4.0462\n",
            "Epoch 9/10\n",
            "  Training Loss: 4.0462\n",
            "Epoch 10/10\n",
            "  Training Loss: 4.0462\n",
            "Training complete!\n",
            "\n",
            "Test F1-macro:  0.0014421997091957962\n",
            "##########################################\n",
            "2025-06-08 11:37:02 Getting cached textual weights W ...\n",
            "2025-06-08 11:37:02 Loading texture features from ./__few_shot_cache__\\indian_dataset_ViT-B/16_textfeats.pt\n",
            "\n",
            "#######################################\n",
            "Training few-shot model...\n",
            "Train dataset size:  15\n",
            "Train dataset size:  44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 0: 100%|██████████| 15/15 [00:59<00:00,  3.95s/it, cur_loss=13.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train acc=0.01939655172413793, [l1_loss, ce_loss] => [8.178938802083334, 0.3331217447916667, 4.22734375, 4.0796875, 4.054427083333334]\n",
            "Epoch: 0, loss: 20.8734, lr: 0.00000000\n",
            "Training complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluate: 100%|██████████| 44/44 [00:55<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test F1-macro:  0.0014195303720352518\n",
            "#######################################\n",
            "\n",
            "Iteration:  1\n",
            "\n",
            "#######################################\n",
            "Training non-few shot model...\n",
            "Train dataset size:  175\n",
            "Train dataset size:  44\n",
            "Epoch 1/10\n",
            "  Training Loss: 3.9690\n",
            "Epoch 2/10\n",
            "  Training Loss: 3.9502\n",
            "Epoch 3/10\n",
            "  Training Loss: 3.9141\n",
            "Epoch 4/10\n",
            "  Training Loss: 3.8999\n",
            "Epoch 5/10\n",
            "  Training Loss: 3.9089\n",
            "Epoch 6/10\n",
            "  Training Loss: 3.8922\n",
            "Epoch 7/10\n",
            "  Training Loss: 3.8985\n",
            "Epoch 8/10\n",
            "  Training Loss: 3.8809\n",
            "Epoch 9/10\n",
            "  Training Loss: 3.8854\n",
            "Epoch 10/10\n",
            "  Training Loss: 3.9026\n",
            "Training complete!\n",
            "\n",
            "Test F1-macro:  0.052649259276361854\n",
            "##########################################\n",
            "2025-06-08 11:45:29 Getting cached textual weights W ...\n",
            "2025-06-08 11:45:29 Loading texture features from ./__few_shot_cache__\\indian_dataset_ViT-B/16_textfeats.pt\n",
            "\n",
            "#######################################\n",
            "Training few-shot model...\n",
            "Train dataset size:  15\n",
            "Train dataset size:  44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 0: 100%|██████████| 15/15 [01:20<00:00,  5.38s/it, cur_loss=12.3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train acc=0.036637931034482756, [l1_loss, ce_loss] => [7.495572916666666, 0.30439453125, 3.9895833333333335, 4.000911458333333, 3.9174479166666667]\n",
            "Epoch: 0, loss: 19.7115, lr: 0.00000000\n",
            "Training complete!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluate: 100%|██████████| 44/44 [03:21<00:00,  4.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test F1-macro:  0.002265666342613476\n",
            "#######################################\n",
            "\n",
            "Iteration:  2\n",
            "\n",
            "#######################################\n",
            "Training non-few shot model...\n",
            "Train dataset size:  175\n",
            "Train dataset size:  44\n",
            "Epoch 1/10\n",
            "  Training Loss: 4.0476\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[58], line 55\u001b[0m\n\u001b[0;32m     51\u001b[0m    \u001b[38;5;28mprint\u001b[39m(t_stat,t_critical,no_few_shot_ap_results,few_shot_ap_results,result)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 55\u001b[0m    main()\n",
            "Cell \u001b[1;32mIn[58], line 35\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# MATTIA\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m##\u001b[39;00m\n\u001b[0;32m     34\u001b[0m fs_CNN \u001b[38;5;241m=\u001b[39m TrafficSignRecognitionComparator(few_shot_models[\u001b[38;5;241m0\u001b[39m], non_few_shot_models[\u001b[38;5;241m0\u001b[39m], allDatasets\u001b[38;5;241m.\u001b[39mstream_all(), k_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, n_folds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m t_stat, t_critical, no_few_shot_ap_results, few_shot_ap_results, result \u001b[38;5;241m=\u001b[39m fs_CNN\u001b[38;5;241m.\u001b[39mrun_comparison()\n\u001b[0;32m     37\u001b[0m fs_MDCNN \u001b[38;5;241m=\u001b[39m TrafficSignRecognitionComparator(few_shot_models[\u001b[38;5;241m0\u001b[39m], non_few_shot_models[\u001b[38;5;241m1\u001b[39m], allDatasets\u001b[38;5;241m.\u001b[39mstream_all(), k_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, n_folds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     38\u001b[0m t_stat, t_critical, no_few_shot_ap_results, few_shot_ap_results, result \u001b[38;5;241m=\u001b[39m fs_MDCNN\u001b[38;5;241m.\u001b[39mrun_comparison()\n",
            "Cell \u001b[1;32mIn[57], line 239\u001b[0m, in \u001b[0;36mTrafficSignRecognitionComparator.run_comparison\u001b[1;34m(self, confidence_level)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#######################################\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_iterator):\n\u001b[1;32m--> 239\u001b[0m     no_few_shot_ap_result, few_shot_ap_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_dataset(dataset)\n\u001b[0;32m    240\u001b[0m     no_few_shot_ap_results\u001b[38;5;241m.\u001b[39mappend(no_few_shot_ap_result)\n\u001b[0;32m    241\u001b[0m     few_shot_ap_results\u001b[38;5;241m.\u001b[39mappend(few_shot_ap_result)\n",
            "Cell \u001b[1;32mIn[57], line 160\u001b[0m, in \u001b[0;36mTrafficSignRecognitionComparator._evaluate_dataset\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain dataset size: \u001b[39m\u001b[38;5;124m\"\u001b[39m,train_dataset_loader\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m())\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain dataset size: \u001b[39m\u001b[38;5;124m\"\u001b[39m,test_dataset_loader\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m())\n\u001b[1;32m--> 160\u001b[0m no_few_shot_model\u001b[38;5;241m.\u001b[39mtrain_model(train_dataset_loader)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Make the predictionas on the test set\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[46], line 153\u001b[0m, in \u001b[0;36mCNNModel.train_model\u001b[1;34m(self, train_loader, epochs, lr)\u001b[0m\n\u001b[0;32m    151\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m    152\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m--> 153\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtraining_loop(train_loader, optimizer, loss, epochs)\n",
            "Cell \u001b[1;32mIn[46], line 68\u001b[0m, in \u001b[0;36mModifiedNN.training_loop\u001b[1;34m(self, train_loader, optimizer, loss_function, epochs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m     67\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear previous gradients\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()        \u001b[38;5;66;03m# Compute gradients\u001b[39;00m\n\u001b[0;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()       \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[0;32m     71\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
            "File \u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\MLexam\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    650\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\MLexam\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m _engine_run_backward(\n\u001b[0;32m    354\u001b[0m     tensors,\n\u001b[0;32m    355\u001b[0m     grad_tensors_,\n\u001b[0;32m    356\u001b[0m     retain_graph,\n\u001b[0;32m    357\u001b[0m     create_graph,\n\u001b[0;32m    358\u001b[0m     inputs,\n\u001b[0;32m    359\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    360\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    361\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\utente\\miniconda3\\envs\\MLexam\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "def main():\n",
        "   # Kaggle datasets\n",
        "   indian_dataset = KaggleDataset(\"neelpratiksha/indian-traffic-sign-dataset\", \"indian_dataset\", \"image\", \"label\", os.path.join(\"Indian-Traffic Sign-Dataset\", \"images\"))\n",
        "   persian_dataset = KaggleDataset(\"saraparsaseresht/persian-traffic-sign-dataset-ptsd\", \"persian_dataset\", \"image\", \"label\", os.path.join(\"PTSD_Recognition/PTSD_Recognition\", \"train\"))\n",
        "   bangladesh_dataset = KaggleDataset(\"tithikhan/traffic\", \"bangladesh_dataset\", \"image\", \"label\", \"myData\")\n",
        "   kaggle_datasets_list = []\n",
        "   kaggle_datasets_list.append(indian_dataset)\n",
        "   kaggle_datasets_list.append(persian_dataset)\n",
        "   kaggle_datasets_list.append(bangladesh_dataset)\n",
        "\n",
        "   # Hugging face datasets\n",
        "   chinese_dataset = HuggingFaceDataset(\"kuchidareo/chinese_trafficsign_dataset\", \"chinese_dataset\", \"image\", \"label\")\n",
        "   german_dataset = HuggingFaceDataset(\"bazyl/GTSRB\", \"german_dataset\", \"Path\", \"ClassId\")\n",
        "   russian_dataset = HuggingFaceDataset(\"eleldar/rtsd_cleaned\", \"russian_dataset\", \"image\", \"sign_class\")\n",
        "   hugging_face_datasets_list = []\n",
        "   hugging_face_datasets_list.append(chinese_dataset)\n",
        "   hugging_face_datasets_list.append(german_dataset)\n",
        "   hugging_face_datasets_list.append(russian_dataset)\n",
        "\n",
        "   # Local datasets\n",
        "   belgian_dataset = LocalDataset(\"./dataset/datasets/belgium-traffic-sign\", \"belgian_dataset\", \"image\", \"label\")\n",
        "   local_datasets_list = []\n",
        "   local_datasets_list.append(belgian_dataset)\n",
        "\n",
        "   allDatasets = DatasetCollection(kaggle_datasets_list,hugging_face_datasets_list,local_datasets_list)\n",
        "\n",
        "   # List of Non-Few-Shot models \n",
        "   non_few_shot_models = [CNNModel,MCDNN,KNNClassifier,HOG_SVM]\n",
        "   few_shot_models = [FewShotModel]\n",
        "\n",
        "   ##\n",
        "   # MATTIA\n",
        "   ##\n",
        "   fs_CNN = TrafficSignRecognitionComparator(few_shot_models[0], non_few_shot_models[0], allDatasets.stream_all(), k_shot=16, n_folds=5)\n",
        "   t_stat, t_critical, no_few_shot_ap_results, few_shot_ap_results, result = fs_CNN.run_comparison()\n",
        "   \n",
        "   fs_MDCNN = TrafficSignRecognitionComparator(few_shot_models[0], non_few_shot_models[1], allDatasets.stream_all(), k_shot=16, n_folds=5)\n",
        "   t_stat, t_critical, no_few_shot_ap_results, few_shot_ap_results, result = fs_MDCNN.run_comparison()\n",
        "   \"\"\"\n",
        "   ##\n",
        "   # ALESSANDRO\n",
        "   ##\n",
        "\n",
        "   fs_KNN = TrafficSignRecognitionComparator(few_shot_models[0], non_few_shot_models[2], allDatasets.stream_all(), k_shot=16, n_folds=5)\n",
        "   t_stat, t_critical, no_few_shot_ap_results, few_shot_ap_results, result = fs_KNN.run_comparison()\n",
        "   \"\"\"\n",
        "   \"\"\"\n",
        "   fs_SVM = TrafficSignRecognitionComparator(few_shot_models[0], non_few_shot_models[3], allDatasets.stream_all(), k_shot=16, n_folds=5)\n",
        "   t_stat, t_critical, no_few_shot_ap_results, few_shot_ap_results, result = fs_SVM.run_comparison()\"\"\"\n",
        "\n",
        "   print(t_stat,t_critical,no_few_shot_ap_results,few_shot_ap_results,result)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "   main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLexam",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
