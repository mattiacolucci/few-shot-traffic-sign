PERFORMING COMPARISON USING  5 CROSS-VALIDATION AND  16 -SHOT LEARNING
#######################################
KNNClassifier  VS  FewShotModel
#######################################

Processing the Kaggle dataset: indian_dataset
Processing images: 100%|██████████| 13971/13971 [00:12<00:00, 1078.26it/s]
Number of filtered labels:  58
Number of removed labels:  0
Number of samples in the dataset:  13971

Iteration:  0

#######################################
Training non-few shot model...
Train dataset size:  175
Test dataset size:  44
Training complete!

Test F1-macro:  0.6611782240521116
##########################################
2025-06-09 13:17:08 Getting cached textual weights W ...
2025-06-09 13:17:08 Loading texture features from ./__few_shot_cache__\indian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  15
Test dataset size:  44
epoch 0: 100%|██████████| 15/15 [00:33<00:00,  2.21s/it, cur_loss=14.1]
train acc=0.03771551724137931, [l1_loss, ce_loss] => [8.9427734375, 0.33811848958333335, 4.109244791666667, 4.078125, 4.015885416666666]
Epoch: 0, loss: 21.4839, lr: 0.00009755
epoch 1: 100%|██████████| 15/15 [00:35<00:00,  2.40s/it, cur_loss=12.2]
train acc=0.0625, [l1_loss, ce_loss] => [1.0913736979166666, 0.31106770833333336, 3.738671875, 3.8229166666666665, 3.7296875]
Epoch: 1, loss: 12.6932, lr: 0.00009045
epoch 2: 100%|██████████| 15/15 [00:37<00:00,  2.52s/it, cur_loss=11.6]
train acc=0.07974137931034483, [l1_loss, ce_loss] => [0.6645182291666667, 0.3075032552083333, 3.5716145833333335, 3.66015625, 3.57578125]
Epoch: 2, loss: 11.7792, lr: 0.00007939
epoch 3: 100%|██████████| 15/15 [00:35<00:00,  2.33s/it, cur_loss=11]  
train acc=0.09375, [l1_loss, ce_loss] => [0.56962890625, 0.3037109375, 3.462760416666667, 3.599869791666667, 3.4868489583333333]
Epoch: 3, loss: 11.4229, lr: 0.00006545
epoch 4: 100%|██████████| 15/15 [00:35<00:00,  2.40s/it, cur_loss=11.6]
train acc=0.11422413793103449, [l1_loss, ce_loss] => [0.5349446614583333, 0.30568033854166665, 3.3971354166666665, 3.55078125, 3.4204427083333333]
Epoch: 4, loss: 11.2083, lr: 0.00005000
epoch 5: 100%|██████████| 15/15 [00:36<00:00,  2.46s/it, cur_loss=11.2]
train acc=0.14547413793103448, [l1_loss, ce_loss] => [0.5151041666666667, 0.3040852864583333, 3.3139322916666667, 3.509765625, 3.345703125]
Epoch: 5, loss: 10.9880, lr: 0.00003455
epoch 6: 100%|██████████| 15/15 [00:34<00:00,  2.31s/it, cur_loss=11]  
train acc=0.16918103448275862, [l1_loss, ce_loss] => [0.51904296875, 0.299658203125, 3.2514322916666667, 3.475, 3.2799479166666665]
Epoch: 6, loss: 10.8245, lr: 0.00002061
epoch 7: 100%|██████████| 15/15 [00:37<00:00,  2.47s/it, cur_loss=11.1]
train acc=0.16594827586206898, [l1_loss, ce_loss] => [0.5269856770833333, 0.30100911458333335, 3.2140625, 3.469010416666667, 3.252734375]
Epoch: 7, loss: 10.7630, lr: 0.00000955
epoch 8: 100%|██████████| 15/15 [00:34<00:00,  2.31s/it, cur_loss=11.2]
train acc=0.17349137931034483, [l1_loss, ce_loss] => [0.5189127604166667, 0.2972819010416667, 3.1938802083333333, 3.456770833333333, 3.2291666666666665]
Epoch: 8, loss: 10.6948, lr: 0.00000245
epoch 9: 100%|██████████| 15/15 [00:38<00:00,  2.59s/it, cur_loss=11]  
train acc=0.17672413793103448, [l1_loss, ce_loss] => [0.5207194010416667, 0.29708658854166664, 3.1828125, 3.44921875, 3.217578125]
Epoch: 9, loss: 10.6667, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 44/44 [01:09<00:00,  1.57s/it]
Test F1-macro:  0.08798322775935806
#######################################

Iteration:  1

#######################################
Training non-few shot model...
Train dataset size:  175
Test dataset size:  44
Training complete!

Test F1-macro:  0.6646838233028787
##########################################
2025-06-09 13:24:37 Getting cached textual weights W ...
2025-06-09 13:24:37 Loading texture features from ./__few_shot_cache__\indian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  15
Test dataset size:  44
epoch 0: 100%|██████████| 15/15 [01:11<00:00,  4.77s/it, cur_loss=13.2]
train acc=0.04956896551724138, [l1_loss, ce_loss] => [9.55341796875, 0.30125325520833335, 3.968359375, 3.999609375, 3.915755208333333]
Epoch: 0, loss: 21.7437, lr: 0.00009755
epoch 1: 100%|██████████| 15/15 [01:12<00:00,  4.86s/it, cur_loss=12.2]
train acc=0.06573275862068965, [l1_loss, ce_loss] => [1.1008138020833333, 0.26953125, 3.5442708333333335, 3.7309895833333333, 3.5518229166666666]
Epoch: 1, loss: 12.1979, lr: 0.00009045
epoch 2: 100%|██████████| 15/15 [01:14<00:00,  4.94s/it, cur_loss=10.8]
train acc=0.12392241379310345, [l1_loss, ce_loss] => [0.7600911458333334, 0.2660888671875, 3.2473958333333335, 3.615234375, 3.3111979166666665]
Epoch: 2, loss: 11.2016, lr: 0.00007939
epoch 3: 100%|██████████| 15/15 [01:14<00:00,  4.97s/it, cur_loss=9.79]
train acc=0.15301724137931033, [l1_loss, ce_loss] => [0.71962890625, 0.26544596354166666, 3.011588541666667, 3.525651041666667, 3.070052083333333]
Epoch: 3, loss: 10.5932, lr: 0.00006545
epoch 4: 100%|██████████| 15/15 [01:13<00:00,  4.93s/it, cur_loss=9.62]
train acc=0.2349137931034483, [l1_loss, ce_loss] => [0.72119140625, 0.27587890625, 2.8190104166666665, 3.410416666666667, 2.8700520833333334]
Epoch: 4, loss: 10.0969, lr: 0.00005000
epoch 5: 100%|██████████| 15/15 [01:13<00:00,  4.88s/it, cur_loss=9.34]
train acc=0.25862068965517243, [l1_loss, ce_loss] => [0.71865234375, 0.286669921875, 2.695442708333333, 3.3329427083333334, 2.7471354166666666]
Epoch: 5, loss: 9.7807, lr: 0.00003455
epoch 6: 100%|██████████| 15/15 [01:13<00:00,  4.89s/it, cur_loss=10.1]
train acc=0.2952586206896552, [l1_loss, ce_loss] => [0.7221028645833333, 0.29705403645833334, 2.576953125, 3.253645833333333, 2.626692708333333]
Epoch: 6, loss: 9.4750, lr: 0.00002061
epoch 7: 100%|██████████| 15/15 [01:13<00:00,  4.89s/it, cur_loss=8.73]
train acc=0.3308189655172414, [l1_loss, ce_loss] => [0.7202799479166667, 0.30224609375, 2.4751302083333333, 3.20625, 2.533203125]
Epoch: 7, loss: 9.2359, lr: 0.00000955
epoch 8: 100%|██████████| 15/15 [01:13<00:00,  4.89s/it, cur_loss=8.7] 
train acc=0.3771551724137931, [l1_loss, ce_loss] => [0.72177734375, 0.30458984375, 2.4109375, 3.1723958333333333, 2.4682291666666667]
Epoch: 8, loss: 9.0771, lr: 0.00000245
epoch 9: 100%|██████████| 15/15 [01:13<00:00,  4.89s/it, cur_loss=9.59]
train acc=0.38146551724137934, [l1_loss, ce_loss] => [0.7203776041666666, 0.3062337239583333, 2.399609375, 3.1828125, 2.457421875]
Epoch: 9, loss: 9.0661, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 44/44 [01:44<00:00,  2.38s/it]
Test F1-macro:  0.2506020866366978
#######################################

Iteration:  2

#######################################
Training non-few shot model...
Train dataset size:  175
Test dataset size:  44
Training complete!

Test F1-macro:  0.6941107132034996
##########################################
2025-06-09 13:38:53 Getting cached textual weights W ...
2025-06-09 13:38:53 Loading texture features from ./__few_shot_cache__\indian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  15
Test dataset size:  44
epoch 0: 100%|██████████| 15/15 [00:52<00:00,  3.51s/it, cur_loss=12.6]
train acc=0.03556034482758621, [l1_loss, ce_loss] => [6.644921875, 0.3213704427083333, 4.167057291666667, 4.026822916666666, 4.010546875]
Epoch: 0, loss: 19.1719, lr: 0.00009755
epoch 1: 100%|██████████| 15/15 [00:52<00:00,  3.47s/it, cur_loss=11.9]
train acc=0.05603448275862069, [l1_loss, ce_loss] => [0.92861328125, 0.26775716145833334, 3.6546875, 3.76484375, 3.666015625]
Epoch: 1, loss: 12.2818, lr: 0.00009045
epoch 2: 100%|██████████| 15/15 [00:53<00:00,  3.53s/it, cur_loss=11.6]
train acc=0.10560344827586207, [l1_loss, ce_loss] => [0.623046875, 0.2579752604166667, 3.445703125, 3.6553385416666666, 3.484114583333333]
Epoch: 2, loss: 11.4646, lr: 0.00007939
epoch 3: 100%|██████████| 15/15 [00:57<00:00,  3.83s/it, cur_loss=11.2]
train acc=0.12607758620689655, [l1_loss, ce_loss] => [0.57421875, 0.27047526041666664, 3.3013020833333333, 3.581640625, 3.347916666666667]
Epoch: 3, loss: 11.0745, lr: 0.00006545
epoch 4: 100%|██████████| 15/15 [00:57<00:00,  3.81s/it, cur_loss=10.1]
train acc=0.16918103448275862, [l1_loss, ce_loss] => [0.5824869791666667, 0.27179361979166666, 3.1333333333333333, 3.4946614583333333, 3.1747395833333334]
Epoch: 4, loss: 10.6552, lr: 0.00005000
epoch 5: 100%|██████████| 15/15 [00:57<00:00,  3.84s/it, cur_loss=10.1]
train acc=0.2025862068965517, [l1_loss, ce_loss] => [0.59794921875, 0.27765299479166666, 3.0126302083333334, 3.4419270833333333, 3.055078125]
Epoch: 5, loss: 10.3854, lr: 0.00003455
epoch 6: 100%|██████████| 15/15 [00:57<00:00,  3.80s/it, cur_loss=10.2]
train acc=0.2521551724137931, [l1_loss, ce_loss] => [0.62451171875, 0.27737630208333336, 2.876953125, 3.41484375, 2.9286458333333334]
Epoch: 6, loss: 10.1234, lr: 0.00002061
epoch 7: 100%|██████████| 15/15 [00:57<00:00,  3.81s/it, cur_loss=10.5]
train acc=0.2855603448275862, [l1_loss, ce_loss] => [0.62177734375, 0.28201497395833336, 2.787369791666667, 3.373307291666667, 2.8403645833333333]
Epoch: 7, loss: 9.9052, lr: 0.00000955
epoch 8: 100%|██████████| 15/15 [00:57<00:00,  3.81s/it, cur_loss=9.77]
train acc=0.2920258620689655, [l1_loss, ce_loss] => [0.629296875, 0.28419596354166665, 2.7270833333333333, 3.344010416666667, 2.785026041666667]
Epoch: 8, loss: 9.7693, lr: 0.00000245
epoch 9: 100%|██████████| 15/15 [00:57<00:00,  3.81s/it, cur_loss=10.2]
train acc=0.2995689655172414, [l1_loss, ce_loss] => [0.6246744791666666, 0.28460286458333334, 2.724348958333333, 3.33046875, 2.779166666666667]
Epoch: 9, loss: 9.7443, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 44/44 [01:44<00:00,  2.37s/it]
Test F1-macro:  0.194164251202399
#######################################

Iteration:  3

#######################################
Training non-few shot model...
Train dataset size:  175
Test dataset size:  44
Training complete!

Test F1-macro:  0.6981584289057639
##########################################
2025-06-09 13:50:14 Getting cached textual weights W ...
2025-06-09 13:50:14 Loading texture features from ./__few_shot_cache__\indian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  15
Test dataset size:  44
epoch 0: 100%|██████████| 15/15 [01:05<00:00,  4.36s/it, cur_loss=13.7]
train acc=0.032327586206896554, [l1_loss, ce_loss] => [7.000423177083333, 0.303857421875, 4.1484375, 4.079947916666667, 4.043619791666667]
Epoch: 0, loss: 19.5760, lr: 0.00009755
epoch 1: 100%|██████████| 15/15 [01:07<00:00,  4.49s/it, cur_loss=12.6]
train acc=0.052801724137931036, [l1_loss, ce_loss] => [0.85205078125, 0.2548014322916667, 3.8171875, 3.87265625, 3.810416666666667]
Epoch: 1, loss: 12.6078, lr: 0.00009045
epoch 2: 100%|██████████| 15/15 [01:07<00:00,  4.49s/it, cur_loss=11.5]
train acc=0.0668103448275862, [l1_loss, ce_loss] => [0.565380859375, 0.2418701171875, 3.619140625, 3.74765625, 3.6557291666666667]
Epoch: 2, loss: 11.8292, lr: 0.00007939
epoch 3: 100%|██████████| 15/15 [01:07<00:00,  4.49s/it, cur_loss=11.3]
train acc=0.09159482758620689, [l1_loss, ce_loss] => [0.5232747395833334, 0.26592610677083334, 3.4657552083333334, 3.656380208333333, 3.5259114583333333]
Epoch: 3, loss: 11.4385, lr: 0.00006545
epoch 4: 100%|██████████| 15/15 [01:18<00:00,  5.26s/it, cur_loss=11.3]
train acc=0.12176724137931035, [l1_loss, ce_loss] => [0.53251953125, 0.2745279947916667, 3.339713541666667, 3.579296875, 3.3822916666666667]
Epoch: 4, loss: 11.1083, lr: 0.00005000
epoch 5: 100%|██████████| 15/15 [01:19<00:00,  5.32s/it, cur_loss=11.8]
train acc=0.16702586206896552, [l1_loss, ce_loss] => [0.5486653645833334, 0.28147786458333335, 3.2666666666666666, 3.557421875, 3.3032552083333333]
Epoch: 5, loss: 10.9573, lr: 0.00003455
epoch 6: 100%|██████████| 15/15 [01:19<00:00,  5.32s/it, cur_loss=10.5]
train acc=0.17780172413793102, [l1_loss, ce_loss] => [0.55927734375, 0.28175455729166665, 3.1548177083333333, 3.488020833333333, 3.19765625]
Epoch: 6, loss: 10.6813, lr: 0.00002061
epoch 7: 100%|██████████| 15/15 [01:19<00:00,  5.32s/it, cur_loss=10.3]
train acc=0.19181034482758622, [l1_loss, ce_loss] => [0.5712565104166667, 0.28330078125, 3.06796875, 3.462109375, 3.1177083333333333]
Epoch: 7, loss: 10.5016, lr: 0.00000955
epoch 8: 100%|██████████| 15/15 [01:19<00:00,  5.32s/it, cur_loss=10.5]
train acc=0.2165948275862069, [l1_loss, ce_loss] => [0.5707356770833333, 0.28486328125, 3.019270833333333, 3.43515625, 3.0713541666666666]
Epoch: 8, loss: 10.3818, lr: 0.00000245
epoch 9: 100%|██████████| 15/15 [01:19<00:00,  5.33s/it, cur_loss=10.3]
train acc=0.2036637931034483, [l1_loss, ce_loss] => [0.57529296875, 0.285595703125, 3.0376302083333333, 3.445442708333333, 3.083203125]
Epoch: 9, loss: 10.4281, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 44/44 [01:38<00:00,  2.24s/it]
Test F1-macro:  0.11067049975014052
#######################################

Iteration:  4

#######################################
Training non-few shot model...
Train dataset size:  175
Test dataset size:  44
Training complete!

Test F1-macro:  0.683011696888203
##########################################
2025-06-09 14:04:40 Getting cached textual weights W ...
2025-06-09 14:04:40 Loading texture features from ./__few_shot_cache__\indian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  15
Test dataset size:  44
epoch 0: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=13.6]
train acc=0.04741379310344827, [l1_loss, ce_loss] => [7.443815104166666, 0.2826904296875, 4.008723958333333, 4.02890625, 3.9399739583333333]
Epoch: 0, loss: 19.7026, lr: 0.00009755
epoch 1: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=11.9]
train acc=0.07866379310344827, [l1_loss, ce_loss] => [0.97666015625, 0.22412923177083333, 3.575911458333333, 3.8037760416666666, 3.6180989583333334]
Epoch: 1, loss: 12.1984, lr: 0.00009045
epoch 2: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=10.7]
train acc=0.10775862068965517, [l1_loss, ce_loss] => [0.6735677083333333, 0.23045247395833332, 3.369140625, 3.677994791666667, 3.431770833333333]
Epoch: 2, loss: 11.3823, lr: 0.00007939
epoch 3: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=11.3]
train acc=0.1206896551724138, [l1_loss, ce_loss] => [0.6013997395833334, 0.24034830729166667, 3.2411458333333334, 3.5845052083333333, 3.306770833333333]
Epoch: 3, loss: 10.9740, lr: 0.00006545
epoch 4: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=11]  
train acc=0.16702586206896552, [l1_loss, ce_loss] => [0.6164713541666667, 0.2565836588541667, 3.1201822916666666, 3.501822916666667, 3.1809895833333335]
Epoch: 4, loss: 10.6766, lr: 0.00005000
epoch 5: 100%|██████████| 15/15 [00:51<00:00,  3.46s/it, cur_loss=9.99]
train acc=0.18211206896551724, [l1_loss, ce_loss] => [0.63564453125, 0.268212890625, 3.009895833333333, 3.419661458333333, 3.0716145833333335]
Epoch: 5, loss: 10.4052, lr: 0.00003455
epoch 6: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=9.41]
train acc=0.22306034482758622, [l1_loss, ce_loss] => [0.6319661458333333, 0.28123372395833335, 2.867317708333333, 3.343359375, 2.93515625]
Epoch: 6, loss: 10.0594, lr: 0.00002061
epoch 7: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=9.67]
train acc=0.21767241379310345, [l1_loss, ce_loss] => [0.6552083333333333, 0.28880208333333335, 2.8149739583333333, 3.308463541666667, 2.889453125]
Epoch: 7, loss: 9.9568, lr: 0.00000955
epoch 8: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=9.9] 
train acc=0.2349137931034483, [l1_loss, ce_loss] => [0.652734375, 0.292822265625, 2.769270833333333, 3.263671875, 2.8368489583333334]
Epoch: 8, loss: 9.8161, lr: 0.00000245
epoch 9: 100%|██████████| 15/15 [00:51<00:00,  3.45s/it, cur_loss=9.83]
train acc=0.2510775862068966, [l1_loss, ce_loss] => [0.6561848958333333, 0.292578125, 2.7569010416666666, 3.26953125, 2.8236979166666667]
Epoch: 9, loss: 9.7979, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 44/44 [01:21<00:00,  1.86s/it]
Test F1-macro:  0.14402139398553662
#######################################
Processing the Kaggle dataset: persian_dataset
Processing images: 100%|██████████| 14405/14405 [00:19<00:00, 726.27it/s]
Number of filtered labels:  43
Number of removed labels:  0
Number of samples in the dataset:  14405

Iteration:  0

#######################################
Training non-few shot model...
Train dataset size:  181
Test dataset size:  46
Training complete!

Test F1-macro:  0.8756052663074253
##########################################
2025-06-09 14:16:04 Getting cached textual weights W ...
2025-06-09 14:16:04 Loading texture features from ./__few_shot_cache__\persian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  46
epoch 0: 100%|██████████| 11/11 [00:33<00:00,  3.05s/it, cur_loss=14.2]
train acc=0.046511627906976744, [l1_loss, ce_loss] => [11.278364701704545, 0.336181640625, 3.830078125, 3.815696022727273, 3.733487215909091]
Epoch: 0, loss: 22.9908, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:32<00:00,  2.99s/it, cur_loss=11.6]
train acc=0.11773255813953488, [l1_loss, ce_loss] => [1.5098544034090908, 0.27754350142045453, 3.237393465909091, 3.581321022727273, 3.305930397727273]
Epoch: 1, loss: 11.9134, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:31<00:00,  2.88s/it, cur_loss=10.8]
train acc=0.20930232558139536, [l1_loss, ce_loss] => [0.9555220170454546, 0.3040216619318182, 2.91015625, 3.3753551136363638, 2.9984019886363638]
Epoch: 2, loss: 10.5426, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:30<00:00,  2.81s/it, cur_loss=9.56]
train acc=0.30523255813953487, [l1_loss, ce_loss] => [0.7872425426136364, 0.3032892400568182, 2.5775923295454546, 3.2017045454545454, 2.698153409090909]
Epoch: 3, loss: 9.5682, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:33<00:00,  3.02s/it, cur_loss=8.78]
train acc=0.3648255813953488, [l1_loss, ce_loss] => [0.7824485085227273, 0.32581676136363635, 2.3126775568181817, 3.0623224431818183, 2.4398082386363638]
Epoch: 4, loss: 8.9247, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:33<00:00,  3.06s/it, cur_loss=8.23]
train acc=0.46511627906976744, [l1_loss, ce_loss] => [0.8098810369318182, 0.3476784446022727, 2.0869140625, 2.913174715909091, 2.200284090909091]
Epoch: 5, loss: 8.3572, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:33<00:00,  3.01s/it, cur_loss=8.22]
train acc=0.5145348837209303, [l1_loss, ce_loss] => [0.8086381392045454, 0.36217151988636365, 1.9148615056818181, 2.783203125, 2.0144708806818183]
Epoch: 6, loss: 7.8828, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:31<00:00,  2.89s/it, cur_loss=8.05]
train acc=0.5741279069767442, [l1_loss, ce_loss] => [0.8073508522727273, 0.36616654829545453, 1.7743252840909092, 2.7066761363636362, 1.8775745738636365]
Epoch: 7, loss: 7.5327, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:30<00:00,  2.82s/it, cur_loss=6.9] 
train acc=0.6322674418604651, [l1_loss, ce_loss] => [0.8063299005681818, 0.36723188920454547, 1.6638849431818181, 2.65234375, 1.7692649147727273]
Epoch: 8, loss: 7.2599, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:33<00:00,  3.02s/it, cur_loss=7.03]
train acc=0.6148255813953488, [l1_loss, ce_loss] => [0.80712890625, 0.3694735440340909, 1.6402698863636365, 2.634055397727273, 1.7417436079545454]
Epoch: 9, loss: 7.1925, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 46/46 [00:38<00:00,  1.19it/s]
Test F1-macro:  0.3381588033329393
#######################################

Iteration:  1

#######################################
Training non-few shot model...
Train dataset size:  181
Test dataset size:  46
Training complete!

Test F1-macro:  0.8782554275193896
##########################################
2025-06-09 14:23:09 Getting cached textual weights W ...
2025-06-09 14:23:09 Loading texture features from ./__few_shot_cache__\persian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  46
epoch 0: 100%|██████████| 11/11 [00:59<00:00,  5.38s/it, cur_loss=11.9]
train acc=0.03343023255813953, [l1_loss, ce_loss] => [10.033336292613637, 0.3205344460227273, 3.947975852272727, 3.7913707386363638, 3.7950994318181817]
Epoch: 0, loss: 21.8849, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:59<00:00,  5.39s/it, cur_loss=12]  
train acc=0.08284883720930232, [l1_loss, ce_loss] => [0.8165394176136364, 0.24113325639204544, 3.4692826704545454, 3.6051136363636362, 3.4888139204545454]
Epoch: 1, loss: 11.6214, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:59<00:00,  5.40s/it, cur_loss=10.8]
train acc=0.11918604651162791, [l1_loss, ce_loss] => [0.6525656960227273, 0.21624200994318182, 3.255149147727273, 3.5120738636363638, 3.323330965909091]
Epoch: 2, loss: 10.9581, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:59<00:00,  5.40s/it, cur_loss=10.4]
train acc=0.14970930232558138, [l1_loss, ce_loss] => [0.6216264204545454, 0.23511851917613635, 3.1148792613636362, 3.4174360795454546, 3.188210227272727]
Epoch: 3, loss: 10.5781, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:59<00:00,  5.39s/it, cur_loss=11.2]
train acc=0.16279069767441862, [l1_loss, ce_loss] => [0.6102627840909091, 0.2688321200284091, 3.0174005681818183, 3.327059659090909, 3.0823863636363638]
Epoch: 4, loss: 10.3068, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:59<00:00,  5.40s/it, cur_loss=10.1]
train acc=0.22529069767441862, [l1_loss, ce_loss] => [0.5860262784090909, 0.2827814275568182, 2.8849431818181817, 3.2418323863636362, 2.9564985795454546]
Epoch: 5, loss: 9.9538, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:59<00:00,  5.39s/it, cur_loss=9.55]
train acc=0.24273255813953487, [l1_loss, ce_loss] => [0.5956143465909091, 0.2900390625, 2.7833806818181817, 3.1800426136363638, 2.8694957386363638]
Epoch: 6, loss: 9.7180, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:59<00:00,  5.40s/it, cur_loss=9.94]
train acc=0.28924418604651164, [l1_loss, ce_loss] => [0.6083984375, 0.30286754261363635, 2.7105823863636362, 3.1292613636363638, 2.795987215909091]
Epoch: 7, loss: 9.5469, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:59<00:00,  5.39s/it, cur_loss=9.2] 
train acc=0.30523255813953487, [l1_loss, ce_loss] => [0.6108842329545454, 0.30668501420454547, 2.65234375, 3.096768465909091, 2.7423650568181817]
Epoch: 8, loss: 9.4084, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:59<00:00,  5.40s/it, cur_loss=9.52]
train acc=0.2921511627906977, [l1_loss, ce_loss] => [0.6096857244318182, 0.3080166903409091, 2.650390625, 3.091796875, 2.7405894886363638]
Epoch: 9, loss: 9.4013, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 46/46 [01:55<00:00,  2.51s/it]
Test F1-macro:  0.13920669361240143
#######################################

Iteration:  2

#######################################
Training non-few shot model...
Train dataset size:  181
Test dataset size:  46
Training complete!

Test F1-macro:  0.879552958700013
##########################################
2025-06-09 14:35:58 Getting cached textual weights W ...
2025-06-09 14:35:58 Loading texture features from ./__few_shot_cache__\persian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  46
epoch 0: 100%|██████████| 11/11 [00:32<00:00,  2.93s/it, cur_loss=13.8]
train acc=0.0188953488372093, [l1_loss, ce_loss] => [10.254083806818182, 0.31358753551136365, 3.9786931818181817, 3.814453125, 3.846413352272727]
Epoch: 0, loss: 22.2067, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:29<00:00,  2.68s/it, cur_loss=11.9]
train acc=0.06831395348837209, [l1_loss, ce_loss] => [1.1379616477272727, 0.25684703480113635, 3.621981534090909, 3.6693892045454546, 3.5843394886363638]
Epoch: 1, loss: 12.2706, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:29<00:00,  2.69s/it, cur_loss=11.2]
train acc=0.12063953488372094, [l1_loss, ce_loss] => [0.716796875, 0.23393110795454544, 3.387784090909091, 3.573153409090909, 3.4215198863636362]
Epoch: 2, loss: 11.3352, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:32<00:00,  2.96s/it, cur_loss=11]  
train acc=0.14098837209302326, [l1_loss, ce_loss] => [0.5621448863636364, 0.22993607954545456, 3.274680397727273, 3.503196022727273, 3.325284090909091]
Epoch: 3, loss: 10.8949, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:29<00:00,  2.69s/it, cur_loss=10.5]
train acc=0.15261627906976744, [l1_loss, ce_loss] => [0.5227716619318182, 0.24395197088068182, 3.1928267045454546, 3.422762784090909, 3.2359730113636362]
Epoch: 4, loss: 10.6179, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:29<00:00,  2.70s/it, cur_loss=10.3]
train acc=0.17877906976744187, [l1_loss, ce_loss] => [0.5108309659090909, 0.26109730113636365, 3.1265980113636362, 3.3552911931818183, 3.167080965909091]
Epoch: 5, loss: 10.4205, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:32<00:00,  2.96s/it, cur_loss=10]  
train acc=0.2005813953488372, [l1_loss, ce_loss] => [0.5275213068181818, 0.27381480823863635, 3.055397727272727, 3.303444602272727, 3.0994318181818183]
Epoch: 6, loss: 10.2592, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:29<00:00,  2.69s/it, cur_loss=10.3]
train acc=0.20348837209302326, [l1_loss, ce_loss] => [0.5216619318181818, 0.281982421875, 3.007102272727273, 3.2755681818181817, 3.0545099431818183]
Epoch: 7, loss: 10.1399, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:29<00:00,  2.70s/it, cur_loss=9.7] 
train acc=0.20930232558139536, [l1_loss, ce_loss] => [0.5239035866477273, 0.28642134232954547, 2.9802911931818183, 3.2444957386363638, 3.0189985795454546]
Epoch: 8, loss: 10.0554, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:32<00:00,  2.96s/it, cur_loss=10.1]
train acc=0.2136627906976744, [l1_loss, ce_loss] => [0.5227494673295454, 0.2852450284090909, 2.985617897727273, 3.2517755681818183, 3.024147727272727]
Epoch: 9, loss: 10.0689, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 46/46 [00:39<00:00,  1.16it/s]
Test F1-macro:  0.08839775412915396
#######################################

Iteration:  3

#######################################
Training non-few shot model...
Train dataset size:  181
Test dataset size:  46
Training complete!

Test F1-macro:  0.8683429741822927
##########################################
2025-06-09 14:42:46 Getting cached textual weights W ...
2025-06-09 14:42:46 Loading texture features from ./__few_shot_cache__\persian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  46
epoch 0: 100%|██████████| 11/11 [00:31<00:00,  2.84s/it, cur_loss=13.4]
train acc=0.020348837209302327, [l1_loss, ce_loss] => [12.752574573863637, 0.3221990411931818, 4.0735085227272725, 3.819247159090909, 3.8481889204545454]
Epoch: 0, loss: 24.8168, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:32<00:00,  2.94s/it, cur_loss=11.9]
train acc=0.04796511627906977, [l1_loss, ce_loss] => [1.7564364346590908, 0.26890980113636365, 3.7224786931818183, 3.6871448863636362, 3.6443536931818183]
Epoch: 1, loss: 13.0788, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:31<00:00,  2.89s/it, cur_loss=11.7]
train acc=0.07267441860465117, [l1_loss, ce_loss] => [0.8753551136363636, 0.22980291193181818, 3.5042613636363638, 3.6154119318181817, 3.5216619318181817]
Epoch: 2, loss: 11.7457, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:31<00:00,  2.88s/it, cur_loss=10.8]
train acc=0.11482558139534883, [l1_loss, ce_loss] => [0.6234907670454546, 0.2253085049715909, 3.32421875, 3.555752840909091, 3.389559659090909]
Epoch: 3, loss: 11.1179, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:31<00:00,  2.87s/it, cur_loss=10.7]
train acc=0.14098837209302326, [l1_loss, ce_loss] => [0.5448774857954546, 0.22669566761363635, 3.1970880681818183, 3.5021306818181817, 3.270241477272727]
Epoch: 4, loss: 10.7401, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:31<00:00,  2.88s/it, cur_loss=10.6]
train acc=0.18895348837209303, [l1_loss, ce_loss] => [0.5470969460227273, 0.23121226917613635, 3.0697798295454546, 3.454367897727273, 3.1424005681818183]
Epoch: 5, loss: 10.4432, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:31<00:00,  2.87s/it, cur_loss=10.3]
train acc=0.2136627906976744, [l1_loss, ce_loss] => [0.5551313920454546, 0.2416659268465909, 2.9614701704545454, 3.401455965909091, 3.038174715909091]
Epoch: 6, loss: 10.1982, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:31<00:00,  2.88s/it, cur_loss=10.1]
train acc=0.251453488372093, [l1_loss, ce_loss] => [0.5648970170454546, 0.24298650568181818, 2.872336647727273, 3.3902698863636362, 2.9547230113636362]
Epoch: 7, loss: 10.0241, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:31<00:00,  2.87s/it, cur_loss=9.76]
train acc=0.2616279069767442, [l1_loss, ce_loss] => [0.5665838068181818, 0.24739213423295456, 2.807883522727273, 3.3556463068181817, 2.897372159090909]
Epoch: 8, loss: 9.8757, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:31<00:00,  2.88s/it, cur_loss=10.2]
train acc=0.25726744186046513, [l1_loss, ce_loss] => [0.5680042613636364, 0.2474698153409091, 2.795632102272727, 3.346590909090909, 2.886008522727273]
Epoch: 9, loss: 9.8423, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 46/46 [00:52<00:00,  1.15s/it]
Test F1-macro:  0.11658786972814564
#######################################

Iteration:  4

#######################################
Training non-few shot model...
Train dataset size:  181
Test dataset size:  46
Training complete!

Test F1-macro:  0.8938582894042842
##########################################
2025-06-09 14:49:53 Getting cached textual weights W ...
2025-06-09 14:49:53 Loading texture features from ./__few_shot_cache__\persian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  46
epoch 0: 100%|██████████| 11/11 [00:24<00:00,  2.20s/it, cur_loss=13.7]
train acc=0.046511627906976744, [l1_loss, ce_loss] => [11.069602272727273, 0.3090154474431818, 4.024857954545454, 3.838600852272727, 3.837002840909091]
Epoch: 0, loss: 23.0774, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=11.5]
train acc=0.061046511627906974, [l1_loss, ce_loss] => [0.9991122159090909, 0.25264115767045453, 3.5662286931818183, 3.676491477272727, 3.53515625]
Epoch: 1, loss: 12.0298, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:23<00:00,  2.13s/it, cur_loss=11.1]
train acc=0.1380813953488372, [l1_loss, ce_loss] => [0.7444069602272727, 0.22355513139204544, 3.233309659090909, 3.583274147727273, 3.301491477272727]
Epoch: 2, loss: 11.0859, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:23<00:00,  2.13s/it, cur_loss=10.8]
train acc=0.17296511627906977, [l1_loss, ce_loss] => [0.6390713778409091, 0.23936878551136365, 3.117897727272727, 3.5060369318181817, 3.1876775568181817]
Epoch: 3, loss: 10.6896, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=10.1]
train acc=0.19622093023255813, [l1_loss, ce_loss] => [0.62841796875, 0.2618963068181818, 2.946555397727273, 3.4359019886363638, 3.0406605113636362]
Epoch: 4, loss: 10.3132, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:23<00:00,  2.13s/it, cur_loss=10]  
train acc=0.2616279069767442, [l1_loss, ce_loss] => [0.6444424715909091, 0.2753684303977273, 2.7933238636363638, 3.362393465909091, 2.891690340909091]
Epoch: 5, loss: 9.9680, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=9.25]
train acc=0.30377906976744184, [l1_loss, ce_loss] => [0.6631303267045454, 0.2862881747159091, 2.6088423295454546, 3.2872869318181817, 2.723899147727273]
Epoch: 6, loss: 9.5696, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:23<00:00,  2.15s/it, cur_loss=9.34]
train acc=0.34011627906976744, [l1_loss, ce_loss] => [0.6845259232954546, 0.29600941051136365, 2.530007102272727, 3.2423650568181817, 2.6500355113636362]
Epoch: 7, loss: 9.4027, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:23<00:00,  2.13s/it, cur_loss=8.82]
train acc=0.38953488372093026, [l1_loss, ce_loss] => [0.6905628551136364, 0.29942737926136365, 2.4334161931818183, 3.2056107954545454, 2.5564630681818183]
Epoch: 8, loss: 9.1854, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=8.86]
train acc=0.38226744186046513, [l1_loss, ce_loss] => [0.6850142045454546, 0.2992942116477273, 2.399502840909091, 3.1951349431818183, 2.5316051136363638]
Epoch: 9, loss: 9.1108, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 46/46 [00:34<00:00,  1.34it/s]
Test F1-macro:  0.18335961353524008
#######################################
Processing the Kaggle dataset: bangladesh_dataset
Processing images: 100%|██████████| 73139/73139 [01:05<00:00, 1108.72it/s]
Number of filtered labels:  43
Number of removed labels:  0
Number of samples in the dataset:  73139

Iteration:  0

#######################################
Training non-few shot model...
Train dataset size:  915
Test dataset size:  229
Training complete!

Test F1-macro:  0.9741627100364023
##########################################
2025-06-09 14:57:33 Getting cached textual weights W ...
2025-06-09 14:57:33 Loading texture features from ./__few_shot_cache__\bangladesh_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  229
epoch 0: 100%|██████████| 11/11 [00:27<00:00,  2.52s/it, cur_loss=13.6]
train acc=0.03924418604651163, [l1_loss, ce_loss] => [9.137961647727273, 0.3060857599431818, 3.9302201704545454, 3.834872159090909, 3.8283025568181817]
Epoch: 0, loss: 21.0405, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:28<00:00,  2.57s/it, cur_loss=12.2]
train acc=0.07412790697674419, [l1_loss, ce_loss] => [0.9651988636363636, 0.21085981889204544, 3.6322798295454546, 3.7212357954545454, 3.6255326704545454]
Epoch: 1, loss: 12.1548, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:25<00:00,  2.36s/it, cur_loss=11.6]
train acc=0.07994186046511628, [l1_loss, ce_loss] => [0.6363858309659091, 0.196533203125, 3.5213068181818183, 3.646484375, 3.5255681818181817]
Epoch: 2, loss: 11.5256, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:25<00:00,  2.36s/it, cur_loss=11.1]
train acc=0.11627906976744186, [l1_loss, ce_loss] => [0.47472034801136365, 0.17711292613636365, 3.3771306818181817, 3.6010298295454546, 3.4122869318181817]
Epoch: 3, loss: 11.0419, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:27<00:00,  2.51s/it, cur_loss=10.8]
train acc=0.18313953488372092, [l1_loss, ce_loss] => [0.4624689275568182, 0.17612526633522727, 3.2322443181818183, 3.561257102272727, 3.2739701704545454]
Epoch: 4, loss: 10.7074, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:29<00:00,  2.67s/it, cur_loss=10.6]
train acc=0.18313953488372092, [l1_loss, ce_loss] => [0.4736993963068182, 0.17872203480113635, 3.1148792613636362, 3.5193536931818183, 3.155362215909091]
Epoch: 5, loss: 10.4425, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:28<00:00,  2.57s/it, cur_loss=10.2]
train acc=0.20348837209302326, [l1_loss, ce_loss] => [0.48741566051136365, 0.1827059659090909, 3.033203125, 3.4884588068181817, 3.0688920454545454]
Epoch: 6, loss: 10.2599, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:26<00:00,  2.39s/it, cur_loss=9.77]
train acc=0.2311046511627907, [l1_loss, ce_loss] => [0.48255504261363635, 0.18682306463068182, 2.9474431818181817, 3.4604048295454546, 2.9881036931818183]
Epoch: 7, loss: 10.0646, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:26<00:00,  2.37s/it, cur_loss=9.58]
train acc=0.24709302325581395, [l1_loss, ce_loss] => [0.4964266690340909, 0.18914240056818182, 2.8755326704545454, 3.4389204545454546, 2.917080965909091]
Epoch: 8, loss: 9.9176, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:27<00:00,  2.51s/it, cur_loss=10.1]
train acc=0.25726744186046513, [l1_loss, ce_loss] => [0.497314453125, 0.1898526278409091, 2.8774857954545454, 3.446377840909091, 2.926491477272727]
Epoch: 9, loss: 9.9375, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 229/229 [02:03<00:00,  1.85it/s]
Test F1-macro:  0.0806935802118311
#######################################

Iteration:  1

#######################################
Training non-few shot model...
Train dataset size:  915
Test dataset size:  229
Training complete!

Test F1-macro:  0.9703814375234473
##########################################
2025-06-09 15:06:04 Getting cached textual weights W ...
2025-06-09 15:06:04 Loading texture features from ./__few_shot_cache__\bangladesh_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  229
epoch 0: 100%|██████████| 11/11 [00:51<00:00,  4.64s/it, cur_loss=15.7]
train acc=0.03197674418604651, [l1_loss, ce_loss] => [9.111416903409092, 0.3095481178977273, 4.072620738636363, 3.8462357954545454, 3.878196022727273]
Epoch: 0, loss: 21.2173, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:59<00:00,  5.38s/it, cur_loss=12.6]
train acc=0.0436046511627907, [l1_loss, ce_loss] => [1.2753462357954546, 0.21123712713068182, 3.7737926136363638, 3.743252840909091, 3.7017045454545454]
Epoch: 1, loss: 12.7038, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:59<00:00,  5.39s/it, cur_loss=11.4]
train acc=0.07412790697674419, [l1_loss, ce_loss] => [0.6755149147727273, 0.1809414950284091, 3.6205610795454546, 3.6860795454545454, 3.615944602272727]
Epoch: 2, loss: 11.7777, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:59<00:00,  5.39s/it, cur_loss=11.5]
train acc=0.07994186046511628, [l1_loss, ce_loss] => [0.5015536221590909, 0.16216486150568182, 3.5783025568181817, 3.662109375, 3.5955255681818183]
Epoch: 3, loss: 11.4986, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:52<00:00,  4.77s/it, cur_loss=11.4]
train acc=0.09156976744186046, [l1_loss, ce_loss] => [0.3756658380681818, 0.16074440696022727, 3.549538352272727, 3.651455965909091, 3.57421875]
Epoch: 4, loss: 11.3118, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:51<00:00,  4.67s/it, cur_loss=11.4]
train acc=0.09011627906976744, [l1_loss, ce_loss] => [0.34825550426136365, 0.14679509943181818, 3.547762784090909, 3.6408025568181817, 3.5640980113636362]
Epoch: 5, loss: 11.2464, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:51<00:00,  4.67s/it, cur_loss=11] 
train acc=0.09593023255813954, [l1_loss, ce_loss] => [0.29283558238636365, 0.14072487571022727, 3.5200639204545454, 3.6303267045454546, 3.535866477272727]
Epoch: 6, loss: 11.1214, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:51<00:00,  4.67s/it, cur_loss=10.6]
train acc=0.09738372093023256, [l1_loss, ce_loss] => [0.27119584517045453, 0.14111328125, 3.512961647727273, 3.6244673295454546, 3.5314275568181817]
Epoch: 7, loss: 11.0810, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:51<00:00,  4.67s/it, cur_loss=11.2]
train acc=0.10465116279069768, [l1_loss, ce_loss] => [0.2644264914772727, 0.14317737926136365, 3.512606534090909, 3.6209161931818183, 3.5287642045454546]
Epoch: 8, loss: 11.0703, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:51<00:00,  4.67s/it, cur_loss=11.1]
train acc=0.1002906976744186, [l1_loss, ce_loss] => [0.2642489346590909, 0.13916015625, 3.516867897727273, 3.6214488636363638, 3.5308948863636362]
Epoch: 9, loss: 11.0717, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 229/229 [08:18<00:00,  2.18s/it]
Test F1-macro:  0.016076800440061104
#######################################

Iteration:  2

#######################################
Training non-few shot model...
Train dataset size:  915
Test dataset size:  229
Training complete!

Test F1-macro:  0.9681925206515251
##########################################
2025-06-09 15:25:14 Getting cached textual weights W ...
2025-06-09 15:25:14 Loading texture features from ./__few_shot_cache__\bangladesh_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  229
epoch 0: 100%|██████████| 11/11 [00:26<00:00,  2.42s/it, cur_loss=13.1]
train acc=0.027616279069767442, [l1_loss, ce_loss] => [10.685014204545455, 0.2925470525568182, 3.9604048295454546, 3.8158735795454546, 3.8240411931818183]
Epoch: 0, loss: 22.5753, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:24<00:00,  2.27s/it, cur_loss=12.6]
train acc=0.036337209302325583, [l1_loss, ce_loss] => [1.3182262073863635, 0.2389248934659091, 3.7143110795454546, 3.7109375, 3.6732954545454546]
Epoch: 1, loss: 12.6577, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:25<00:00,  2.30s/it, cur_loss=11.5]
train acc=0.05377906976744186, [l1_loss, ce_loss] => [0.6384721235795454, 0.20085005326704544, 3.6060014204545454, 3.6754261363636362, 3.6214488636363638]
Epoch: 2, loss: 11.7429, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it, cur_loss=11.3]
train acc=0.07412790697674419, [l1_loss, ce_loss] => [0.4036310369318182, 0.17018821022727273, 3.580788352272727, 3.647194602272727, 3.602805397727273]
Epoch: 3, loss: 11.4048, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:24<00:00,  2.27s/it, cur_loss=11.2]
train acc=0.06976744186046512, [l1_loss, ce_loss] => [0.3410422585227273, 0.15087890625, 3.5779474431818183, 3.6427556818181817, 3.5981889204545454]
Epoch: 4, loss: 11.3118, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:25<00:00,  2.31s/it, cur_loss=11.2]
train acc=0.0755813953488372, [l1_loss, ce_loss] => [0.3056418678977273, 0.15116743607954544, 3.5525568181818183, 3.6214488636363638, 3.5719105113636362]
Epoch: 5, loss: 11.2024, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:26<00:00,  2.45s/it, cur_loss=11.2]
train acc=0.09302325581395349, [l1_loss, ce_loss] => [0.27001953125, 0.15528453480113635, 3.54296875, 3.6134588068181817, 3.5584161931818183]
Epoch: 6, loss: 11.1399, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:24<00:00,  2.27s/it, cur_loss=11.2]
train acc=0.09593023255813954, [l1_loss, ce_loss] => [0.2587002840909091, 0.15595037286931818, 3.5330255681818183, 3.6097301136363638, 3.549715909090909]
Epoch: 7, loss: 11.1072, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:25<00:00,  2.30s/it, cur_loss=11]  
train acc=0.10174418604651163, [l1_loss, ce_loss] => [0.2555930397727273, 0.15623890269886365, 3.5170454545454546, 3.5990767045454546, 3.534446022727273]
Epoch: 8, loss: 11.0625, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:26<00:00,  2.45s/it, cur_loss=11.3]
train acc=0.10319767441860465, [l1_loss, ce_loss] => [0.2530184659090909, 0.15684925426136365, 3.521484375, 3.604403409090909, 3.538174715909091]
Epoch: 9, loss: 11.0739, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 229/229 [02:00<00:00,  1.90it/s]
Test F1-macro:  0.014479046584455788
#######################################

Iteration:  3

#######################################
Training non-few shot model...
Train dataset size:  915
Test dataset size:  229
Training complete!

Test F1-macro:  0.9713644800252019
##########################################
2025-06-09 15:33:28 Getting cached textual weights W ...
2025-06-09 15:33:28 Loading texture features from ./__few_shot_cache__\bangladesh_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  229
epoch 0: 100%|██████████| 11/11 [00:30<00:00,  2.77s/it, cur_loss=14.9]
train acc=0.024709302325581394, [l1_loss, ce_loss] => [10.381392045454545, 0.329345703125, 3.9431818181818183, 3.821555397727273, 3.8217329545454546]
Epoch: 0, loss: 22.2969, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:31<00:00,  2.86s/it, cur_loss=12.5]
train acc=0.06540697674418605, [l1_loss, ce_loss] => [1.9288441051136365, 0.2564031427556818, 3.6875, 3.696377840909091, 3.6402698863636362]
Epoch: 1, loss: 13.2109, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:31<00:00,  2.85s/it, cur_loss=11.6]
train acc=0.09447674418604651, [l1_loss, ce_loss] => [0.738037109375, 0.21052689985795456, 3.5111860795454546, 3.6518110795454546, 3.5333806818181817]
Epoch: 2, loss: 11.6442, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:31<00:00,  2.87s/it, cur_loss=10.8]
train acc=0.14680232558139536, [l1_loss, ce_loss] => [0.5471413352272727, 0.1884765625, 3.3441051136363638, 3.595703125, 3.395596590909091]
Epoch: 3, loss: 11.0717, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:31<00:00,  2.83s/it, cur_loss=11.1]
train acc=0.17877906976744187, [l1_loss, ce_loss] => [0.5211514559659091, 0.18577991832386365, 3.2171519886363638, 3.5550426136363638, 3.272194602272727]
Epoch: 4, loss: 10.7507, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:31<00:00,  2.86s/it, cur_loss=10]  
train acc=0.20930232558139536, [l1_loss, ce_loss] => [0.5094105113636364, 0.19233842329545456, 3.088955965909091, 3.5138494318181817, 3.151633522727273]
Epoch: 5, loss: 10.4553, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:31<00:00,  2.82s/it, cur_loss=10.4]
train acc=0.23837209302325582, [l1_loss, ce_loss] => [0.5176890980113636, 0.19167258522727273, 2.995205965909091, 3.481356534090909, 3.059303977272727]
Epoch: 6, loss: 10.2464, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:31<00:00,  2.86s/it, cur_loss=10.3]
train acc=0.24273255813953487, [l1_loss, ce_loss] => [0.5450106534090909, 0.19921875, 2.921875, 3.458274147727273, 2.9904119318181817]
Epoch: 7, loss: 10.1143, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:31<00:00,  2.83s/it, cur_loss=9.95]
train acc=0.27180232558139533, [l1_loss, ce_loss] => [0.5403941761363636, 0.20124955610795456, 2.8673650568181817, 3.4373224431818183, 2.9376775568181817]
Epoch: 8, loss: 9.9837, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:31<00:00,  2.87s/it, cur_loss=10] 
train acc=0.24709302325581395, [l1_loss, ce_loss] => [0.5420365767045454, 0.20319158380681818, 2.8494318181818183, 3.425071022727273, 2.919921875]
Epoch: 9, loss: 9.9396, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 229/229 [03:24<00:00,  1.12it/s]
Test F1-macro:  0.07840916348046101
#######################################

Iteration:  4

#######################################
Training non-few shot model...
Train dataset size:  915
Test dataset size:  229
Training complete!

Test F1-macro:  0.9712957482625112
##########################################
2025-06-09 15:44:01 Getting cached textual weights W ...
2025-06-09 15:44:01 Loading texture features from ./__few_shot_cache__\bangladesh_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  229
epoch 0: 100%|██████████| 11/11 [00:23<00:00,  2.18s/it, cur_loss=13.5]
train acc=0.03488372093023256, [l1_loss, ce_loss] => [10.735973011363637, 0.2790860262784091, 3.960227272727273, 3.8125, 3.8226207386363638]
Epoch: 0, loss: 22.6101, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=13.5]
train acc=0.061046511627906974, [l1_loss, ce_loss] => [2.6337890625, 0.1874667080965909, 3.680397727272727, 3.729758522727273, 3.6468394886363638]
Epoch: 1, loss: 13.8764, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=11.5]
train acc=0.09156976744186046, [l1_loss, ce_loss] => [1.0346235795454546, 0.15339799360795456, 3.5426136363636362, 3.665305397727273, 3.563387784090909]
Epoch: 2, loss: 11.9595, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=11.2]
train acc=0.11337209302325581, [l1_loss, ce_loss] => [0.7001287286931818, 0.14918101917613635, 3.461647727272727, 3.633700284090909, 3.502663352272727]
Epoch: 3, loss: 11.4489, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=11.2]
train acc=0.10465116279069768, [l1_loss, ce_loss] => [0.516357421875, 0.15138938210227273, 3.408203125, 3.606534090909091, 3.4536576704545454]
Epoch: 4, loss: 11.1364, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:23<00:00,  2.13s/it, cur_loss=10.8]
train acc=0.125, [l1_loss, ce_loss] => [0.4233176491477273, 0.14705033735795456, 3.353515625, 3.5864701704545454, 3.4037642045454546]
Epoch: 5, loss: 10.9148, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:23<00:00,  2.13s/it, cur_loss=10.7]
train acc=0.14825581395348839, [l1_loss, ce_loss] => [0.39610706676136365, 0.14872602982954544, 3.30859375, 3.5678267045454546, 3.357421875]
Epoch: 6, loss: 10.7784, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=10.7]
train acc=0.16424418604651161, [l1_loss, ce_loss] => [0.39717240767045453, 0.15477405894886365, 3.266690340909091, 3.557528409090909, 3.3181818181818183]
Epoch: 7, loss: 10.6953, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=11.1]
train acc=0.16715116279069767, [l1_loss, ce_loss] => [0.3975275213068182, 0.15381969105113635, 3.2562144886363638, 3.552024147727273, 3.305930397727273]
Epoch: 8, loss: 10.6648, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:23<00:00,  2.14s/it, cur_loss=10.5]
train acc=0.1686046511627907, [l1_loss, ce_loss] => [0.39635120738636365, 0.15424138849431818, 3.247336647727273, 3.555930397727273, 3.3004261363636362]
Epoch: 9, loss: 10.6527, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 229/229 [02:01<00:00,  1.89it/s]
Test F1-macro:  0.04066035353175917
#######################################
Using the latest cached version of the dataset since kuchidareo/chinese_trafficsign_dataset couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at dataset\HuggingFace\chinese_dataset\kuchidareo___chinese_trafficsign_dataset\default\0.0.0\48bc20b7796a3a061deaacf98d4bf188ecc2bdbc (last modified on Sun Jun  8 21:48:26 2025).
Processing the Hugging Face dataset: chinese_dataset
Processing images: 100%|██████████| 5902/5902 [00:00<00:00, 1038763.89it/s]
Number of filtered labels:  47
Number of removed labels:  11
Number of samples in the dataset:  5902

Iteration:  0

#######################################
Training non-few shot model...
Train dataset size:  74
Test dataset size:  19
Training complete!

Test F1-macro:  0.8198023309033463
##########################################
2025-06-09 15:50:22 Getting cached textual weights W ...
2025-06-09 15:50:22 Loading texture features from ./__few_shot_cache__\chinese_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  12
Test dataset size:  19
epoch 0: 100%|██████████| 12/12 [00:26<00:00,  2.21s/it, cur_loss=12.7]
train acc=0.043882978723404256, [l1_loss, ce_loss] => [9.2852783203125, 0.3077189127604167, 4.118489583333333, 3.8712565104166665, 3.857421875]
Epoch: 0, loss: 21.4401, lr: 0.00009755
epoch 1: 100%|██████████| 12/12 [00:28<00:00,  2.37s/it, cur_loss=11.4]
train acc=0.16489361702127658, [l1_loss, ce_loss] => [0.8223063151041666, 0.2663777669270833, 3.4052734375, 3.6549479166666665, 3.4361979166666665]
Epoch: 1, loss: 11.5853, lr: 0.00009045
epoch 2: 100%|██████████| 12/12 [00:27<00:00,  2.25s/it, cur_loss=10.3]
train acc=0.2393617021276596, [l1_loss, ce_loss] => [0.726806640625, 0.28485107421875, 2.9427083333333335, 3.4601236979166665, 3.0826822916666665]
Epoch: 2, loss: 10.4974, lr: 0.00007939
epoch 3: 100%|██████████| 12/12 [00:25<00:00,  2.13s/it, cur_loss=9.77]
train acc=0.3204787234042553, [l1_loss, ce_loss] => [0.7859700520833334, 0.31768798828125, 2.5486653645833335, 3.2859700520833335, 2.7242838541666665]
Epoch: 3, loss: 9.6615, lr: 0.00006545
epoch 4: 100%|██████████| 12/12 [00:25<00:00,  2.11s/it, cur_loss=8.26]
train acc=0.39361702127659576, [l1_loss, ce_loss] => [0.7823486328125, 0.3452962239583333, 2.2529296875, 3.1092122395833335, 2.4156901041666665]
Epoch: 4, loss: 8.9043, lr: 0.00005000
epoch 5: 100%|██████████| 12/12 [00:27<00:00,  2.27s/it, cur_loss=8.75]
train acc=0.4654255319148936, [l1_loss, ce_loss] => [0.7869873046875, 0.3729044596354167, 1.9922688802083333, 2.9615885416666665, 2.151611328125]
Epoch: 5, loss: 8.2653, lr: 0.00003455
epoch 6: 100%|██████████| 12/12 [00:26<00:00,  2.23s/it, cur_loss=7.32]
train acc=0.5625, [l1_loss, ce_loss] => [0.802490234375, 0.3864339192708333, 1.7836100260416667, 2.8331705729166665, 1.931884765625]
Epoch: 6, loss: 7.7376, lr: 0.00002061
epoch 7: 100%|██████████| 12/12 [00:26<00:00,  2.21s/it, cur_loss=7.73]
train acc=0.6077127659574468, [l1_loss, ce_loss] => [0.7998046875, 0.3917643229166667, 1.6331380208333333, 2.7275390625, 1.7797037760416667]
Epoch: 7, loss: 7.3324, lr: 0.00000955
epoch 8: 100%|██████████| 12/12 [00:25<00:00,  2.13s/it, cur_loss=6.98]
train acc=0.6648936170212766, [l1_loss, ce_loss] => [0.794189453125, 0.39453125, 1.5437825520833333, 2.6730143229166665, 1.69287109375]
Epoch: 8, loss: 7.0983, lr: 0.00000245
epoch 9: 100%|██████████| 12/12 [00:25<00:00,  2.11s/it, cur_loss=6.77]
train acc=0.6502659574468085, [l1_loss, ce_loss] => [0.79345703125, 0.3947550455729167, 1.5099283854166667, 2.6534830729166665, 1.6640625]
Epoch: 9, loss: 7.0160, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 19/19 [00:12<00:00,  1.49it/s]
Test F1-macro:  0.3733402859566345
#######################################

Iteration:  1

#######################################
Training non-few shot model...
Train dataset size:  74
Test dataset size:  19
Training complete!

Test F1-macro:  0.8342146892641877
##########################################
2025-06-09 15:55:22 Getting cached textual weights W ...
2025-06-09 15:55:22 Loading texture features from ./__few_shot_cache__\chinese_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  12
Test dataset size:  19
epoch 0: 100%|██████████| 12/12 [00:51<00:00,  4.31s/it, cur_loss=12.9]
train acc=0.0398936170212766, [l1_loss, ce_loss] => [8.506998697916666, 0.3213907877604167, 4.074544270833333, 3.9415690104166665, 3.9034830729166665]
Epoch: 0, loss: 20.7513, lr: 0.00009755
epoch 1: 100%|██████████| 12/12 [00:50<00:00,  4.17s/it, cur_loss=11.9]
train acc=0.07845744680851063, [l1_loss, ce_loss] => [0.97412109375, 0.2586161295572917, 3.6844075520833335, 3.7451171875, 3.6407877604166665]
Epoch: 1, loss: 12.3034, lr: 0.00009045
epoch 2: 100%|██████████| 12/12 [00:52<00:00,  4.33s/it, cur_loss=11.3]
train acc=0.09707446808510638, [l1_loss, ce_loss] => [0.678466796875, 0.2642822265625, 3.5177408854166665, 3.60888671875, 3.517578125]
Epoch: 2, loss: 11.5866, lr: 0.00007939
epoch 3: 100%|██████████| 12/12 [00:50<00:00,  4.19s/it, cur_loss=10.8]
train acc=0.14893617021276595, [l1_loss, ce_loss] => [0.61572265625, 0.2817789713541667, 3.2540690104166665, 3.4794921875, 3.3243815104166665]
Epoch: 3, loss: 10.9564, lr: 0.00006545
epoch 4: 100%|██████████| 12/12 [00:52<00:00,  4.34s/it, cur_loss=9.71]
train acc=0.22074468085106383, [l1_loss, ce_loss] => [0.6594645182291666, 0.3018798828125, 2.9851888020833335, 3.3575846354166665, 3.115234375]
Epoch: 4, loss: 10.4186, lr: 0.00005000
epoch 5: 100%|██████████| 12/12 [00:50<00:00,  4.17s/it, cur_loss=10.3]
train acc=0.23404255319148937, [l1_loss, ce_loss] => [0.6786702473958334, 0.3230794270833333, 2.81005859375, 3.2560221354166665, 2.9401041666666665]
Epoch: 5, loss: 10.0091, lr: 0.00003455
epoch 6: 100%|██████████| 12/12 [00:52<00:00,  4.35s/it, cur_loss=9.88]
train acc=0.30186170212765956, [l1_loss, ce_loss] => [0.6789957682291666, 0.3399658203125, 2.64111328125, 3.1774088541666665, 2.7919921875]
Epoch: 6, loss: 9.6283, lr: 0.00002061
epoch 7: 100%|██████████| 12/12 [00:50<00:00,  4.17s/it, cur_loss=9.37]
train acc=0.3497340425531915, [l1_loss, ce_loss] => [0.6990559895833334, 0.3483072916666667, 2.5301106770833335, 3.1227213541666665, 2.6863606770833335]
Epoch: 7, loss: 9.3874, lr: 0.00000955
epoch 8: 100%|██████████| 12/12 [00:52<00:00,  4.34s/it, cur_loss=9.34]
train acc=0.3617021276595745, [l1_loss, ce_loss] => [0.6919352213541666, 0.3500773111979167, 2.4568684895833335, 3.06884765625, 2.6106770833333335]
Epoch: 8, loss: 9.1790, lr: 0.00000245
epoch 9: 100%|██████████| 12/12 [00:50<00:00,  4.17s/it, cur_loss=9.02]
train acc=0.37101063829787234, [l1_loss, ce_loss] => [0.6930745442708334, 0.3517659505208333, 2.4420572916666665, 3.0628255208333335, 2.5963541666666665]
Epoch: 9, loss: 9.1458, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 19/19 [00:40<00:00,  2.15s/it]
Test F1-macro:  0.1691296748019944
#######################################

Iteration:  2

#######################################
Training non-few shot model...
Train dataset size:  74
Test dataset size:  19
Training complete!

Test F1-macro:  0.8306841576408132
##########################################
2025-06-09 16:04:56 Getting cached textual weights W ...
2025-06-09 16:04:56 Loading texture features from ./__few_shot_cache__\chinese_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  12
Test dataset size:  19
epoch 0: 100%|██████████| 12/12 [00:24<00:00,  2.00s/it, cur_loss=12.8]
train acc=0.02526595744680851, [l1_loss, ce_loss] => [8.241861979166666, 0.2770894368489583, 4.187174479166667, 3.9069010416666665, 3.95458984375]
Epoch: 0, loss: 20.5677, lr: 0.00009755
epoch 1: 100%|██████████| 12/12 [00:24<00:00,  2.06s/it, cur_loss=11.9]
train acc=0.0797872340425532, [l1_loss, ce_loss] => [0.9290364583333334, 0.22764078776041666, 3.76708984375, 3.7711588541666665, 3.7042643229166665]
Epoch: 1, loss: 12.3997, lr: 0.00009045
epoch 2: 100%|██████████| 12/12 [00:24<00:00,  2.06s/it, cur_loss=11.6]
train acc=0.12632978723404256, [l1_loss, ce_loss] => [0.6260172526041666, 0.19856770833333334, 3.5476888020833335, 3.6915690104166665, 3.58154296875]
Epoch: 2, loss: 11.6445, lr: 0.00007939
epoch 3: 100%|██████████| 12/12 [00:25<00:00,  2.12s/it, cur_loss=11]  
train acc=0.13031914893617022, [l1_loss, ce_loss] => [0.5498453776041666, 0.21552530924479166, 3.3678385416666665, 3.58642578125, 3.431640625]
Epoch: 3, loss: 11.1517, lr: 0.00006545
epoch 4: 100%|██████████| 12/12 [00:26<00:00,  2.21s/it, cur_loss=11.3]
train acc=0.18351063829787234, [l1_loss, ce_loss] => [0.548583984375, 0.244476318359375, 3.2239583333333335, 3.4908854166666665, 3.2972005208333335]
Epoch: 4, loss: 10.8040, lr: 0.00005000
epoch 5: 100%|██████████| 12/12 [00:24<00:00,  2.00s/it, cur_loss=11]  
train acc=0.21143617021276595, [l1_loss, ce_loss] => [0.5615234375, 0.26861572265625, 3.0877278645833335, 3.40673828125, 3.1756184895833335]
Epoch: 5, loss: 10.5013, lr: 0.00003455
epoch 6: 100%|██████████| 12/12 [00:24<00:00,  2.06s/it, cur_loss=10]  
train acc=0.23537234042553193, [l1_loss, ce_loss] => [0.5746256510416666, 0.2834065755208333, 2.9778645833333335, 3.32763671875, 3.0646158854166665]
Epoch: 6, loss: 10.2272, lr: 0.00002061
epoch 7: 100%|██████████| 12/12 [00:24<00:00,  2.06s/it, cur_loss=10.7]
train acc=0.2632978723404255, [l1_loss, ce_loss] => [0.5732421875, 0.2943929036458333, 2.91552734375, 3.2888997395833335, 3.0052083333333335]
Epoch: 7, loss: 10.0775, lr: 0.00000955
epoch 8: 100%|██████████| 12/12 [00:25<00:00,  2.12s/it, cur_loss=10.1]
train acc=0.26728723404255317, [l1_loss, ce_loss] => [0.5834554036458334, 0.2990519205729167, 2.85400390625, 3.24609375, 2.9471028645833335]
Epoch: 8, loss: 9.9303, lr: 0.00000245
epoch 9: 100%|██████████| 12/12 [00:26<00:00,  2.23s/it, cur_loss=9.58]
train acc=0.2752659574468085, [l1_loss, ce_loss] => [0.5805257161458334, 0.3011067708333333, 2.8453776041666665, 3.2320963541666665, 2.935546875]
Epoch: 9, loss: 9.8965, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 19/19 [00:12<00:00,  1.52it/s]
Test F1-macro:  0.11202082439272944
#######################################

Iteration:  3

#######################################
Training non-few shot model...
Train dataset size:  74
Test dataset size:  19
Training complete!

Test F1-macro:  0.8229588012993989
##########################################
2025-06-09 16:09:41 Getting cached textual weights W ...
2025-06-09 16:09:41 Loading texture features from ./__few_shot_cache__\chinese_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  12
Test dataset size:  19
epoch 0: 100%|██████████| 12/12 [00:32<00:00,  2.68s/it, cur_loss=14.5]
train acc=0.031914893617021274, [l1_loss, ce_loss] => [8.987955729166666, 0.3210856119791667, 4.243326822916667, 3.9059244791666665, 3.9581705729166665]
Epoch: 0, loss: 21.4180, lr: 0.00009755
epoch 1: 100%|██████████| 12/12 [00:31<00:00,  2.66s/it, cur_loss=12.7]
train acc=0.07579787234042554, [l1_loss, ce_loss] => [1.7018229166666667, 0.21978759765625, 3.8567708333333335, 3.78759765625, 3.7430013020833335]
Epoch: 1, loss: 13.3079, lr: 0.00009045
epoch 2: 100%|██████████| 12/12 [00:30<00:00,  2.55s/it, cur_loss=11.4]
train acc=0.09308510638297872, [l1_loss, ce_loss] => [0.802490234375, 0.21178181966145834, 3.6495768229166665, 3.6985677083333335, 3.6253255208333335]
Epoch: 2, loss: 11.9876, lr: 0.00007939
epoch 3: 100%|██████████| 12/12 [00:32<00:00,  2.71s/it, cur_loss=11.6]
train acc=0.1196808510638298, [l1_loss, ce_loss] => [0.5994466145833334, 0.22890218098958334, 3.5128580729166665, 3.63427734375, 3.5358072916666665]
Epoch: 3, loss: 11.5098, lr: 0.00006545
epoch 4: 100%|██████████| 12/12 [00:30<00:00,  2.53s/it, cur_loss=11]  
train acc=0.13962765957446807, [l1_loss, ce_loss] => [0.5095418294270834, 0.23848470052083334, 3.3984375, 3.5753580729166665, 3.4529622395833335]
Epoch: 4, loss: 11.1751, lr: 0.00005000
epoch 5: 100%|██████████| 12/12 [00:32<00:00,  2.71s/it, cur_loss=10.9]
train acc=0.17420212765957446, [l1_loss, ce_loss] => [0.50640869140625, 0.24977620442708334, 3.2666015625, 3.5167643229166665, 3.3375651041666665]
Epoch: 5, loss: 10.8776, lr: 0.00003455
epoch 6: 100%|██████████| 12/12 [00:30<00:00,  2.54s/it, cur_loss=10.8]
train acc=0.20212765957446807, [l1_loss, ce_loss] => [0.5152791341145834, 0.2575480143229167, 3.1837565104166665, 3.4716796875, 3.2581380208333335]
Epoch: 6, loss: 10.6862, lr: 0.00002061
epoch 7: 100%|██████████| 12/12 [00:32<00:00,  2.71s/it, cur_loss=10.8]
train acc=0.20611702127659576, [l1_loss, ce_loss] => [0.5301106770833334, 0.2658487955729167, 3.11328125, 3.4339192708333335, 3.1910807291666665]
Epoch: 7, loss: 10.5339, lr: 0.00000955
epoch 8: 100%|██████████| 12/12 [00:30<00:00,  2.54s/it, cur_loss=10.6]
train acc=0.21941489361702127, [l1_loss, ce_loss] => [0.5291951497395834, 0.2685139973958333, 3.083984375, 3.4171549479166665, 3.1642252604166665]
Epoch: 8, loss: 10.4635, lr: 0.00000245
epoch 9: 100%|██████████| 12/12 [00:32<00:00,  2.71s/it, cur_loss=10.1]
train acc=0.21941489361702127, [l1_loss, ce_loss] => [0.5298258463541666, 0.2684529622395833, 3.0660807291666665, 3.40771484375, 3.14794921875]
Epoch: 9, loss: 10.4206, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 19/19 [00:21<00:00,  1.13s/it]
Test F1-macro:  0.0769227503433297
#######################################

Iteration:  4

#######################################
Training non-few shot model...
Train dataset size:  74
Test dataset size:  19
Training complete!

Test F1-macro:  0.8350376530379114
##########################################
2025-06-09 16:15:41 Getting cached textual weights W ...
2025-06-09 16:15:41 Loading texture features from ./__few_shot_cache__\chinese_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  12
Test dataset size:  19
epoch 0: 100%|██████████| 12/12 [00:23<00:00,  2.00s/it, cur_loss=13.1]
train acc=0.023936170212765957, [l1_loss, ce_loss] => [10.75146484375, 0.34307861328125, 4.1689453125, 3.8777669270833335, 3.904296875]
Epoch: 0, loss: 23.0443, lr: 0.00009755
epoch 1: 100%|██████████| 12/12 [00:24<00:00,  2.01s/it, cur_loss=11.9]
train acc=0.06914893617021277, [l1_loss, ce_loss] => [1.0233561197916667, 0.2750651041666667, 3.7137044270833335, 3.7296549479166665, 3.6565755208333335]
Epoch: 1, loss: 12.3991, lr: 0.00009045
epoch 2: 100%|██████████| 12/12 [00:23<00:00,  1.98s/it, cur_loss=11.2]
train acc=0.10505319148936171, [l1_loss, ce_loss] => [0.6638590494791666, 0.2669677734375, 3.4464518229166665, 3.6336263020833335, 3.49267578125]
Epoch: 2, loss: 11.5039, lr: 0.00007939
epoch 3: 100%|██████████| 12/12 [00:23<00:00,  1.99s/it, cur_loss=11.1]
train acc=0.1356382978723404, [l1_loss, ce_loss] => [0.5620524088541666, 0.2760416666666667, 3.31005859375, 3.54443359375, 3.3681640625]
Epoch: 3, loss: 11.0618, lr: 0.00006545
epoch 4: 100%|██████████| 12/12 [00:23<00:00,  2.00s/it, cur_loss=10.6]
train acc=0.17154255319148937, [l1_loss, ce_loss] => [0.5258992513020834, 0.28497314453125, 3.1710611979166665, 3.4677734375, 3.2470703125]
Epoch: 4, loss: 10.6979, lr: 0.00005000
epoch 5: 100%|██████████| 12/12 [00:23<00:00,  1.99s/it, cur_loss=10.3]
train acc=0.21143617021276595, [l1_loss, ce_loss] => [0.5497639973958334, 0.2920735677083333, 3.0686848958333335, 3.4098307291666665, 3.13232421875]
Epoch: 5, loss: 10.4525, lr: 0.00003455
epoch 6: 100%|██████████| 12/12 [00:23<00:00,  1.99s/it, cur_loss=10.4]
train acc=0.22074468085106383, [l1_loss, ce_loss] => [0.5462646484375, 0.2978108723958333, 2.9886067708333335, 3.3675130208333335, 3.0520833333333335]
Epoch: 6, loss: 10.2526, lr: 0.00002061
epoch 7: 100%|██████████| 12/12 [00:23<00:00,  1.99s/it, cur_loss=10.1]
train acc=0.22074468085106383, [l1_loss, ce_loss] => [0.5581868489583334, 0.3039347330729167, 2.9117838541666665, 3.3235677083333335, 2.9715169270833335]
Epoch: 7, loss: 10.0684, lr: 0.00000955
epoch 8: 100%|██████████| 12/12 [00:23<00:00,  1.99s/it, cur_loss=10.2]
train acc=0.24202127659574468, [l1_loss, ce_loss] => [0.5672200520833334, 0.30670166015625, 2.8821614583333335, 3.3118489583333335, 2.94384765625]
Epoch: 8, loss: 10.0104, lr: 0.00000245
epoch 9: 100%|██████████| 12/12 [00:23<00:00,  2.00s/it, cur_loss=10.1]
train acc=0.25132978723404253, [l1_loss, ce_loss] => [0.5649007161458334, 0.3075154622395833, 2.8701171875, 3.3092447916666665, 2.93408203125]
Epoch: 9, loss: 9.9857, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 19/19 [00:12<00:00,  1.55it/s]
Test F1-macro:  0.11777572093278696
#######################################
Using the latest cached version of the dataset since bazyl/GTSRB couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at dataset\HuggingFace\german_dataset\bazyl___gtsrb\default\0.0.0\a8093a9c7757b59d64702f892002542e8f3a1fb0 (last modified on Mon Jun  9 03:58:08 2025).
Processing the Hugging Face dataset: german_dataset
Processing images: 100%|██████████| 51839/51839 [00:00<00:00, 1255796.03it/s]
Number of filtered labels:  43
Number of removed labels:  0
Number of samples in the dataset:  51839

Iteration:  0

#######################################
Training non-few shot model...
Train dataset size:  648
Test dataset size:  162
Training complete!

Test F1-macro:  0.9425367853075011
##########################################
2025-06-09 16:21:20 Getting cached textual weights W ...

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  162
epoch 0: 100%|██████████| 11/11 [00:24<00:00,  2.23s/it, cur_loss=14.3]
train acc=0.02180232558139535, [l1_loss, ce_loss] => [11.208806818181818, 0.26121937144886365, 4.069957386363637, 3.8169389204545454, 3.856356534090909]
Epoch: 0, loss: 23.2124, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it, cur_loss=12.2]
train acc=0.06831395348837209, [l1_loss, ce_loss] => [1.1039595170454546, 0.19797585227272727, 3.754616477272727, 3.7407670454545454, 3.692294034090909]
Epoch: 1, loss: 12.4901, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:21<00:00,  2.00s/it, cur_loss=11.5]
train acc=0.07267441860465117, [l1_loss, ce_loss] => [0.5033513849431818, 0.1747159090909091, 3.606711647727273, 3.7009943181818183, 3.625]
Epoch: 2, loss: 11.6108, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it, cur_loss=11.4]
train acc=0.08139534883720931, [l1_loss, ce_loss] => [0.37733043323863635, 0.14750532670454544, 3.5720880681818183, 3.6640625, 3.592862215909091]
Epoch: 3, loss: 11.3537, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:23<00:00,  2.12s/it, cur_loss=11.1]
train acc=0.1002906976744186, [l1_loss, ce_loss] => [0.33647017045454547, 0.14817116477272727, 3.528231534090909, 3.6443536931818183, 3.5601917613636362]
Epoch: 4, loss: 11.2188, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:21<00:00,  1.95s/it, cur_loss=11]  
train acc=0.09156976744186046, [l1_loss, ce_loss] => [0.33556019176136365, 0.15782581676136365, 3.492897727272727, 3.614169034090909, 3.520241477272727]
Epoch: 5, loss: 11.1207, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:21<00:00,  1.99s/it, cur_loss=10.9]
train acc=0.12354651162790697, [l1_loss, ce_loss] => [0.3317649147727273, 0.15929066051136365, 3.4605823863636362, 3.596946022727273, 3.490944602272727]
Epoch: 6, loss: 11.0391, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:21<00:00,  1.97s/it, cur_loss=10.8]
train acc=0.11482558139534883, [l1_loss, ce_loss] => [0.32490678267045453, 0.15288751775568182, 3.430575284090909, 3.586825284090909, 3.4630681818181817]
Epoch: 7, loss: 10.9574, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:22<00:00,  2.02s/it, cur_loss=10.8]
train acc=0.11918604651162791, [l1_loss, ce_loss] => [0.31327681107954547, 0.15399724786931818, 3.41796875, 3.5841619318181817, 3.4568536931818183]
Epoch: 8, loss: 10.9268, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:23<00:00,  2.13s/it, cur_loss=10.8]
train acc=0.12063953488372094, [l1_loss, ce_loss] => [0.31261097301136365, 0.1549072265625, 3.415127840909091, 3.579012784090909, 3.4509943181818183]
Epoch: 9, loss: 10.9134, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 162/162 [01:28<00:00,  1.83it/s]
Test F1-macro:  0.02226774181086571
#######################################

Iteration:  1

#######################################
Training non-few shot model...
Train dataset size:  648
Test dataset size:  162
Training complete!

Test F1-macro:  0.9443845814490822
##########################################
2025-06-09 16:28:02 Getting cached textual weights W ...
2025-06-09 16:28:02 Loading texture features from ./__few_shot_cache__\german_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  162
epoch 0: 100%|██████████| 11/11 [00:26<00:00,  2.45s/it, cur_loss=13]  
train acc=0.027616279069767442, [l1_loss, ce_loss] => [10.629216974431818, 0.3281028053977273, 3.9786931818181817, 3.826171875, 3.8258167613636362]
Epoch: 0, loss: 22.5916, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:27<00:00,  2.46s/it, cur_loss=12.2]
train acc=0.04941860465116279, [l1_loss, ce_loss] => [0.8155406605113636, 0.21839488636363635, 3.7544389204545454, 3.7281605113636362, 3.705788352272727]
Epoch: 1, loss: 12.2230, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:27<00:00,  2.47s/it, cur_loss=11.5]
train acc=0.05813953488372093, [l1_loss, ce_loss] => [0.43867631392045453, 0.17377263849431818, 3.6605113636363638, 3.6832386363636362, 3.6528764204545454]
Epoch: 2, loss: 11.6072, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:27<00:00,  2.47s/it, cur_loss=11.4]
train acc=0.07267441860465117, [l1_loss, ce_loss] => [0.272216796875, 0.14731667258522727, 3.629616477272727, 3.6802201704545454, 3.641512784090909]
Epoch: 3, loss: 11.3693, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:27<00:00,  2.47s/it, cur_loss=11.2]
train acc=0.08575581395348837, [l1_loss, ce_loss] => [0.24648215553977273, 0.13832231001420456, 3.6099076704545454, 3.661399147727273, 3.6196732954545454]
Epoch: 4, loss: 11.2763, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:27<00:00,  2.47s/it, cur_loss=11.2]
train acc=0.09447674418604651, [l1_loss, ce_loss] => [0.24114435369318182, 0.12500554865056818, 3.5765269886363638, 3.656960227272727, 3.598366477272727]
Epoch: 5, loss: 11.1974, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:27<00:00,  2.47s/it, cur_loss=11.5]
train acc=0.09011627906976744, [l1_loss, ce_loss] => [0.24156605113636365, 0.12841242009943182, 3.5523792613636362, 3.6548295454545454, 3.584694602272727]
Epoch: 6, loss: 11.1619, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:27<00:00,  2.47s/it, cur_loss=11.4]
train acc=0.10901162790697674, [l1_loss, ce_loss] => [0.23881392045454544, 0.12336314808238637, 3.5257457386363638, 3.6390269886363638, 3.5571732954545454]
Epoch: 7, loss: 11.0845, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:27<00:00,  2.47s/it, cur_loss=11]  
train acc=0.09738372093023256, [l1_loss, ce_loss] => [0.23262162642045456, 0.12855668501420456, 3.5150923295454546, 3.636008522727273, 3.548117897727273]
Epoch: 8, loss: 11.0597, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:27<00:00,  2.47s/it, cur_loss=11] 
train acc=0.11337209302325581, [l1_loss, ce_loss] => [0.23384232954545456, 0.1290560635653409, 3.4998224431818183, 3.627840909090909, 3.5330255681818183]
Epoch: 9, loss: 11.0227, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 162/162 [02:15<00:00,  1.19it/s]
Test F1-macro:  0.02321962391589948
#######################################

Iteration:  2

#######################################
Training non-few shot model...
Train dataset size:  648
Test dataset size:  162
Training complete!

Test F1-macro:  0.9434487806966683
##########################################
2025-06-09 16:36:18 Getting cached textual weights W ...
2025-06-09 16:36:18 Loading texture features from ./__few_shot_cache__\german_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  162
epoch 0: 100%|██████████| 11/11 [00:26<00:00,  2.43s/it, cur_loss=14.6]
train acc=0.0188953488372093, [l1_loss, ce_loss] => [11.471413352272727, 0.29521040482954547, 4.1452414772727275, 3.8162286931818183, 3.891690340909091]
Epoch: 0, loss: 23.6158, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it, cur_loss=13.3]
train acc=0.03343023255813953, [l1_loss, ce_loss] => [1.9465553977272727, 0.21233575994318182, 3.803444602272727, 3.7347301136363638, 3.723899147727273]
Epoch: 1, loss: 13.4205, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:26<00:00,  2.45s/it, cur_loss=12.1]
train acc=0.06686046511627906, [l1_loss, ce_loss] => [1.0678488991477273, 0.18134099786931818, 3.647372159090909, 3.694069602272727, 3.6468394886363638]
Epoch: 2, loss: 12.2365, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it, cur_loss=11.5]
train acc=0.07267441860465117, [l1_loss, ce_loss] => [0.5346013849431818, 0.16664817116477273, 3.5864701704545454, 3.658913352272727, 3.6051136363636362]
Epoch: 3, loss: 11.5511, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it, cur_loss=11.3]
train acc=0.08430232558139535, [l1_loss, ce_loss] => [0.3545143821022727, 0.1597567471590909, 3.539950284090909, 3.6273082386363638, 3.5649857954545454]
Epoch: 4, loss: 11.2464, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it, cur_loss=11.1]
train acc=0.09447674418604651, [l1_loss, ce_loss] => [0.28846324573863635, 0.15788130326704544, 3.5094105113636362, 3.600497159090909, 3.5294744318181817]
Epoch: 5, loss: 11.0866, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it, cur_loss=10.9]
train acc=0.09302325581395349, [l1_loss, ce_loss] => [0.28955078125, 0.15969016335227273, 3.4769176136363638, 3.5740411931818183, 3.495383522727273]
Epoch: 6, loss: 10.9943, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:26<00:00,  2.43s/it, cur_loss=11.1]
train acc=0.10755813953488372, [l1_loss, ce_loss] => [0.281494140625, 0.1634188565340909, 3.4625355113636362, 3.561434659090909, 3.4802911931818183]
Epoch: 7, loss: 10.9489, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it, cur_loss=11.2]
train acc=0.11627906976744186, [l1_loss, ce_loss] => [0.2908602627840909, 0.1656827059659091, 3.446555397727273, 3.5571732954545454, 3.4671519886363638]
Epoch: 8, loss: 10.9283, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:26<00:00,  2.44s/it, cur_loss=10.9]
train acc=0.10465116279069768, [l1_loss, ce_loss] => [0.2822043678977273, 0.16640403053977273, 3.4469105113636362, 3.5545099431818183, 3.465553977272727]
Epoch: 9, loss: 10.9169, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 162/162 [01:29<00:00,  1.82it/s]
Test F1-macro:  0.02509649269255973
#######################################

Iteration:  3

#######################################
Training non-few shot model...
Train dataset size:  648
Test dataset size:  162
Training complete!

Test F1-macro:  0.9482184530995976
##########################################
2025-06-09 16:43:43 Getting cached textual weights W ...
2025-06-09 16:43:43 Loading texture features from ./__few_shot_cache__\german_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  162
epoch 0: 100%|██████████| 11/11 [00:24<00:00,  2.23s/it, cur_loss=15]  
train acc=0.023255813953488372, [l1_loss, ce_loss] => [11.961581143465908, 0.28157182173295453, 3.909090909090909, 3.819247159090909, 3.8160511363636362]
Epoch: 0, loss: 23.7876, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:23<00:00,  2.16s/it, cur_loss=11.9]
train acc=0.055232558139534885, [l1_loss, ce_loss] => [0.9318403764204546, 0.18894264914772727, 3.6704545454545454, 3.736328125, 3.653586647727273]
Epoch: 1, loss: 12.1811, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it, cur_loss=11]  
train acc=0.08139534883720931, [l1_loss, ce_loss] => [0.5216175426136364, 0.1632412997159091, 3.4710582386363638, 3.6505681818181817, 3.5079900568181817]
Epoch: 2, loss: 11.3139, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it, cur_loss=11.2]
train acc=0.13372093023255813, [l1_loss, ce_loss] => [0.479736328125, 0.170654296875, 3.3160511363636362, 3.585049715909091, 3.391335227272727]
Epoch: 3, loss: 10.9425, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:22<00:00,  2.07s/it, cur_loss=11.1]
train acc=0.1511627906976744, [l1_loss, ce_loss] => [0.4694158380681818, 0.18556906960227273, 3.192116477272727, 3.5198863636363638, 3.2697088068181817]
Epoch: 4, loss: 10.6371, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:22<00:00,  2.08s/it, cur_loss=10.5]
train acc=0.17877906976744187, [l1_loss, ce_loss] => [0.4840420809659091, 0.20424582741477273, 3.082741477272727, 3.456321022727273, 3.1598011363636362]
Epoch: 5, loss: 10.3871, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:22<00:00,  2.08s/it, cur_loss=10.4]
train acc=0.2136627906976744, [l1_loss, ce_loss] => [0.5272105823863636, 0.2162198153409091, 2.9454900568181817, 3.4080255681818183, 3.026633522727273]
Epoch: 6, loss: 10.1229, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:22<00:00,  2.08s/it, cur_loss=9.84]
train acc=0.2441860465116279, [l1_loss, ce_loss] => [0.5393732244318182, 0.22337757457386365, 2.850852272727273, 3.376242897727273, 2.9399857954545454]
Epoch: 7, loss: 9.9304, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:22<00:00,  2.08s/it, cur_loss=10.1]
train acc=0.2703488372093023, [l1_loss, ce_loss] => [0.5486949573863636, 0.2283602627840909, 2.8091264204545454, 3.3618607954545454, 2.895241477272727]
Epoch: 8, loss: 9.8430, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:22<00:00,  2.08s/it, cur_loss=9.79]
train acc=0.2805232558139535, [l1_loss, ce_loss] => [0.5462979403409091, 0.2303133877840909, 2.778231534090909, 3.354403409090909, 2.8671875]
Epoch: 9, loss: 9.7763, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 162/162 [01:27<00:00,  1.85it/s]
Test F1-macro:  0.07703751042458672
#######################################

Iteration:  4

#######################################
Training non-few shot model...
Train dataset size:  648
Test dataset size:  162
Training complete!

Test F1-macro:  0.9463956004208047
##########################################
2025-06-09 16:50:28 Getting cached textual weights W ...
2025-06-09 16:50:28 Loading texture features from ./__few_shot_cache__\german_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  11
Test dataset size:  162
epoch 0: 100%|██████████| 11/11 [00:23<00:00,  2.13s/it, cur_loss=15.1]
train acc=0.0436046511627907, [l1_loss, ce_loss] => [12.405362215909092, 0.30668501420454547, 3.907492897727273, 3.8149857954545454, 3.7828480113636362]
Epoch: 0, loss: 24.2173, lr: 0.00009755
epoch 1: 100%|██████████| 11/11 [00:22<00:00,  2.09s/it, cur_loss=12]  
train acc=0.06540697674418605, [l1_loss, ce_loss] => [1.7385475852272727, 0.23664994673295456, 3.5806107954545454, 3.6871448863636362, 3.575284090909091]
Epoch: 1, loss: 12.8175, lr: 0.00009045
epoch 2: 100%|██████████| 11/11 [00:23<00:00,  2.16s/it, cur_loss=11.2]
train acc=0.11337209302325581, [l1_loss, ce_loss] => [0.7981622869318182, 0.21602006392045456, 3.3394886363636362, 3.559481534090909, 3.356178977272727]
Epoch: 2, loss: 11.2685, lr: 0.00007939
epoch 3: 100%|██████████| 11/11 [00:24<00:00,  2.19s/it, cur_loss=10.5]
train acc=0.15261627906976744, [l1_loss, ce_loss] => [0.6169211647727273, 0.22466486150568182, 3.1578480113636362, 3.4691051136363638, 3.2123579545454546]
Epoch: 3, loss: 10.6832, lr: 0.00006545
epoch 4: 100%|██████████| 11/11 [00:24<00:00,  2.23s/it, cur_loss=10.9]
train acc=0.17296511627906977, [l1_loss, ce_loss] => [0.5897549715909091, 0.25269664417613635, 3.022549715909091, 3.3872514204545454, 3.082919034090909]
Epoch: 4, loss: 10.3359, lr: 0.00005000
epoch 5: 100%|██████████| 11/11 [00:24<00:00,  2.24s/it, cur_loss=9.77]
train acc=0.251453488372093, [l1_loss, ce_loss] => [0.5723544034090909, 0.2648259943181818, 2.8394886363636362, 3.329367897727273, 2.9280894886363638]
Epoch: 5, loss: 9.9361, lr: 0.00003455
epoch 6: 100%|██████████| 11/11 [00:24<00:00,  2.23s/it, cur_loss=9.66]
train acc=0.27906976744186046, [l1_loss, ce_loss] => [0.6171875, 0.275390625, 2.686612215909091, 3.2737926136363638, 2.778409090909091]
Epoch: 6, loss: 9.6314, lr: 0.00002061
epoch 7: 100%|██████████| 11/11 [00:24<00:00,  2.24s/it, cur_loss=9.37]
train acc=0.30959302325581395, [l1_loss, ce_loss] => [0.6393377130681818, 0.28284801136363635, 2.544211647727273, 3.224609375, 2.6480823863636362]
Epoch: 7, loss: 9.3388, lr: 0.00000955
epoch 8: 100%|██████████| 11/11 [00:24<00:00,  2.24s/it, cur_loss=8.73]
train acc=0.34738372093023256, [l1_loss, ce_loss] => [0.6512784090909091, 0.2851784446022727, 2.4431818181818183, 3.2095170454545454, 2.5530894886363638]
Epoch: 8, loss: 9.1420, lr: 0.00000245
epoch 9: 100%|██████████| 11/11 [00:24<00:00,  2.24s/it, cur_loss=8.82]
train acc=0.3648255813953488, [l1_loss, ce_loss] => [0.6553178267045454, 0.288330078125, 2.4142400568181817, 3.1977982954545454, 2.524502840909091]
Epoch: 9, loss: 9.0788, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 162/162 [01:28<00:00,  1.82it/s]
Test F1-macro:  0.11237103659963853
#######################################
Using the latest cached version of the dataset since eleldar/rtsd_cleaned couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'default' at dataset\HuggingFace\russian_dataset\eleldar___rtsd_cleaned\default\0.0.0\2a397393d74975c43e0b64ff466fa839d1347eb8 (last modified on Mon Jun  9 10:25:40 2025).
Processing the Hugging Face dataset: russian_dataset
Processing images: 100%|██████████| 103841/103841 [00:00<00:00, 1290292.23it/s]
Number of filtered labels:  139
Number of removed labels:  59
Number of samples in the dataset:  103841

Iteration:  0

#######################################
Training non-few shot model...
Train dataset size:  1298
Test dataset size:  325
Training complete!

Test F1-macro:  0.8470583980885426
##########################################
2025-06-09 16:59:25 Getting cached textual weights W ...

#######################################
Training few-shot model...
Train dataset size:  35
Test dataset size:  325
epoch 0: 100%|██████████| 35/35 [01:16<00:00,  2.20s/it, cur_loss=15.2]
train acc=0.0170863309352518, [l1_loss, ce_loss] => [3.5875558035714286, 0.43131626674107143, 4.99765625, 4.985044642857143, 4.941741071428571]
Epoch: 0, loss: 18.9429, lr: 0.00009755
epoch 1: 100%|██████████| 35/35 [01:13<00:00,  2.09s/it, cur_loss=14.4]
train acc=0.045413669064748204, [l1_loss, ce_loss] => [0.5330147879464285, 0.26113630022321427, 4.472879464285715, 4.784598214285714, 4.557477678571429]
Epoch: 1, loss: 14.6096, lr: 0.00009045
epoch 2: 100%|██████████| 35/35 [01:10<00:00,  2.01s/it, cur_loss=13.4]
train acc=0.08588129496402877, [l1_loss, ce_loss] => [0.6805036272321429, 0.25733816964285716, 4.149888392857143, 4.662053571428571, 4.2352678571428575]
Epoch: 2, loss: 13.9848, lr: 0.00007939
epoch 3: 100%|██████████| 35/35 [01:20<00:00,  2.29s/it, cur_loss=12.9]
train acc=0.12320143884892086, [l1_loss, ce_loss] => [0.7659737723214286, 0.28365304129464286, 3.8353794642857144, 4.524553571428571, 3.9122767857142855]
Epoch: 3, loss: 13.3221, lr: 0.00006545
epoch 4: 100%|██████████| 35/35 [01:15<00:00,  2.16s/it, cur_loss=12.8]
train acc=0.16591726618705036, [l1_loss, ce_loss] => [0.7715680803571429, 0.3026157924107143, 3.6043526785714284, 4.3801339285714285, 3.667578125]
Epoch: 4, loss: 12.7263, lr: 0.00005000
epoch 5: 100%|██████████| 35/35 [01:13<00:00,  2.10s/it, cur_loss=11.8]
train acc=0.23471223021582735, [l1_loss, ce_loss] => [0.7815290178571429, 0.3231654575892857, 3.3623325892857143, 4.2352678571428575, 3.4256696428571427]
Epoch: 5, loss: 12.1281, lr: 0.00003455
epoch 6: 100%|██████████| 35/35 [01:12<00:00,  2.08s/it, cur_loss=11.7]
train acc=0.27473021582733814, [l1_loss, ce_loss] => [0.7973353794642857, 0.336083984375, 3.1472098214285715, 4.1276785714285715, 3.210044642857143]
Epoch: 6, loss: 11.6176, lr: 0.00002061
epoch 7: 100%|██████████| 35/35 [01:11<00:00,  2.05s/it, cur_loss=11.5]
train acc=0.3120503597122302, [l1_loss, ce_loss] => [0.7960379464285714, 0.34388253348214287, 2.96875, 4.02421875, 3.029073660714286]
Epoch: 7, loss: 11.1618, lr: 0.00000955
epoch 8: 100%|██████████| 35/35 [01:20<00:00,  2.29s/it, cur_loss=10.8]
train acc=0.3552158273381295, [l1_loss, ce_loss] => [0.7906668526785714, 0.347705078125, 2.8445870535714284, 3.9675223214285715, 2.9088169642857142]
Epoch: 8, loss: 10.8583, lr: 0.00000245
epoch 9: 100%|██████████| 35/35 [01:15<00:00,  2.16s/it, cur_loss=11]  
train acc=0.3669064748201439, [l1_loss, ce_loss] => [0.7880022321428571, 0.3474888392857143, 2.8043526785714286, 3.9449776785714286, 2.869810267857143]
Epoch: 9, loss: 10.7549, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 325/325 [02:53<00:00,  1.87it/s]
Test F1-macro:  0.08519306943959307
#######################################

Iteration:  1

#######################################
Training non-few shot model...
Train dataset size:  1299
Test dataset size:  325
Training complete!

Test F1-macro:  0.8371878866230399
##########################################
2025-06-09 17:18:15 Getting cached textual weights W ...
2025-06-09 17:18:15 Loading texture features from ./__few_shot_cache__\russian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  35
Test dataset size:  325
epoch 0: 100%|██████████| 35/35 [02:09<00:00,  3.69s/it, cur_loss=15.4]
train acc=0.022931654676258992, [l1_loss, ce_loss] => [4.5349190848214285, 0.5413434709821429, 5.000558035714286, 5.021316964285714, 4.927790178571429]
Epoch: 0, loss: 20.0270, lr: 0.00009755
epoch 1: 100%|██████████| 35/35 [02:06<00:00,  3.61s/it, cur_loss=14.1]
train acc=0.07508992805755396, [l1_loss, ce_loss] => [0.5658830915178571, 0.31968470982142855, 4.335379464285714, 4.782254464285714, 4.4209821428571425]
Epoch: 1, loss: 14.4266, lr: 0.00009045
epoch 2: 100%|██████████| 35/35 [02:07<00:00,  3.64s/it, cur_loss=13.1]
train acc=0.14253597122302158, [l1_loss, ce_loss] => [0.7756975446428571, 0.3258510044642857, 3.770424107142857, 4.6081473214285715, 3.853125]
Epoch: 2, loss: 13.3337, lr: 0.00007939
epoch 3: 100%|██████████| 35/35 [02:06<00:00,  3.61s/it, cur_loss=11.3]
train acc=0.2239208633093525, [l1_loss, ce_loss] => [0.8348493303571428, 0.33486328125, 3.279966517857143, 4.3975446428571425, 3.3592633928571427]
Epoch: 3, loss: 12.2065, lr: 0.00006545
epoch 4: 100%|██████████| 35/35 [02:06<00:00,  3.61s/it, cur_loss=10.8]
train acc=0.31789568345323743, [l1_loss, ce_loss] => [0.8665178571428571, 0.3678989955357143, 2.862220982142857, 4.134430803571429, 2.9320870535714287]
Epoch: 4, loss: 11.1627, lr: 0.00005000
epoch 5: 100%|██████████| 35/35 [02:06<00:00,  3.61s/it, cur_loss=9.3] 
train acc=0.4114208633093525, [l1_loss, ce_loss] => [0.8763671875, 0.3965053013392857, 2.5132254464285713, 3.847935267857143, 2.573716517857143]
Epoch: 5, loss: 10.2080, lr: 0.00003455
epoch 6: 100%|██████████| 35/35 [02:06<00:00,  3.62s/it, cur_loss=9.08]
train acc=0.5058453237410072, [l1_loss, ce_loss] => [0.8805524553571429, 0.4128487723214286, 2.2349609375, 3.609151785714286, 2.2896205357142856]
Epoch: 6, loss: 9.4272, lr: 0.00002061
epoch 7: 100%|██████████| 35/35 [02:06<00:00,  3.61s/it, cur_loss=8.95]
train acc=0.5759892086330936, [l1_loss, ce_loss] => [0.8734514508928571, 0.41639229910714287, 2.0157924107142855, 3.4427455357142858, 2.067661830357143]
Epoch: 7, loss: 8.8162, lr: 0.00000955
epoch 8: 100%|██████████| 35/35 [02:06<00:00,  3.61s/it, cur_loss=7.97]
train acc=0.6371402877697842, [l1_loss, ce_loss] => [0.8702706473214286, 0.4181919642857143, 1.8724330357142858, 3.3234933035714285, 1.923046875]
Epoch: 8, loss: 8.4071, lr: 0.00000245
epoch 9: 100%|██████████| 35/35 [02:06<00:00,  3.61s/it, cur_loss=8.88]
train acc=0.6515287769784173, [l1_loss, ce_loss] => [0.8696986607142857, 0.41759207589285713, 1.8322823660714285, 3.29765625, 1.8849609375]
Epoch: 9, loss: 8.3028, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 325/325 [07:37<00:00,  1.41s/it]
Test F1-macro:  0.22256582665629496
#######################################

Iteration:  2

#######################################
Training non-few shot model...
Train dataset size:  1299
Test dataset size:  325
Training complete!

Test F1-macro:  0.8328992409622592
##########################################
2025-06-09 17:50:17 Getting cached textual weights W ...
2025-06-09 17:50:17 Loading texture features from ./__few_shot_cache__\russian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  35
Test dataset size:  325
epoch 0: 100%|██████████| 35/35 [01:18<00:00,  2.24s/it, cur_loss=15.3]
train acc=0.017985611510791366, [l1_loss, ce_loss] => [4.081201171875, 0.4730678013392857, 5.228125, 4.974441964285714, 4.989397321428571]
Epoch: 0, loss: 19.7455, lr: 0.00009755
epoch 1: 100%|██████████| 35/35 [01:21<00:00,  2.33s/it, cur_loss=14.5]
train acc=0.053057553956834536, [l1_loss, ce_loss] => [0.4031319754464286, 0.2874302455357143, 4.547321428571428, 4.769642857142857, 4.6084821428571425]
Epoch: 1, loss: 14.6156, lr: 0.00009045
epoch 2: 100%|██████████| 35/35 [01:21<00:00,  2.33s/it, cur_loss=13.5]
train acc=0.09982014388489209, [l1_loss, ce_loss] => [0.6141880580357143, 0.3134068080357143, 4.097098214285714, 4.591964285714286, 4.169084821428571]
Epoch: 2, loss: 13.7862, lr: 0.00007939
epoch 3: 100%|██████████| 35/35 [01:21<00:00,  2.33s/it, cur_loss=12.4]
train acc=0.16636690647482014, [l1_loss, ce_loss] => [0.7513811383928571, 0.32272600446428573, 3.6747767857142857, 4.430245535714286, 3.742857142857143]
Epoch: 3, loss: 12.9212, lr: 0.00006545
epoch 4: 100%|██████████| 35/35 [01:21<00:00,  2.32s/it, cur_loss=11.9]
train acc=0.21133093525179855, [l1_loss, ce_loss] => [0.8114536830357143, 0.3390625, 3.3773995535714287, 4.281808035714286, 3.4392857142857145]
Epoch: 4, loss: 12.2484, lr: 0.00005000
epoch 5: 100%|██████████| 35/35 [01:21<00:00,  2.33s/it, cur_loss=11.4]
train acc=0.2783273381294964, [l1_loss, ce_loss] => [0.8286969866071429, 0.3469168526785714, 3.0765625, 4.104631696428571, 3.136495535714286]
Epoch: 5, loss: 11.4938, lr: 0.00003455
epoch 6: 100%|██████████| 35/35 [01:21<00:00,  2.32s/it, cur_loss=11]  
train acc=0.3376798561151079, [l1_loss, ce_loss] => [0.8393136160714286, 0.35745675223214285, 2.8439174107142855, 3.94375, 2.899330357142857]
Epoch: 6, loss: 10.8844, lr: 0.00002061
epoch 7: 100%|██████████| 35/35 [01:21<00:00,  2.33s/it, cur_loss=11]  
train acc=0.38264388489208634, [l1_loss, ce_loss] => [0.8365931919642857, 0.36434151785714286, 2.685044642857143, 3.823158482142857, 2.7375]
Epoch: 7, loss: 10.4471, lr: 0.00000955
epoch 8: 100%|██████████| 35/35 [01:21<00:00,  2.33s/it, cur_loss=9.75]
train acc=0.4294064748201439, [l1_loss, ce_loss] => [0.8330217633928572, 0.36880580357142856, 2.574441964285714, 3.7439732142857145, 2.627455357142857]
Epoch: 8, loss: 10.1482, lr: 0.00000245
epoch 9: 100%|██████████| 35/35 [01:21<00:00,  2.32s/it, cur_loss=9.98]
train acc=0.4401978417266187, [l1_loss, ce_loss] => [0.8341517857142857, 0.36915457589285716, 2.552064732142857, 3.7236607142857143, 2.605245535714286]
Epoch: 9, loss: 10.0837, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 325/325 [02:55<00:00,  1.86it/s]
Test F1-macro:  0.10704545975126835
#######################################

Iteration:  3

#######################################
Training non-few shot model...
Train dataset size:  1299
Test dataset size:  325
Training complete!

Test F1-macro:  0.8387169484620429
##########################################
2025-06-09 18:09:59 Getting cached textual weights W ...
2025-06-09 18:09:59 Loading texture features from ./__few_shot_cache__\russian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  35
Test dataset size:  325
epoch 0: 100%|██████████| 35/35 [01:28<00:00,  2.53s/it, cur_loss=15.2]
train acc=0.01753597122302158, [l1_loss, ce_loss] => [3.909444754464286, 0.5020856584821428, 5.062053571428572, 4.993973214285714, 4.9582589285714285]
Epoch: 0, loss: 19.4252, lr: 0.00009755
epoch 1: 100%|██████████| 35/35 [01:39<00:00,  2.86s/it, cur_loss=14.1]
train acc=0.05170863309352518, [l1_loss, ce_loss] => [0.5131068638392857, 0.3608956473214286, 4.47109375, 4.770089285714286, 4.532589285714286]
Epoch: 1, loss: 14.6484, lr: 0.00009045
epoch 2: 100%|██████████| 35/35 [01:28<00:00,  2.52s/it, cur_loss=13.5]
train acc=0.09577338129496403, [l1_loss, ce_loss] => [0.6203543526785714, 0.30717075892857143, 4.074386160714286, 4.648772321428571, 4.139508928571429]
Epoch: 2, loss: 13.7897, lr: 0.00007939
epoch 3: 100%|██████████| 35/35 [01:29<00:00,  2.56s/it, cur_loss=12.7]
train acc=0.14613309352517986, [l1_loss, ce_loss] => [0.7005580357142858, 0.30613839285714284, 3.71953125, 4.5321428571428575, 3.791294642857143]
Epoch: 3, loss: 13.0509, lr: 0.00006545
epoch 4: 100%|██████████| 35/35 [01:25<00:00,  2.43s/it, cur_loss=12.8]
train acc=0.21223021582733814, [l1_loss, ce_loss] => [0.7484095982142858, 0.3259905133928571, 3.3934151785714284, 4.38046875, 3.4574776785714287]
Epoch: 4, loss: 12.3060, lr: 0.00005000
epoch 5: 100%|██████████| 35/35 [01:29<00:00,  2.55s/it, cur_loss=11.9]
train acc=0.27113309352517984, [l1_loss, ce_loss] => [0.7675083705357143, 0.3478306361607143, 3.1232142857142855, 4.202008928571429, 3.178125]
Epoch: 5, loss: 11.6185, lr: 0.00003455
epoch 6: 100%|██████████| 35/35 [01:26<00:00,  2.46s/it, cur_loss=11.2]
train acc=0.35881294964028776, [l1_loss, ce_loss] => [0.7799525669642857, 0.3684151785714286, 2.8624441964285716, 4.013002232142857, 2.9154017857142858]
Epoch: 6, loss: 10.9391, lr: 0.00002061
epoch 7: 100%|██████████| 35/35 [01:30<00:00,  2.59s/it, cur_loss=10.5]
train acc=0.4028776978417266, [l1_loss, ce_loss] => [0.785546875, 0.3827497209821429, 2.6712611607142858, 3.8689732142857145, 2.72265625]
Epoch: 7, loss: 10.4317, lr: 0.00000955
epoch 8: 100%|██████████| 35/35 [01:25<00:00,  2.44s/it, cur_loss=9.62]
train acc=0.4464928057553957, [l1_loss, ce_loss] => [0.7820452008928571, 0.39078543526785714, 2.5411830357142855, 3.777734375, 2.5929129464285716]
Epoch: 8, loss: 10.0850, lr: 0.00000245
epoch 9: 100%|██████████| 35/35 [01:29<00:00,  2.56s/it, cur_loss=9.73]
train acc=0.47257194244604317, [l1_loss, ce_loss] => [0.7806919642857143, 0.3919642857142857, 2.4913504464285716, 3.7400669642857145, 2.54296875]
Epoch: 9, loss: 9.9467, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 325/325 [04:25<00:00,  1.23it/s]
Test F1-macro:  0.10882908772524162
#######################################

Iteration:  4

#######################################
Training non-few shot model...
Train dataset size:  1299
Test dataset size:  325
Training complete!

Test F1-macro:  0.8333719879220214
##########################################
2025-06-09 18:32:28 Getting cached textual weights W ...
2025-06-09 18:32:28 Loading texture features from ./__few_shot_cache__\russian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  35
Test dataset size:  325
epoch 0: 100%|██████████| 35/35 [01:40<00:00,  2.88s/it, cur_loss=15.4]
train acc=0.02158273381294964, [l1_loss, ce_loss] => [3.9569754464285714, 0.37999441964285713, 5.1493303571428575, 4.986383928571429, 4.979464285714286]
Epoch: 0, loss: 19.4536, lr: 0.00009755
epoch 1: 100%|██████████| 35/35 [01:40<00:00,  2.88s/it, cur_loss=14.5]
train acc=0.04316546762589928, [l1_loss, ce_loss] => [0.5325125558035714, 0.2536028180803571, 4.528683035714286, 4.8212053571428575, 4.6024553571428575]
Epoch: 1, loss: 14.7386, lr: 0.00009045
epoch 2: 100%|██████████| 35/35 [01:40<00:00,  2.88s/it, cur_loss=13.3]
train acc=0.10341726618705036, [l1_loss, ce_loss] => [0.6362862723214285, 0.23624093191964285, 4.060491071428571, 4.675446428571429, 4.146595982142857]
Epoch: 2, loss: 13.7547, lr: 0.00007939
epoch 3: 100%|██████████| 35/35 [01:40<00:00,  2.87s/it, cur_loss=12.6]
train acc=0.15467625899280577, [l1_loss, ce_loss] => [0.7373325892857143, 0.25729631696428573, 3.685770089285714, 4.522098214285714, 3.771261160714286]
Epoch: 3, loss: 12.9741, lr: 0.00006545
epoch 4: 100%|██████████| 35/35 [01:40<00:00,  2.88s/it, cur_loss=12.4]
train acc=0.21133093525179855, [l1_loss, ce_loss] => [0.7826032366071428, 0.29545200892857143, 3.3754464285714287, 4.345647321428571, 3.4529575892857145]
Epoch: 4, loss: 12.2520, lr: 0.00005000
epoch 5: 100%|██████████| 35/35 [01:40<00:00,  2.88s/it, cur_loss=12]  
train acc=0.27068345323741005, [l1_loss, ce_loss] => [0.8147739955357143, 0.31881975446428573, 3.0958705357142855, 4.17890625, 3.168861607142857]
Epoch: 5, loss: 11.5772, lr: 0.00003455
epoch 6: 100%|██████████| 35/35 [01:40<00:00,  2.87s/it, cur_loss=11.2]
train acc=0.318794964028777, [l1_loss, ce_loss] => [0.8216796875, 0.33754185267857145, 2.8802455357142858, 4.031752232142857, 2.948549107142857]
Epoch: 6, loss: 11.0190, lr: 0.00002061
epoch 7: 100%|██████████| 35/35 [01:40<00:00,  2.88s/it, cur_loss=10.2]
train acc=0.385341726618705, [l1_loss, ce_loss] => [0.819140625, 0.34651925223214286, 2.6823660714285715, 3.9038504464285713, 2.7484375]
Epoch: 7, loss: 10.5004, lr: 0.00000955
epoch 8: 100%|██████████| 35/35 [01:40<00:00,  2.88s/it, cur_loss=9.84]
train acc=0.4154676258992806, [l1_loss, ce_loss] => [0.81689453125, 0.350732421875, 2.5938616071428573, 3.83515625, 2.658984375]
Epoch: 8, loss: 10.2554, lr: 0.00000245
epoch 9: 100%|██████████| 35/35 [01:40<00:00,  2.88s/it, cur_loss=10.9]
train acc=0.4316546762589928, [l1_loss, ce_loss] => [0.8161969866071429, 0.35098353794642856, 2.558816964285714, 3.8221540178571427, 2.6248325892857145]
Epoch: 9, loss: 10.1732, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 325/325 [04:27<00:00,  1.22it/s]
Test F1-macro:  0.10450778692301822
#######################################
Processing the local dataset: belgian_dataset
Processing images: 100%|██████████| 6970/6970 [02:01<00:00, 57.17it/s]
Number of filtered labels:  52
Number of removed labels:  10
Number of samples in the dataset:  6970

Iteration:  0

#######################################
Training non-few shot model...
Train dataset size:  88
Test dataset size:  22
Training complete!

Test F1-macro:  0.8153152148864417
##########################################
2025-06-09 18:55:58 Getting cached textual weights W ...
2025-06-09 18:55:58 Loading texture features from ./__few_shot_cache__\belgian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  13
Test dataset size:  22
epoch 0: 100%|██████████| 13/13 [00:27<00:00,  2.09s/it, cur_loss=13.4]
train acc=0.051682692307692304, [l1_loss, ce_loss] => [8.307204026442308, 0.3070256159855769, 4.020282451923077, 3.9540264423076925, 3.906550480769231]
Epoch: 0, loss: 20.4928, lr: 0.00009755
epoch 1: 100%|██████████| 13/13 [00:27<00:00,  2.15s/it, cur_loss=11.8]
train acc=0.09014423076923077, [l1_loss, ce_loss] => [1.1180513822115385, 0.24859149639423078, 3.390625, 3.743840144230769, 3.464543269230769]
Epoch: 1, loss: 11.9657, lr: 0.00009045
epoch 2: 100%|██████████| 13/13 [00:29<00:00,  2.28s/it, cur_loss=10.6]
train acc=0.13221153846153846, [l1_loss, ce_loss] => [0.7744516225961539, 0.2866962139423077, 3.1873497596153846, 3.5935997596153846, 3.284405048076923]
Epoch: 2, loss: 11.1256, lr: 0.00007939
epoch 3: 100%|██████████| 13/13 [00:28<00:00,  2.23s/it, cur_loss=10.1]
train acc=0.19471153846153846, [l1_loss, ce_loss] => [0.7062424879807693, 0.3011005108173077, 3.0006009615384617, 3.4809194711538463, 3.103816105769231]
Epoch: 3, loss: 10.5925, lr: 0.00006545
epoch 4: 100%|██████████| 13/13 [00:28<00:00,  2.21s/it, cur_loss=10.1]
train acc=0.25, [l1_loss, ce_loss] => [0.6820913461538461, 0.31727013221153844, 2.8318810096153846, 3.3775540865384617, 2.9396033653846154]
Epoch: 4, loss: 10.1478, lr: 0.00005000
epoch 5: 100%|██████████| 13/13 [00:28<00:00,  2.21s/it, cur_loss=9.69]
train acc=0.28725961538461536, [l1_loss, ce_loss] => [0.693359375, 0.3308293269230769, 2.6630108173076925, 3.2734375, 2.7723858173076925]
Epoch: 5, loss: 9.7344, lr: 0.00003455
epoch 6: 100%|██████████| 13/13 [00:28<00:00,  2.21s/it, cur_loss=8.92]
train acc=0.36177884615384615, [l1_loss, ce_loss] => [0.7210036057692307, 0.3462665264423077, 2.4774639423076925, 3.1693209134615383, 2.5902944711538463]
Epoch: 6, loss: 9.3053, lr: 0.00002061
epoch 7: 100%|██████████| 13/13 [00:28<00:00,  2.21s/it, cur_loss=9.17]
train acc=0.41225961538461536, [l1_loss, ce_loss] => [0.7260366586538461, 0.3529710036057692, 2.341045673076923, 3.1083233173076925, 2.45703125]
Epoch: 7, loss: 8.9844, lr: 0.00000955
epoch 8: 100%|██████████| 13/13 [00:28<00:00,  2.22s/it, cur_loss=8.53]
train acc=0.453125, [l1_loss, ce_loss] => [0.7342623197115384, 0.3604266826923077, 2.2471454326923075, 3.0560396634615383, 2.3602764423076925]
Epoch: 8, loss: 8.7590, lr: 0.00000245
epoch 9: 100%|██████████| 13/13 [00:28<00:00,  2.22s/it, cur_loss=8.53]
train acc=0.4519230769230769, [l1_loss, ce_loss] => [0.7344501201923077, 0.36031400240384615, 2.205378605769231, 3.0372596153846154, 2.3306790865384617]
Epoch: 9, loss: 8.6671, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 22/22 [00:12<00:00,  1.70it/s]
Test F1-macro:  0.20384674654117446
#######################################

Iteration:  1

#######################################
Training non-few shot model...
Train dataset size:  88
Test dataset size:  22
Training complete!

Test F1-macro:  0.8754493328930224
##########################################
2025-06-09 19:01:09 Getting cached textual weights W ...
2025-06-09 19:01:09 Loading texture features from ./__few_shot_cache__\belgian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  13
Test dataset size:  22
epoch 0: 100%|██████████| 13/13 [00:37<00:00,  2.90s/it, cur_loss=12.9]
train acc=0.04807692307692308, [l1_loss, ce_loss] => [7.43603515625, 0.28647085336538464, 4.176382211538462, 3.9501201923076925, 3.943359375]
Epoch: 0, loss: 19.7915, lr: 0.00009755
epoch 1: 100%|██████████| 13/13 [00:39<00:00,  3.03s/it, cur_loss=11.7]
train acc=0.08052884615384616, [l1_loss, ce_loss] => [0.9239032451923077, 0.2747051532451923, 3.5579927884615383, 3.7406850961538463, 3.5405649038461537]
Epoch: 1, loss: 12.0403, lr: 0.00009045
epoch 2: 100%|██████████| 13/13 [00:39<00:00,  3.02s/it, cur_loss=11.1]
train acc=0.10576923076923077, [l1_loss, ce_loss] => [0.7727614182692307, 0.31787109375, 3.3357872596153846, 3.5528846153846154, 3.3470552884615383]
Epoch: 2, loss: 11.3275, lr: 0.00007939
epoch 3: 100%|██████████| 13/13 [00:38<00:00,  2.99s/it, cur_loss=10.6]
train acc=0.15264423076923078, [l1_loss, ce_loss] => [0.7045522836538461, 0.36144080528846156, 3.163311298076923, 3.4067007211538463, 3.1840444711538463]
Epoch: 3, loss: 10.8203, lr: 0.00006545
epoch 4: 100%|██████████| 13/13 [00:39<00:00,  3.04s/it, cur_loss=10.4]
train acc=0.16826923076923078, [l1_loss, ce_loss] => [0.6752554086538461, 0.3869441105769231, 3.0913461538461537, 3.3064903846153846, 3.0904447115384617]
Epoch: 4, loss: 10.5499, lr: 0.00005000
epoch 5: 100%|██████████| 13/13 [00:39<00:00,  3.04s/it, cur_loss=10.3]
train acc=0.19591346153846154, [l1_loss, ce_loss] => [0.6417518028846154, 0.4058368389423077, 3.0076622596153846, 3.229717548076923, 3.0052584134615383]
Epoch: 5, loss: 10.2903, lr: 0.00003455
epoch 6: 100%|██████████| 13/13 [00:39<00:00,  3.02s/it, cur_loss=10.6]
train acc=0.21634615384615385, [l1_loss, ce_loss] => [0.6431039663461539, 0.41201547475961536, 2.9493689903846154, 3.1714242788461537, 2.9390024038461537]
Epoch: 6, loss: 10.1148, lr: 0.00002061
epoch 7: 100%|██████████| 13/13 [00:39<00:00,  3.03s/it, cur_loss=10.1]
train acc=0.23076923076923078, [l1_loss, ce_loss] => [0.6297701322115384, 0.4124286358173077, 2.9119591346153846, 3.1466346153846154, 2.9021935096153846]
Epoch: 7, loss: 10.0030, lr: 0.00000955
epoch 8: 100%|██████████| 13/13 [00:39<00:00,  3.02s/it, cur_loss=10.1]
train acc=0.2439903846153846, [l1_loss, ce_loss] => [0.6376953125, 0.41556490384615385, 2.873798076923077, 3.120793269230769, 2.8598257211538463]
Epoch: 8, loss: 9.9081, lr: 0.00000245
epoch 9: 100%|██████████| 13/13 [00:38<00:00,  2.99s/it, cur_loss=9.78]
train acc=0.23317307692307693, [l1_loss, ce_loss] => [0.6341646634615384, 0.4162785456730769, 2.8740985576923075, 3.114032451923077, 2.8556189903846154]
Epoch: 9, loss: 9.8936, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 22/22 [00:27<00:00,  1.26s/it]
Test F1-macro:  0.10960040109552936
#######################################

Iteration:  2

#######################################
Training non-few shot model...
Train dataset size:  88
Test dataset size:  22
Training complete!

Test F1-macro:  0.8398954397388233
##########################################
2025-06-09 19:08:19 Getting cached textual weights W ...
2025-06-09 19:08:19 Loading texture features from ./__few_shot_cache__\belgian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  13
Test dataset size:  22
epoch 0: 100%|██████████| 13/13 [00:25<00:00,  1.95s/it, cur_loss=13.7]
train acc=0.025240384615384616, [l1_loss, ce_loss] => [8.42705829326923, 0.32132662259615385, 4.138521634615385, 4.018780048076923, 3.9936899038461537]
Epoch: 0, loss: 20.9002, lr: 0.00009755
epoch 1: 100%|██████████| 13/13 [00:26<00:00,  2.03s/it, cur_loss=12.5]
train acc=0.051682692307692304, [l1_loss, ce_loss] => [1.2255108173076923, 0.27869591346153844, 3.587890625, 3.8018329326923075, 3.6424278846153846]
Epoch: 1, loss: 12.5361, lr: 0.00009045
epoch 2: 100%|██████████| 13/13 [00:26<00:00,  2.05s/it, cur_loss=11.4]
train acc=0.09495192307692307, [l1_loss, ce_loss] => [0.8185471754807693, 0.2953913762019231, 3.4053485576923075, 3.6631610576923075, 3.479717548076923]
Epoch: 2, loss: 11.6623, lr: 0.00007939
epoch 3: 100%|██████████| 13/13 [00:26<00:00,  2.04s/it, cur_loss=10.9]
train acc=0.11298076923076923, [l1_loss, ce_loss] => [0.6693960336538461, 0.3151292067307692, 3.3094951923076925, 3.5653545673076925, 3.371844951923077]
Epoch: 3, loss: 11.2308, lr: 0.00006545
epoch 4: 100%|██████████| 13/13 [00:26<00:00,  2.05s/it, cur_loss=10.7]
train acc=0.13822115384615385, [l1_loss, ce_loss] => [0.6257887620192307, 0.33775916466346156, 3.234074519230769, 3.4873798076923075, 3.2853064903846154]
Epoch: 4, loss: 10.9694, lr: 0.00005000
epoch 5: 100%|██████████| 13/13 [00:26<00:00,  2.03s/it, cur_loss=10.6]
train acc=0.16947115384615385, [l1_loss, ce_loss] => [0.6276292067307693, 0.35184420072115385, 3.1410757211538463, 3.4262319711538463, 3.195612980769231]
Epoch: 5, loss: 10.7422, lr: 0.00003455
epoch 6: 100%|██████████| 13/13 [00:26<00:00,  2.05s/it, cur_loss=10.9]
train acc=0.18028846153846154, [l1_loss, ce_loss] => [0.6283052884615384, 0.35875525841346156, 3.082782451923077, 3.3822115384615383, 3.134465144230769]
Epoch: 6, loss: 10.5859, lr: 0.00002061
epoch 7: 100%|██████████| 13/13 [00:26<00:00,  2.03s/it, cur_loss=10.1]
train acc=0.1814903846153846, [l1_loss, ce_loss] => [0.6227463942307693, 0.3618351862980769, 3.026592548076923, 3.3517127403846154, 3.0826322115384617]
Epoch: 7, loss: 10.4441, lr: 0.00000955
epoch 8: 100%|██████████| 13/13 [00:26<00:00,  2.05s/it, cur_loss=10.2]
train acc=0.20192307692307693, [l1_loss, ce_loss] => [0.6226337139423077, 0.36422025240384615, 3.0108173076923075, 3.3360877403846154, 3.061748798076923]
Epoch: 8, loss: 10.3954, lr: 0.00000245
epoch 9: 100%|██████████| 13/13 [00:26<00:00,  2.04s/it, cur_loss=10.2]
train acc=0.19951923076923078, [l1_loss, ce_loss] => [0.6212064302884616, 0.3644268329326923, 3.0006009615384617, 3.3353365384615383, 3.0570913461538463]
Epoch: 9, loss: 10.3786, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 22/22 [00:12<00:00,  1.77it/s]
Test F1-macro:  0.06041356841649495
#######################################

Iteration:  3

#######################################
Training non-few shot model...
Train dataset size:  88
Test dataset size:  22
Training complete!

Test F1-macro:  0.8682301614650788
##########################################
2025-06-09 19:13:08 Getting cached textual weights W ...
2025-06-09 19:13:08 Loading texture features from ./__few_shot_cache__\belgian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  13
Test dataset size:  22
epoch 0: 100%|██████████| 13/13 [00:26<00:00,  2.05s/it, cur_loss=13.2]
train acc=0.051682692307692304, [l1_loss, ce_loss] => [7.782977764423077, 0.3228102463942308, 3.9100060096153846, 3.946965144230769, 3.817157451923077]
Epoch: 0, loss: 19.7806, lr: 0.00009755
epoch 1: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=11.5]
train acc=0.13822115384615385, [l1_loss, ce_loss] => [1.2817758413461537, 0.3026592548076923, 3.2391826923076925, 3.6890024038461537, 3.3140024038461537]
Epoch: 1, loss: 11.8275, lr: 0.00009045
epoch 2: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=10.7]
train acc=0.20192307692307693, [l1_loss, ce_loss] => [0.9806565504807693, 0.3361065204326923, 2.927734375, 3.4932391826923075, 3.0208834134615383]
Epoch: 2, loss: 10.7578, lr: 0.00007939
epoch 3: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=9.73]
train acc=0.27524038461538464, [l1_loss, ce_loss] => [0.83642578125, 0.3614032451923077, 2.6493389423076925, 3.3070913461538463, 2.7540564903846154]
Epoch: 3, loss: 9.9099, lr: 0.00006545
epoch 4: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=8.72]
train acc=0.3485576923076923, [l1_loss, ce_loss] => [0.8091571514423077, 0.3751690204326923, 2.4604867788461537, 3.175480769230769, 2.560246394230769]
Epoch: 4, loss: 9.3804, lr: 0.00005000
epoch 5: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=8.66]
train acc=0.41346153846153844, [l1_loss, ce_loss] => [0.8122370793269231, 0.3906813401442308, 2.2563100961538463, 3.0455228365384617, 2.357722355769231]
Epoch: 5, loss: 8.8636, lr: 0.00003455
epoch 6: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=8.17]
train acc=0.47596153846153844, [l1_loss, ce_loss] => [0.8044996995192307, 0.3972731370192308, 2.048527644230769, 2.9173677884615383, 2.1456580528846154]
Epoch: 6, loss: 8.3149, lr: 0.00002061
epoch 7: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=8.04]
train acc=0.5168269230769231, [l1_loss, ce_loss] => [0.8085186298076923, 0.4049541766826923, 1.8674128605769231, 2.8198617788461537, 1.9625150240384615]
Epoch: 7, loss: 7.8621, lr: 0.00000955
epoch 8: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=7.55]
train acc=0.5817307692307693, [l1_loss, ce_loss] => [0.8025090144230769, 0.404296875, 1.7698317307692308, 2.7630709134615383, 1.8650841346153846]
Epoch: 8, loss: 7.6046, lr: 0.00000245
epoch 9: 100%|██████████| 13/13 [00:28<00:00,  2.17s/it, cur_loss=6.84]
train acc=0.5709134615384616, [l1_loss, ce_loss] => [0.8015324519230769, 0.4059495192307692, 1.7529296875, 2.7451923076923075, 1.8478816105769231]
Epoch: 9, loss: 7.5538, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 22/22 [00:12<00:00,  1.74it/s]
Test F1-macro:  0.29054747016014837
#######################################

Iteration:  4

#######################################
Training non-few shot model...
Train dataset size:  88
Test dataset size:  22
Training complete!

Test F1-macro:  0.8224375188092983
##########################################
2025-06-09 19:18:12 Getting cached textual weights W ...
2025-06-09 19:18:12 Loading texture features from ./__few_shot_cache__\belgian_dataset_ViT-B/16_textfeats.pt

#######################################
Training few-shot model...
Train dataset size:  13
Test dataset size:  22
epoch 0: 100%|██████████| 13/13 [00:24<00:00,  1.87s/it, cur_loss=12.7]
train acc=0.040865384615384616, [l1_loss, ce_loss] => [9.01836688701923, 0.29801119290865385, 4.050480769230769, 3.987980769230769, 3.9400540865384617]
Epoch: 0, loss: 21.2969, lr: 0.00009755
epoch 1: 100%|██████████| 13/13 [00:25<00:00,  1.96s/it, cur_loss=11.7]
train acc=0.08052884615384616, [l1_loss, ce_loss] => [0.8509615384615384, 0.2638972355769231, 3.5244891826923075, 3.7842548076923075, 3.5782752403846154]
Epoch: 1, loss: 12.0000, lr: 0.00009045
epoch 2: 100%|██████████| 13/13 [00:25<00:00,  1.96s/it, cur_loss=11.3]
train acc=0.12139423076923077, [l1_loss, ce_loss] => [0.7341496394230769, 0.28457406850961536, 3.264423076923077, 3.625751201923077, 3.367487980769231]
Epoch: 2, loss: 11.2758, lr: 0.00007939
epoch 3: 100%|██████████| 13/13 [00:25<00:00,  1.97s/it, cur_loss=11]  
train acc=0.13701923076923078, [l1_loss, ce_loss] => [0.6805889423076923, 0.31850961538461536, 3.1514423076923075, 3.510066105769231, 3.250300480769231]
Epoch: 3, loss: 10.9099, lr: 0.00006545
epoch 4: 100%|██████████| 13/13 [00:25<00:00,  1.96s/it, cur_loss=10.5]
train acc=0.15144230769230768, [l1_loss, ce_loss] => [0.6711237980769231, 0.34093299278846156, 3.0662560096153846, 3.435546875, 3.1568509615384617]
Epoch: 4, loss: 10.6713, lr: 0.00005000
epoch 5: 100%|██████████| 13/13 [00:25<00:00,  1.97s/it, cur_loss=10.3]
train acc=0.1971153846153846, [l1_loss, ce_loss] => [0.6627854567307693, 0.3582294170673077, 3.0174278846153846, 3.3706430288461537, 3.1009615384615383]
Epoch: 5, loss: 10.5096, lr: 0.00003455
epoch 6: 100%|██████████| 13/13 [00:25<00:00,  1.97s/it, cur_loss=10]  
train acc=0.21514423076923078, [l1_loss, ce_loss] => [0.6515174278846154, 0.36429537259615385, 2.959284855769231, 3.3246694711538463, 3.0399639423076925]
Epoch: 6, loss: 10.3395, lr: 0.00002061
epoch 7: 100%|██████████| 13/13 [00:25<00:00,  1.96s/it, cur_loss=10.1]
train acc=0.22596153846153846, [l1_loss, ce_loss] => [0.6440805288461539, 0.36844576322115385, 2.9017427884615383, 3.275691105769231, 2.98046875]
Epoch: 7, loss: 10.1695, lr: 0.00000955
epoch 8: 100%|██████████| 13/13 [00:25<00:00,  1.96s/it, cur_loss=10.4]
train acc=0.2247596153846154, [l1_loss, ce_loss] => [0.6429912860576923, 0.36962890625, 2.8751502403846154, 3.2627704326923075, 2.957331730769231]
Epoch: 8, loss: 10.1082, lr: 0.00000245
epoch 9: 100%|██████████| 13/13 [00:25<00:00,  1.96s/it, cur_loss=10.2]
train acc=0.234375, [l1_loss, ce_loss] => [0.6439678485576923, 0.3717698317307692, 2.86328125, 3.260967548076923, 2.9487680288461537]
Epoch: 9, loss: 10.0889, lr: 0.00000000
Training complete!
Evaluate: 100%|██████████| 22/22 [00:12<00:00,  1.79it/s]
Test F1-macro:  0.08174776531606358
#######################################

           T-test results
            - t_statistic: 13.973064407075684
            - t_critical: 2.4469118511449692

            Performance results:
            - Non-few shot: [0.6802285772704912, 0.879122983222681, 0.9710793792998176, 0.8285395264291315, 0.9449968401947307, 0.8378468924115812, 0.8442655335585328]
            - Few-shot: [0.1574882918668264, 0.17314214686757606, 0.046063788849713634, 0.169837851285495, 0.05199848108871004, 0.12562824609908324, 0.14923119030588214]

            Final outcome:
            - result: True
            

-------------------------------------------------------------------