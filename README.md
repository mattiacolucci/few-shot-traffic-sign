Abstract

Nowadays, self-driving vehicles is one of the main application of Artificial Intelligence (AI) which has been most widely used in daily-life scenarios. These vehicles are based on many AI models among which there are traffic sign recognition systems. Different proposals have been provided for these systems, most of which rely on the usage of large datasets such as GTSRB (dataset of German traffic signs). Collecting a big amount of data is one of the main problems of Machine Learning models, which need lots of evidences in order to being able to generalize well. The cost of collecting more data than available can be one of the main aspects to consider during the development of these systems. Furthermore, using a big dataset exposes the model to possible Adversarial attacks, such as poisoning attacks, especially in case of out-source training and testing. For these reasons, in this work we investigate the application of a state-of-art (S.O.T.A.) Few-shot Learning (FSL) model, called LDC, on the traffic sign recognition domain. The aim of this work is to compare few-shot performance with non-few-shot ones by using different kinds of S.O.T.A. and baseline models on multiple datasets. The comparison is performed statistically using a Paired T-test.
